{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "948c8f8d",
   "metadata": {},
   "source": [
    "# fMRI processing pipeline: functional processing for pRF mapping\n",
    "\n",
    "This workflow is run in parallel to recon-all on the T1-MPRAGE anatomical image.\n",
    "\n",
    "The functional processing pipeline aims to follow the steps followed in fMRIPrep, adapted for pRF mapping. The steps implemented in the pipeline are as follows:\n",
    "- discard initial fMRI volumes to allow for T1 equilibration\n",
    "- realignment: head-motion estimation and correction (FSL MCFLIRT); within and between sessions\n",
    "- susceptibility-derived distortion estimation and unwarping (FUGUE)\n",
    "- slice-timing correction (SPM)\n",
    "- co-registration of functional and structural data (ANTs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3374d63",
   "metadata": {},
   "source": [
    "### Set preferences\n",
    "Whether or not to write the workflow viz graph, run pipeline, run specific branches of workflow..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a39dc1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52deec77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# whether or not to run the pipeline\n",
    "run_pipeline = True   \n",
    "\n",
    "# whether or not to write workflow graph (svg)\n",
    "write_graph  = True                           \n",
    "                        \n",
    "# whether manual edits exist (for coregistration)\n",
    "manual_edits = False      \n",
    "\n",
    "# whether to do unwarping\n",
    "unwarp = False   \n",
    "precalc_fmap = False # if fmap has been precalculated outside pipeline\n",
    "\n",
    "# whether to apply coregistration\n",
    "coregister = False\n",
    "precalc_coreg = False # if coregistration transform has been precalculated outside pipeline\n",
    "\n",
    "# coregistration method: 'flirt','freesurfer', 'antsRegistration' or 'itk-snap'\n",
    "coreg_method = 'antsRegistration' \n",
    "\n",
    "# coregistration direction: either from functional to structural ('func2struct') or vice versa ('struct2func')\n",
    "coreg_dir = 'func2struct'\n",
    "\n",
    "# number of cores to use: either set explicitly or based on settings in batch file\n",
    "import os\n",
    "n_procs = 1\n",
    "# n_procs = int(os.getenv('OMP_NUM_THREADS'))   \n",
    "print(n_procs)\n",
    "\n",
    "# field map method (https://lcni.uoregon.edu/kb-articles/kb-0003)\n",
    "# Method 1 calculates a field map based on the difference in phase \n",
    "# between two different echos in a double echo sequence. \n",
    "# Method 2 uses two separate acquisitions with opposite phase encoding \n",
    "# directions to calculate a field map based on the difference in \n",
    "# distortion between the two acquisitions.\n",
    "fmap_method = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefbcb1f",
   "metadata": {},
   "source": [
    "### Set paths\n",
    "All computer-dependent paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee61d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as opj\n",
    "\n",
    "local = False\n",
    "if local:\n",
    "    doc_dir = '/home/mayajas/Documents'\n",
    "    data_dir = '/home/mayajas/scratch/project-0b-pRF-tutorial-3T/'\n",
    "else:\n",
    "    doc_dir = '/home/mayaaj90/'\n",
    "    data_dir = '/scratch/mayaaj90/project-0b-pRF-tutorial-3T/'\n",
    "\n",
    "\n",
    "# general software directory\n",
    "software_dir = opj(doc_dir,'programs')\n",
    "\n",
    "# SPM dir\n",
    "spm_dir = opj(software_dir,'spm12')\n",
    "\n",
    "# data directory\n",
    "raw_data_dir = opj(data_dir,'raw')\n",
    "\n",
    "# scripts directory\n",
    "der_dir = opj(data_dir,'derivatives')\n",
    "\n",
    "# dicoms directory\n",
    "dicom_dir = opj(data_dir,'dicoms')\n",
    "\n",
    "# pRF directory\n",
    "pRF_dir = opj(data_dir,'output','prfpy')\n",
    "\n",
    "# output directory for datasink\n",
    "out_dir = opj(data_dir,'output')\n",
    "\n",
    "# FS output from anatomy pipeline\n",
    "subjects_dir = opj(data_dir,'data_FS')\n",
    "os.environ['SUBJECTS_DIR']=subjects_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848c670d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/mayaaj90/project-0b-pRF-tutorial-3T/data_FS'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['SUBJECTS_DIR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8412b9b",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import required libraries, set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9499b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:37,673 nipype.utils WARNING:\n",
      "\t A newer version (1.8.4) of nipy/nipype is available. You are using 1.7.1\n",
      "230402-10:23:38,209 nipype.interface DEBUG:\n",
      "\t matlab command or path has changed. recomputing version.\n",
      "230402-10:23:38,238 nipype.interface DEBUG:\n",
      "\t nodesktop_True\n",
      "230402-10:23:38,240 nipype.interface DEBUG:\n",
      "\t nosplash_True\n",
      "230402-10:23:38,241 nipype.interface DEBUG:\n",
      "\t single_comp_thread_True\n",
      "230402-10:23:38,243 nipype.interface DEBUG:\n",
      "\t nodesktop_True\n",
      "230402-10:23:38,245 nipype.interface DEBUG:\n",
      "\t nosplash_True\n",
      "230402-10:23:38,246 nipype.interface DEBUG:\n",
      "\t single_comp_thread_True\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from nipype.interfaces.io import DataGrabber, DataSink\n",
    "\n",
    "from nipype import Node, MapNode, JoinNode, Workflow\n",
    "\n",
    "from nipype.interfaces.freesurfer import MRIConvert, SampleToSurface\n",
    "\n",
    "#import nipype_settings\n",
    "import nipype.interfaces.matlab as Matlab\n",
    "from nipype.interfaces.base import (\n",
    "    CommandLineInputSpec,\n",
    "    CommandLine,\n",
    "    TraitedSpec,\n",
    "    BaseInterface, \n",
    "    BaseInterfaceInputSpec, \n",
    "    File,\n",
    "    Directory\n",
    ")\n",
    "\n",
    "from string import Template\n",
    "\n",
    "from nipype.interfaces.utility import Function, IdentityInterface, Select\n",
    "from nipype.interfaces.utility import Merge as utilMerge\n",
    "from nipype.interfaces.utility import Select as utilSelect\n",
    "from nipype.interfaces.base import BaseInterface, BaseInterfaceInputSpec, CommandLine, Directory, File, TraitedSpec, traits\n",
    "\n",
    "from nipype import config\n",
    "config.enable_debug_mode()\n",
    "\n",
    "from os.path import abspath\n",
    "\n",
    "from nipype.interfaces.freesurfer.model import Binarize\n",
    "\n",
    "import pygraphviz \n",
    "\n",
    "from pydicom.data import get_testdata_file\n",
    "from pydicom import dcmread\n",
    "\n",
    "from nipype.interfaces.fsl import BET, PrepareFieldmap, ExtractROI, MCFLIRT, ConvertXFM, FLIRT\n",
    "from nipype.interfaces.fsl import Merge as fslMerge\n",
    "from nipype.interfaces.fsl import Split as fslSplit\n",
    "\n",
    "from nipype.interfaces.freesurfer.registration import MRICoreg\n",
    "from nipype.interfaces.freesurfer.preprocess import BBRegister\n",
    "\n",
    "from nipype.interfaces.dcmstack import MergeNifti\n",
    "\n",
    "import sys\n",
    "sys.path.append(software_dir)\n",
    "from ApplyXfm4D import ApplyXfm4D\n",
    "\n",
    "from nipype.interfaces.fsl.preprocess import FUGUE\n",
    "\n",
    "from nipype.interfaces.afni import Warp, TShift\n",
    "\n",
    "from nipype.interfaces.spm import SliceTiming, Reslice\n",
    "\n",
    "# import neuropythy as ny\n",
    "\n",
    "import nipype.interfaces.matlab as Matlab\n",
    "\n",
    "from nipype.interfaces.ants.registration import Registration\n",
    "from nipype.interfaces.ants import N4BiasFieldCorrection\n",
    "from nipype.interfaces.ants import ApplyTransforms\n",
    "\n",
    "from nipype.interfaces.fsl.maths import BinaryMaths\n",
    "\n",
    "# set SPM path\n",
    "os.environ['SPM_PATH']=spm_dir\n",
    "\n",
    "from nipype.interfaces import spm\n",
    "spm.SPMCommand.set_mlab_paths(paths=spm_dir)\n",
    "\n",
    "from nipype.interfaces.fsl import MeanImage\n",
    "#print(spm.Info.name())\n",
    "#print(spm.SPMCommand().version)\n",
    "\n",
    "import scipy.io\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a3d44",
   "metadata": {},
   "source": [
    "### Neuropythy configuration\n",
    "On startup, neuropythy looks for file ~/.npythyrc. Here, we override these settings and environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677b57a4",
   "metadata": {},
   "source": [
    "### Specify important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2896395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_name = 'wf_func_preproc'\n",
    "\n",
    "T1_id      = 'T1w.nii'                                                # name of preprocessed T1 (output of structural processing pipeline)\n",
    "inplane_id = 'inplane.nii'\n",
    "\n",
    "# manual correction files - from itksnap\n",
    "coreg_itksnap_struct2func_txt_id = 'coreg_itksnap_struct2func.txt'\n",
    "# coreg_itksnap_struct2func_mat_id = 'coreg_itksnap_struct2func.mat'\n",
    "coreg_itksnap_func2struct_txt_id = 'coreg_itksnap_func2struct.txt'\n",
    "coreg_regINPLANE2T1_id      = 'regINPLANE2T1_Composite.h5'\n",
    "coreg_regFUNC2INPLANE_id    = 'regFUNC2INPLANE_Composite.h5'\n",
    "\n",
    "manual_midoccmask_id    = 'midoccMask.nii'\n",
    "manual_occipitalmask_id = 'occipitalMask.nii'\n",
    "\n",
    "if fmap_method == 1:\n",
    "    fmap_magnitude1_id  = 'magnitude1.nii'\n",
    "    fmap_phasediff_id   = 'phasediff.nii'\n",
    "    precalc_fmap_id     = 'funcReg_fmap_rads.nii'\n",
    "#elif fmap_method == 2:\n",
    "    # implement\n",
    "\n",
    "    \n",
    "n_dummy = 8                                                     # number of dummy scans to discard to allow for T1 equilibration\n",
    "\n",
    "n_vol_bar1 = 168                                                # number of volumes of bar pRF mapping stimulus\n",
    "n_vol_bar2 = n_vol_bar1                                         # number of volumes of bar pRF mapping stimulus\n",
    "n_vol_bar3 = n_vol_bar1                                         # number of volumes of bar pRF mapping stimulus\n",
    "\n",
    "# iterables\n",
    "# subject_list = ['sub-01','sub-02','sub-03','sub-04']            # subject identifiers\n",
    "subject_list = ['sub-011']            # subject identifiers\n",
    "sess_id_list = ['task-bar_run-01', 'task-bar_run-02',           # func session identifiers\n",
    "             'task-bar_run-03']#, 'task-bar_run-04']\n",
    "sess_nvol_list = [n_vol_bar1, n_vol_bar2,\n",
    "                  n_vol_bar3]\n",
    "sess_nr_list = list(range(0, len(sess_id_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d698bc51",
   "metadata": {},
   "source": [
    "Get TR/TE/slice timing info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce50a784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ConversionSoftware': 'dicm2nii.m 20220526',\n",
       " 'SeriesNumber': 10,\n",
       " 'SeriesDescription': 'ep2d_func_task-vfmBAR_p2s2_2x2x2_TR1500_168',\n",
       " 'ImageType': ['ORIGINAL', 'PRIMARY', 'FMRI', 'NONE'],\n",
       " 'Modality': 'MR',\n",
       " 'AcquisitionDateTime': '20220620103223.317500',\n",
       " 'TotalReadoutTime': 0.040514734,\n",
       " 'SliceTiming': [0.693,\n",
       "  1.383,\n",
       "  0.593,\n",
       "  1.283,\n",
       "  0.495,\n",
       "  1.185,\n",
       "  0.395,\n",
       "  1.085,\n",
       "  0.298,\n",
       "  0.988,\n",
       "  0.198,\n",
       "  0.888,\n",
       "  0.101,\n",
       "  0.791,\n",
       "  0,\n",
       "  0.693,\n",
       "  1.383,\n",
       "  0.593,\n",
       "  1.283,\n",
       "  0.495,\n",
       "  1.185,\n",
       "  0.395,\n",
       "  1.085,\n",
       "  0.298,\n",
       "  0.988,\n",
       "  0.198,\n",
       "  0.888,\n",
       "  0.101,\n",
       "  0.791,\n",
       "  0],\n",
       " 'RepetitionTime': 1.5,\n",
       " 'ParallelReductionFactorInPlane': 2,\n",
       " 'ParallelAcquisitionTechnique': 'SliceAccel',\n",
       " 'PhaseEncodingDirection': 'i',\n",
       " 'EffectiveEchoSpacing': 0.00036499761,\n",
       " 'EchoTime': 0.03,\n",
       " 'PatientName': 'CCNB_9776^ncFlicker-2',\n",
       " 'PatientSex': 'M',\n",
       " 'PatientAge': '023Y',\n",
       " 'PatientSize': 1.87,\n",
       " 'PatientWeight': 75,\n",
       " 'PatientPosition': 'HFS',\n",
       " 'SliceThickness': 2,\n",
       " 'FlipAngle': 70,\n",
       " 'Manufacturer': 'Siemens Healthineers',\n",
       " 'SoftwareVersion': 'syngo MR XA30',\n",
       " 'MRAcquisitionType': '2D',\n",
       " 'InstitutionName': 'Freie Universität Berlin',\n",
       " 'InstitutionAddress': 'Habelschwerdter Allee 45,Berlin,District,DE,14195',\n",
       " 'DeviceSerialNumber': '167110',\n",
       " 'SequenceName': '*epfid2d1_112'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = opj(data_dir,'raw','sub-011','func','task-bar_run-01.json')\n",
    "  \n",
    "# Opening JSON file\n",
    "f = open(fpath)\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "func_json = json.load(f)\n",
    "func_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c88e4e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.693, 1.383, 0.593, 1.283, 0.495, 1.185, 0.395, 1.085, 0.298, 0.988, 0.198, 0.888, 0.101, 0.791, 0, 0.693, 1.383, 0.593, 1.283, 0.495, 1.185, 0.395, 1.085, 0.298, 0.988, 0.198, 0.888, 0.101, 0.791, 0]\n"
     ]
    }
   ],
   "source": [
    " print(func_json[\"SliceTiming\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4845f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repetition time\n",
    "TR = func_json[\"RepetitionTime\"]                               # in seconds [s]\n",
    "TR_str = '%.1fs' % TR\n",
    "\n",
    "# echo time\n",
    "TE = func_json[\"EchoTime\"]                                     # in seconds [s]\n",
    "\n",
    "# MR acquisition type\n",
    "acquisition_type = func_json[\"MRAcquisitionType\"]\n",
    "\n",
    "# slice acquisition times\n",
    "slice_timing = func_json[\"SliceTiming\"]            # in seconds [s]\n",
    "\n",
    "# number of slices\n",
    "num_slices = len(slice_timing)\n",
    "\n",
    "# time of volume acquisition\n",
    "TA = TR-(TR/num_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63bfdaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e643e31e",
   "metadata": {},
   "source": [
    "Get parameters needed for fieldmap correction (see: https://lcni.uoregon.edu/kb-articles/kb-0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecc2533e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ConversionSoftware': 'dicm2nii.m 20220526',\n",
       " 'SeriesNumber': 6,\n",
       " 'SeriesDescription': 'gre_field_mapping_3mm',\n",
       " 'ImageType': ['ORIGINAL', 'PRIMARY', 'M', 'NONE'],\n",
       " 'Modality': 'MR',\n",
       " 'AcquisitionDateTime': '20220620101853.465000',\n",
       " 'TotalReadoutTime': 0.054054,\n",
       " 'RepetitionTime': 0.4,\n",
       " 'ParallelReductionFactorInPlane': 1,\n",
       " 'ParallelAcquisitionTechnique': 'none',\n",
       " 'PhaseEncodingDirection': 'i',\n",
       " 'EffectiveEchoSpacing': 0.0008316,\n",
       " 'EchoTime': 0.00492,\n",
       " 'deltaTE': 2.46,\n",
       " 'PatientName': 'CCNB_9776^ncFlicker-2',\n",
       " 'PatientSex': 'M',\n",
       " 'PatientAge': '023Y',\n",
       " 'PatientSize': 1.87,\n",
       " 'PatientWeight': 75,\n",
       " 'PatientPosition': 'HFS',\n",
       " 'SliceThickness': 3,\n",
       " 'FlipAngle': 60,\n",
       " 'Manufacturer': 'Siemens Healthineers',\n",
       " 'SoftwareVersion': 'syngo MR XA30',\n",
       " 'MRAcquisitionType': '2D',\n",
       " 'InstitutionName': 'Freie Universität Berlin',\n",
       " 'InstitutionAddress': 'Habelschwerdter Allee 45,Berlin,District,DE,14195',\n",
       " 'DeviceSerialNumber': '167110',\n",
       " 'SequenceName': '*fm2d2r'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = opj(data_dir,'raw','sub-011','fmap','magnitude1.json')\n",
    "  \n",
    "# Opening JSON file\n",
    "f = open(fpath)\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "magnitude1_json = json.load(f)\n",
    "magnitude1_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f039388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# effective echo spacing \n",
    "effective_echo_spacing = func_json[\"EffectiveEchoSpacing\"]\n",
    "\n",
    "# deltaTE\n",
    "delta_TE = magnitude1_json[\"deltaTE\"]# in milliseconds [ms]      \n",
    "                                     # (a float, nipype default value: 2.46) \n",
    "                                     # echo time difference of the fieldmap \n",
    "                                     # sequence in ms. (usually 2.46ms in Siemens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a741e301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00036499761"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effective_echo_spacing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4580fc5",
   "metadata": {},
   "source": [
    "### Create workflow\n",
    "About connecting nodes: https://nipype.readthedocs.io/en/0.11.0/users/joinnode_and_itersource.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18cd9839",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow(name=wf_name, base_dir=der_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d49f3b",
   "metadata": {},
   "source": [
    "### Subjects & functional sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e006bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = Node(IdentityInterface(fields=['subject_id']),name='subjects')\n",
    "subjects.iterables = [('subject_id', subject_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4da9439",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = Node(IdentityInterface(fields=['sess_id','sess_nvol','sess_nr']),name='sessions')\n",
    "sessions.iterables = [('sess_id', sess_id_list), ('sess_nvol', sess_nvol_list), ('sess_nr', sess_nr_list)]\n",
    "sessions.synchronize = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d7ddc",
   "metadata": {},
   "source": [
    "### Acquisition parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "749d873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisitionParams = Node(IdentityInterface(fields=['n_dummy', 'TR'\n",
    "                                                  'TA','TR_str','TE','acquisition_type',\n",
    "                                                  'slice_timing','num_slices',\n",
    "                                                  'effective_echo_spacing',\n",
    "                                                  'delta_TE']),\n",
    "                         name='acquisitionParams')\n",
    "\n",
    "acquisitionParams.inputs.n_dummy = n_dummy\n",
    "acquisitionParams.inputs.TR = TR\n",
    "acquisitionParams.inputs.TA = TA\n",
    "acquisitionParams.inputs.TR_str = TR_str\n",
    "acquisitionParams.inputs.TE = TE\n",
    "acquisitionParams.inputs.acquisition_type = acquisition_type\n",
    "acquisitionParams.inputs.slice_timing = slice_timing\n",
    "acquisitionParams.inputs.num_slices = num_slices\n",
    "acquisitionParams.inputs.effective_echo_spacing = effective_echo_spacing\n",
    "acquisitionParams.inputs.delta_TE = delta_TE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f682f",
   "metadata": {},
   "source": [
    "### Grab data\n",
    "\n",
    "DataGrabber is an interface for collecting files from hard drive. It is very flexible and supports almost any file organization of your data you can imagine.\n",
    "<br>More info: https://nipype.readthedocs.io/en/0.11.0/users/grabbing_and_sinking.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd98b19",
   "metadata": {},
   "source": [
    "#### Anatomical and field map data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a0f51d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource = Node(DataGrabber(infields=['subject_id'], outfields=['T1', \n",
    "                                                                  'fmap_magnitude1', \n",
    "                                                                  'fmap_phasediff', \n",
    "                                                                  'subject_id']),\n",
    "                 name='datasource')\n",
    "datasource.inputs.base_directory = data_dir\n",
    "datasource.inputs.sort_filelist = False\n",
    "datasource.inputs.template = '*'\n",
    "datasource.inputs.field_template = dict(T1='raw/%s/anat/'+T1_id,\n",
    "                                        fmap_magnitude1='raw/%s/fmap/'+fmap_magnitude1_id,\n",
    "                                        fmap_phasediff='raw/%s/fmap/'+fmap_phasediff_id\n",
    "                                       )\n",
    "datasource.inputs.template_args = dict(T1=[['subject_id']],\n",
    "                                       fmap_magnitude1=[['subject_id']],\n",
    "                                       fmap_phasediff=[['subject_id']]\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "488a58c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:57,320 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.subjects, wf_func_preproc.datasource): No edge data\n",
      "230402-10:23:57,321 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.subjects, wf_func_preproc.datasource): new edge data: {'connect': [('subject_id', 'subject_id')]}\n"
     ]
    }
   ],
   "source": [
    "wf.connect([(subjects, datasource,[('subject_id', 'subject_id')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4812dd",
   "metadata": {},
   "source": [
    "#### Functional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de4444a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasourceFunc = Node(DataGrabber(infields=['subject_id','sess_id'], outfields=['sess_id', \n",
    "                                                                  'subject_id']),\n",
    "                 name='datasourceFunc')\n",
    "datasourceFunc.inputs.base_directory = data_dir\n",
    "datasourceFunc.inputs.sort_filelist = False\n",
    "datasourceFunc.inputs.template = '*'\n",
    "datasourceFunc.inputs.field_template = dict(sess_id='raw/%s/func/%s.nii'\n",
    "                                       )\n",
    "datasourceFunc.inputs.template_args = dict(sess_id=[['subject_id','sess_id']]\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dcba196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:57,392 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.subjects, wf_func_preproc.datasourceFunc): No edge data\n",
      "230402-10:23:57,394 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.subjects, wf_func_preproc.datasourceFunc): new edge data: {'connect': [('subject_id', 'subject_id')]}\n",
      "230402-10:23:57,396 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sessions, wf_func_preproc.datasourceFunc): No edge data\n",
      "230402-10:23:57,398 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sessions, wf_func_preproc.datasourceFunc): new edge data: {'connect': [('sess_id', 'sess_id')]}\n"
     ]
    }
   ],
   "source": [
    "wf.connect([(subjects, datasourceFunc, [('subject_id', 'subject_id')])])\n",
    "wf.connect([(sessions, datasourceFunc, [('sess_id', 'sess_id')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e10ffe9",
   "metadata": {},
   "source": [
    "#### Manual edits\n",
    "(if they exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c9cdaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasourceManualEdits = Node(DataGrabber(infields=['subject_id'], outfields=['coreg_regFUNC2INPLANE',\n",
    "                                                                             'coreg_regINPLANE2T1',\n",
    "                                                                             'subject_id']),\n",
    "                 name='datasourceManualEdits')\n",
    "datasourceManualEdits.inputs.base_directory = data_dir\n",
    "datasourceManualEdits.inputs.sort_filelist = False\n",
    "datasourceManualEdits.inputs.template = '*'\n",
    "datasourceManualEdits.inputs.field_template = dict(coreg_regFUNC2INPLANE='output/coreg/%s/func2struct/'+coreg_regFUNC2INPLANE_id,\n",
    "                                                   coreg_regINPLANE2T1='output/coreg/%s/func2struct/'+coreg_regINPLANE2T1_id\n",
    "                                       )\n",
    "datasourceManualEdits.inputs.template_args = dict(coreg_regFUNC2INPLANE=[['subject_id']],\n",
    "                                                  coreg_regINPLANE2T1=[['subject_id']]\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d96d0acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:57,461 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.subjects, wf_func_preproc.datasourceManualEdits): No edge data\n",
      "230402-10:23:57,464 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.subjects, wf_func_preproc.datasourceManualEdits): new edge data: {'connect': [('subject_id', 'subject_id')]}\n"
     ]
    }
   ],
   "source": [
    "if manual_edits: \n",
    "    wf.connect([(subjects, datasourceManualEdits, [('subject_id', 'subject_id')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8322d",
   "metadata": {},
   "source": [
    "#### Pre-calculated field-map\n",
    "(if it exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa3600fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasourcePrecalcFmap = Node(DataGrabber(infields=['subject_id'], outfields=['precalc_fmap',\n",
    "                                                                             'subject_id']),\n",
    "                 name='datasourcePrecalcFmap')\n",
    "datasourcePrecalcFmap.inputs.base_directory = data_dir\n",
    "datasourcePrecalcFmap.inputs.sort_filelist = False\n",
    "datasourcePrecalcFmap.inputs.template = '*'\n",
    "datasourcePrecalcFmap.inputs.field_template = dict(precalc_fmap='output/fmap/_subject_id_%s/'+precalc_fmap_id\n",
    "\n",
    "                                       )\n",
    "datasourcePrecalcFmap.inputs.template_args = dict(precalc_fmap=[['subject_id']]\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "318ad82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if precalc_fmap: \n",
    "    wf.connect([(subjects, datasourcePrecalcFmap, [('subject_id', 'subject_id')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef2915",
   "metadata": {},
   "source": [
    "### Calculate field map\n",
    "\n",
    "Using fsl_prepare_fieldmap. \n",
    "\n",
    "\"If you have data from a SIEMENS scanner then we strongly recommend that the tool fsl_prepare_fieldmap is used to generate the required input data for FEAT or fugue. Fieldmap data from a SIEMENS scanner takes the form of one phase difference image and two magnitude images (one for each echo time). In the following, where a magnitude image is required, pick the \"best looking\" one. This image is used for registration and masking but the process is not particularly sensitive to the quality and typically either image will work fine.\n",
    "\n",
    "Brain extraction of the magnitude image is very important and must be tight - that is, it must exclude all non-brain voxels and any voxels with only a small partial volume contribution. The reason for this is that these areas are normally very noisy in the phase image (look at them in FSLView - if they are not noisy then this is not so important). It is crucial that the mask (derived from this brain extracted image) contains few of these noisy voxels. This is most easily done by making the brain extraction very tight, erring on excluding brain voxels. The exclusion of brain voxels in this instance is actually fine and will have no repercussions, since the fieldmap is extrapolated beyond this mask, and that is the only purpose that the mask plays. Therefore make sure your mask is (if it can't be perfect) too small. As noted above, either magnitude image (from the different echos) can normally be used here - it is not that important.\" \n",
    "\n",
    "Source: https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FUGUE/Guide#SIEMENS_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e6c83",
   "metadata": {},
   "source": [
    "#### Brain extract magnitude image\n",
    "Use magnitude1.nii by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad220c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FSL BET - run on magnitude1.nii image\n",
    "betMagnImg = Node(BET(),name='betMagnImg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04fee403",
   "metadata": {},
   "outputs": [],
   "source": [
    "if unwarp and not precalc_fmap:\n",
    "    wf.connect([(datasource,betMagnImg,[('fmap_magnitude1','in_file')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa79df1b",
   "metadata": {},
   "source": [
    "#### Prepare field map\n",
    "\n",
    "Prepares a fieldmap suitable for FEAT from SIEMENS data - saves output in rad/s format (e.g. `fsl_prepare_fieldmap SIEMENS images_3_gre_field_mapping images_4_gre_field_mapping fmap_rads 2.65`).\n",
    "\n",
    "\n",
    "[Mandatory]\n",
    "delta_TE: (a float, nipype default value: 2.46)\n",
    "        echo time difference of the fieldmap sequence in ms. (usually 2.46ms\n",
    "        in Siemens)\n",
    "        flag: %f, position: -2\n",
    "in_magnitude: (an existing file name)\n",
    "        Magnitude difference map, brain extracted\n",
    "        flag: %s, position: 3\n",
    "in_phase: (an existing file name)\n",
    "        Phase difference map, in SIEMENS format range from 0-4096 or 0-8192)\n",
    "        flag: %s, position: 2\n",
    "        \n",
    "        \n",
    "https://nipype.readthedocs.io/en/0.12.1/interfaces/generated/nipype.interfaces.fsl.epi.html#preparefieldmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff582567",
   "metadata": {},
   "outputs": [],
   "source": [
    "if unwarp and not precalc_fmap:\n",
    "    prepFieldMap = Node(PrepareFieldmap(), name='prepFieldMap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45bdd520",
   "metadata": {},
   "outputs": [],
   "source": [
    "if unwarp and not precalc_fmap:\n",
    "    wf.connect([(acquisitionParams,prepFieldMap,[('delta_TE','delta_TE')])])\n",
    "    wf.connect([(betMagnImg,prepFieldMap,[('out_file','in_magnitude')])])\n",
    "    wf.connect([(datasource,prepFieldMap,[('fmap_phasediff','in_phase')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88857b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps the executable command ``fsl_prepare_fieldmap``.\n",
      "\n",
      "Interface for the fsl_prepare_fieldmap script (FSL 5.0)\n",
      "\n",
      "Prepares a fieldmap suitable for FEAT from SIEMENS data - saves output in\n",
      "rad/s format (e.g. ```fsl_prepare_fieldmap SIEMENS\n",
      "images_3_gre_field_mapping images_4_gre_field_mapping fmap_rads 2.65```).\n",
      "\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      ">>> from nipype.interfaces.fsl import PrepareFieldmap\n",
      ">>> prepare = PrepareFieldmap()\n",
      ">>> prepare.inputs.in_phase = \"phase.nii\"\n",
      ">>> prepare.inputs.in_magnitude = \"magnitude.nii\"\n",
      ">>> prepare.inputs.output_type = \"NIFTI_GZ\"\n",
      ">>> prepare.cmdline # doctest: +ELLIPSIS\n",
      "'fsl_prepare_fieldmap SIEMENS phase.nii magnitude.nii .../phase_fslprepared.nii.gz 2.460000'\n",
      ">>> res = prepare.run() # doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "        [Mandatory]\n",
      "        in_phase: (a pathlike object or string representing an existing file)\n",
      "                Phase difference map, in SIEMENS format range from 0-4096 or 0-8192)\n",
      "                argument: ``%s``, position: 2\n",
      "        in_magnitude: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                Magnitude difference map, brain extracted\n",
      "                argument: ``%s``, position: 3\n",
      "        delta_TE: (a float, nipype default value: 2.46)\n",
      "                echo time difference of the fieldmap sequence in ms. (usually 2.46ms\n",
      "                in Siemens)\n",
      "                argument: ``%f``, position: -2\n",
      "\n",
      "        [Optional]\n",
      "        scanner: (a string, nipype default value: SIEMENS)\n",
      "                must be SIEMENS\n",
      "                argument: ``%s``, position: 1\n",
      "        nocheck: (a boolean, nipype default value: False)\n",
      "                do not perform sanity checks for image size/range/dimensions\n",
      "                argument: ``--nocheck``, position: -1\n",
      "        out_fieldmap: (a pathlike object or string representing a file)\n",
      "                output name for prepared fieldmap\n",
      "                argument: ``%s``, position: 4\n",
      "        output_type: ('NIFTI' or 'NIFTI_PAIR' or 'NIFTI_GZ' or\n",
      "                  'NIFTI_PAIR_GZ')\n",
      "                FSL output type\n",
      "        args: (a string)\n",
      "                Additional parameters to the command\n",
      "                argument: ``%s``\n",
      "        environ: (a dictionary with keys which are a bytes or None or a value\n",
      "                  of class 'str' and with values which are a bytes or None or a\n",
      "                  value of class 'str', nipype default value: {})\n",
      "                Environment variables\n",
      "\n",
      "Outputs::\n",
      "\n",
      "        out_fieldmap: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                output name for prepared fieldmap\n",
      "\n",
      "References:\n",
      "-----------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "PrepareFieldmap.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c1c36b",
   "metadata": {},
   "source": [
    "### Discard initial fMRI volumes to allow for T1 equilibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cee34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "discardDummies = Node(ExtractROI(t_min=n_dummy), name='discardDummies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7eab4a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:57,802 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.datasourceFunc, wf_func_preproc.discardDummies): No edge data\n",
      "230402-10:23:57,805 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.datasourceFunc, wf_func_preproc.discardDummies): new edge data: {'connect': [('sess_id', 'in_file')]}\n",
      "230402-10:23:57,807 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sessions, wf_func_preproc.discardDummies): No edge data\n",
      "230402-10:23:57,809 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sessions, wf_func_preproc.discardDummies): new edge data: {'connect': [('sess_nvol', 't_size')]}\n"
     ]
    }
   ],
   "source": [
    "wf.connect([(datasourceFunc, discardDummies,[('sess_id', 'in_file')])])\n",
    "wf.connect([(sessions, discardDummies,[('sess_nvol', 't_size')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b57a09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps the executable command ``fslroi``.\n",
      "\n",
      "Uses FSL Fslroi command to extract region of interest (ROI)\n",
      "from an image.\n",
      "\n",
      "You can a) take a 3D ROI from a 3D data set (or if it is 4D, the\n",
      "same ROI is taken from each time point and a new 4D data set is\n",
      "created), b) extract just some time points from a 4D data set, or\n",
      "c) control time and space limits to the ROI.  Note that the\n",
      "arguments are minimum index and size (not maximum index).  So to\n",
      "extract voxels 10 to 12 inclusive you would specify 10 and 3 (not\n",
      "10 and 12).\n",
      "\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      ">>> from nipype.interfaces.fsl import ExtractROI\n",
      ">>> from nipype.testing import anatfile\n",
      ">>> fslroi = ExtractROI(in_file=anatfile, roi_file='bar.nii', t_min=0,\n",
      "...                     t_size=1)\n",
      ">>> fslroi.cmdline == 'fslroi %s bar.nii 0 1' % anatfile\n",
      "True\n",
      "\n",
      "Inputs::\n",
      "\n",
      "        [Mandatory]\n",
      "        in_file: (a pathlike object or string representing an existing file)\n",
      "                input file\n",
      "                argument: ``%s``, position: 0\n",
      "\n",
      "        [Optional]\n",
      "        roi_file: (a pathlike object or string representing a file)\n",
      "                output file\n",
      "                argument: ``%s``, position: 1\n",
      "        x_min: (an integer)\n",
      "                argument: ``%d``, position: 2\n",
      "        x_size: (an integer)\n",
      "                argument: ``%d``, position: 3\n",
      "        y_min: (an integer)\n",
      "                argument: ``%d``, position: 4\n",
      "        y_size: (an integer)\n",
      "                argument: ``%d``, position: 5\n",
      "        z_min: (an integer)\n",
      "                argument: ``%d``, position: 6\n",
      "        z_size: (an integer)\n",
      "                argument: ``%d``, position: 7\n",
      "        t_min: (an integer)\n",
      "                argument: ``%d``, position: 8\n",
      "        t_size: (an integer)\n",
      "                argument: ``%d``, position: 9\n",
      "        crop_list: (a list of items which are a tuple of the form: (an\n",
      "                  integer, an integer))\n",
      "                list of two tuples specifying crop options\n",
      "                argument: ``%s``, position: 2\n",
      "                mutually_exclusive: x_min, x_size, y_min, y_size, z_min, z_size,\n",
      "                  t_min, t_size\n",
      "        output_type: ('NIFTI' or 'NIFTI_PAIR' or 'NIFTI_GZ' or\n",
      "                  'NIFTI_PAIR_GZ')\n",
      "                FSL output type\n",
      "        args: (a string)\n",
      "                Additional parameters to the command\n",
      "                argument: ``%s``\n",
      "        environ: (a dictionary with keys which are a bytes or None or a value\n",
      "                  of class 'str' and with values which are a bytes or None or a\n",
      "                  value of class 'str', nipype default value: {})\n",
      "                Environment variables\n",
      "\n",
      "Outputs::\n",
      "\n",
      "        roi_file: (a pathlike object or string representing an existing file)\n",
      "\n",
      "References:\n",
      "-----------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ExtractROI.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fbf916",
   "metadata": {},
   "source": [
    "### Realignment: head-motion estimation and correction (FSL MCFLIRT)\n",
    "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/MCFLIRT\n",
    "\n",
    "https://nipype.readthedocs.io/en/0.12.1/interfaces/generated/nipype.interfaces.fsl.preprocess.html\n",
    "\n",
    "citation: Jenkinson, M., Bannister, P., Brady, J. M. and Smith, S. M. Improved Optimisation for the Robust and Accurate Linear Registration and Motion Correction of Brain Images. NeuroImage, 17(2), 825-841, 2002. \n",
    "\n",
    "First, motion-correction with MCFLIRT, within each session, saving the resulting transformation matrices. Then, concatenate the mean runs from each session and realign to each other with MCFLIRT, saving the transformation matrices. Loop through each matrix in the MCFLIRT output and do 'convert_xfm -omat CONCAT_0000 -concat reg_series1_to_series2.mat MAT_0000' for all MAT* files, then use applyxfm4D, with the \"-userprefix CONCAT_\" option. This does all transformations at once, directly from the original data and minimizes interpolation effects. Based on: https://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=fsl;21c97ca8.06\n",
    "\n",
    "#### Within sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7655ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vol  = False             # (a boolean) register to mean volume\n",
    "save_mats = True              # (a boolean) save transformation parameters\n",
    "ref_vol   = 1                 # (an integer) volume to align frames to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d026419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcflirtWithinSess = Node(MCFLIRT(mean_vol = mean_vol, save_mats=save_mats, ref_vol=ref_vol), \n",
    "               name='mcflirtWithinSess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bb54e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:57,948 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.discardDummies, wf_func_preproc.mcflirtWithinSess): No edge data\n",
      "230402-10:23:57,949 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.discardDummies, wf_func_preproc.mcflirtWithinSess): new edge data: {'connect': [('roi_file', 'in_file')]}\n"
     ]
    }
   ],
   "source": [
    "wf.connect([(discardDummies, mcflirtWithinSess,[('roi_file','in_file')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df500cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps the executable command ``mcflirt``.\n",
      "\n",
      "FSL MCFLIRT wrapper for within-modality motion correction\n",
      "\n",
      "For complete details, see the `MCFLIRT Documentation.\n",
      "<https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/MCFLIRT>`_\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from nipype.interfaces import fsl\n",
      ">>> mcflt = fsl.MCFLIRT()\n",
      ">>> mcflt.inputs.in_file = 'functional.nii'\n",
      ">>> mcflt.inputs.cost = 'mutualinfo'\n",
      ">>> mcflt.inputs.out_file = 'moco.nii'\n",
      ">>> mcflt.cmdline\n",
      "'mcflirt -in functional.nii -cost mutualinfo -out moco.nii'\n",
      ">>> res = mcflt.run()  # doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "        [Mandatory]\n",
      "        in_file: (a pathlike object or string representing an existing file)\n",
      "                timeseries to motion-correct\n",
      "                argument: ``-in %s``, position: 0\n",
      "\n",
      "        [Optional]\n",
      "        out_file: (a pathlike object or string representing a file)\n",
      "                file to write\n",
      "                argument: ``-out %s``\n",
      "        cost: ('mutualinfo' or 'woods' or 'corratio' or 'normcorr' or\n",
      "                  'normmi' or 'leastsquares')\n",
      "                cost function to optimize\n",
      "                argument: ``-cost %s``\n",
      "        bins: (an integer)\n",
      "                number of histogram bins\n",
      "                argument: ``-bins %d``\n",
      "        dof: (an integer)\n",
      "                degrees of freedom for the transformation\n",
      "                argument: ``-dof %d``\n",
      "        ref_vol: (an integer)\n",
      "                volume to align frames to\n",
      "                argument: ``-refvol %d``\n",
      "        scaling: (a float)\n",
      "                scaling factor to use\n",
      "                argument: ``-scaling %.2f``\n",
      "        smooth: (a float)\n",
      "                smoothing factor for the cost function\n",
      "                argument: ``-smooth %.2f``\n",
      "        rotation: (an integer)\n",
      "                scaling factor for rotation tolerances\n",
      "                argument: ``-rotation %d``\n",
      "        stages: (an integer)\n",
      "                stages (if 4, perform final search with sinc interpolation\n",
      "                argument: ``-stages %d``\n",
      "        init: (a pathlike object or string representing an existing file)\n",
      "                inital transformation matrix\n",
      "                argument: ``-init %s``\n",
      "        interpolation: ('spline' or 'nn' or 'sinc')\n",
      "                interpolation method for transformation\n",
      "                argument: ``-%s_final``\n",
      "        use_gradient: (a boolean)\n",
      "                run search on gradient images\n",
      "                argument: ``-gdt``\n",
      "        use_contour: (a boolean)\n",
      "                run search on contour images\n",
      "                argument: ``-edge``\n",
      "        mean_vol: (a boolean)\n",
      "                register to mean volume\n",
      "                argument: ``-meanvol``\n",
      "        stats_imgs: (a boolean)\n",
      "                produce variance and std. dev. images\n",
      "                argument: ``-stats``\n",
      "        save_mats: (a boolean)\n",
      "                save transformation matrices\n",
      "                argument: ``-mats``\n",
      "        save_plots: (a boolean)\n",
      "                save transformation parameters\n",
      "                argument: ``-plots``\n",
      "        save_rms: (a boolean)\n",
      "                save rms displacement parameters\n",
      "                argument: ``-rmsabs -rmsrel``\n",
      "        ref_file: (a pathlike object or string representing an existing file)\n",
      "                target image for motion correction\n",
      "                argument: ``-reffile %s``\n",
      "        output_type: ('NIFTI' or 'NIFTI_PAIR' or 'NIFTI_GZ' or\n",
      "                  'NIFTI_PAIR_GZ')\n",
      "                FSL output type\n",
      "        args: (a string)\n",
      "                Additional parameters to the command\n",
      "                argument: ``%s``\n",
      "        environ: (a dictionary with keys which are a bytes or None or a value\n",
      "                  of class 'str' and with values which are a bytes or None or a\n",
      "                  value of class 'str', nipype default value: {})\n",
      "                Environment variables\n",
      "\n",
      "Outputs::\n",
      "\n",
      "        out_file: (a pathlike object or string representing an existing file)\n",
      "                motion-corrected timeseries\n",
      "        variance_img: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                variance image\n",
      "        std_img: (a pathlike object or string representing an existing file)\n",
      "                standard deviation image\n",
      "        mean_img: (a pathlike object or string representing an existing file)\n",
      "                mean timeseries image (if mean_vol=True)\n",
      "        par_file: (a pathlike object or string representing an existing file)\n",
      "                text-file with motion parameters\n",
      "        mat_file: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                transformation matrices\n",
      "        rms_files: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                absolute and relative displacement parameters\n",
      "\n",
      "References:\n",
      "-----------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "MCFLIRT.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9debe88d",
   "metadata": {},
   "source": [
    "#### Between sessions\n",
    "##### Take mean of each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18df0cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "getMeanImg = Node(MeanImage(dimension='T'),name='getMeanImg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69489a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:58,69 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.mcflirtWithinSess, wf_func_preproc.getMeanImg): No edge data\n",
      "230402-10:23:58,70 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.mcflirtWithinSess, wf_func_preproc.getMeanImg): new edge data: {'connect': [('out_file', 'in_file')]}\n"
     ]
    }
   ],
   "source": [
    "wf.connect([(mcflirtWithinSess,getMeanImg,[('out_file','in_file')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b143510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps the executable command ``fslmaths``.\n",
      "\n",
      "Use fslmaths to generate a mean image across a given dimension.\n",
      "\n",
      "Inputs::\n",
      "\n",
      "        [Mandatory]\n",
      "        in_file: (a pathlike object or string representing an existing file)\n",
      "                image to operate on\n",
      "                argument: ``%s``, position: 2\n",
      "\n",
      "        [Optional]\n",
      "        dimension: ('T' or 'X' or 'Y' or 'Z', nipype default value: T)\n",
      "                dimension to mean across\n",
      "                argument: ``-%smean``, position: 4\n",
      "        out_file: (a pathlike object or string representing a file)\n",
      "                image to write\n",
      "                argument: ``%s``, position: -2\n",
      "        internal_datatype: ('float' or 'char' or 'int' or 'short' or 'double'\n",
      "                  or 'input')\n",
      "                datatype to use for calculations (default is float)\n",
      "                argument: ``-dt %s``, position: 1\n",
      "        output_datatype: ('float' or 'char' or 'int' or 'short' or 'double'\n",
      "                  or 'input')\n",
      "                datatype to use for output (default uses input type)\n",
      "                argument: ``-odt %s``, position: -1\n",
      "        nan2zeros: (a boolean)\n",
      "                change NaNs to zeros before doing anything\n",
      "                argument: ``-nan``, position: 3\n",
      "        output_type: ('NIFTI' or 'NIFTI_PAIR' or 'NIFTI_GZ' or\n",
      "                  'NIFTI_PAIR_GZ')\n",
      "                FSL output type\n",
      "        args: (a string)\n",
      "                Additional parameters to the command\n",
      "                argument: ``%s``\n",
      "        environ: (a dictionary with keys which are a bytes or None or a value\n",
      "                  of class 'str' and with values which are a bytes or None or a\n",
      "                  value of class 'str', nipype default value: {})\n",
      "                Environment variables\n",
      "\n",
      "Outputs::\n",
      "\n",
      "        out_file: (a pathlike object or string representing a file)\n",
      "                image written after calculations\n",
      "\n",
      "References:\n",
      "-----------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "MeanImage.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5fc5c6",
   "metadata": {},
   "source": [
    "##### Concatenate mean runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01c2343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 't'\n",
    "output_type = 'NIFTI'\n",
    "merged_file = 'merged_means.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b31a166c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:58,194 nipype.workflow DEBUG:\n",
      "\t Converted the join node concatenateMeans field in_files trait type from a legal value to a pathlike object or string representing an existing file\n"
     ]
    }
   ],
   "source": [
    "concatenateMeans = JoinNode(fslMerge(dimension=dimension, output_type=output_type, merged_file=merged_file),\n",
    "                        joinfield='in_files',\n",
    "                        joinsource='sessions',\n",
    "                        name=\"concatenateMeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f80ad02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:58,234 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.getMeanImg, wf_func_preproc.concatenateMeans): No edge data\n",
      "230402-10:23:58,234 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.getMeanImg, wf_func_preproc.concatenateMeans): new edge data: {'connect': [('out_file', 'in_files')]}\n"
     ]
    }
   ],
   "source": [
    "# wf.connect([(mcflirtWithinSess, concatenateMeans,[('mean_img', 'in_files')])])\n",
    "wf.connect([(getMeanImg, concatenateMeans,[('out_file', 'in_files')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e4d30",
   "metadata": {},
   "source": [
    "##### MCFLIRT on merged mean runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1491a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vol = False               # (a boolean) register to mean volume\n",
    "save_mats = True               # (a boolean) save transformation parameters\n",
    "ref_vol   = 1                 # (an integer) volume to align frames to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "870ecb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcflirtBetweenSess = Node(MCFLIRT(mean_vol = mean_vol, save_mats=save_mats, ref_vol=ref_vol), \n",
    "               name='mcflirtBetweenSess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3cbdb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:58,328 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.concatenateMeans, wf_func_preproc.mcflirtBetweenSess): No edge data\n",
      "230402-10:23:58,329 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.concatenateMeans, wf_func_preproc.mcflirtBetweenSess): new edge data: {'connect': [('merged_file', 'in_file')]}\n"
     ]
    }
   ],
   "source": [
    "wf.connect([(concatenateMeans, mcflirtBetweenSess,[('merged_file','in_file')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d1f4e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps the executable command ``mcflirt``.\n",
      "\n",
      "FSL MCFLIRT wrapper for within-modality motion correction\n",
      "\n",
      "For complete details, see the `MCFLIRT Documentation.\n",
      "<https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/MCFLIRT>`_\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from nipype.interfaces import fsl\n",
      ">>> mcflt = fsl.MCFLIRT()\n",
      ">>> mcflt.inputs.in_file = 'functional.nii'\n",
      ">>> mcflt.inputs.cost = 'mutualinfo'\n",
      ">>> mcflt.inputs.out_file = 'moco.nii'\n",
      ">>> mcflt.cmdline\n",
      "'mcflirt -in functional.nii -cost mutualinfo -out moco.nii'\n",
      ">>> res = mcflt.run()  # doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "        [Mandatory]\n",
      "        in_file: (a pathlike object or string representing an existing file)\n",
      "                timeseries to motion-correct\n",
      "                argument: ``-in %s``, position: 0\n",
      "\n",
      "        [Optional]\n",
      "        out_file: (a pathlike object or string representing a file)\n",
      "                file to write\n",
      "                argument: ``-out %s``\n",
      "        cost: ('mutualinfo' or 'woods' or 'corratio' or 'normcorr' or\n",
      "                  'normmi' or 'leastsquares')\n",
      "                cost function to optimize\n",
      "                argument: ``-cost %s``\n",
      "        bins: (an integer)\n",
      "                number of histogram bins\n",
      "                argument: ``-bins %d``\n",
      "        dof: (an integer)\n",
      "                degrees of freedom for the transformation\n",
      "                argument: ``-dof %d``\n",
      "        ref_vol: (an integer)\n",
      "                volume to align frames to\n",
      "                argument: ``-refvol %d``\n",
      "        scaling: (a float)\n",
      "                scaling factor to use\n",
      "                argument: ``-scaling %.2f``\n",
      "        smooth: (a float)\n",
      "                smoothing factor for the cost function\n",
      "                argument: ``-smooth %.2f``\n",
      "        rotation: (an integer)\n",
      "                scaling factor for rotation tolerances\n",
      "                argument: ``-rotation %d``\n",
      "        stages: (an integer)\n",
      "                stages (if 4, perform final search with sinc interpolation\n",
      "                argument: ``-stages %d``\n",
      "        init: (a pathlike object or string representing an existing file)\n",
      "                inital transformation matrix\n",
      "                argument: ``-init %s``\n",
      "        interpolation: ('spline' or 'nn' or 'sinc')\n",
      "                interpolation method for transformation\n",
      "                argument: ``-%s_final``\n",
      "        use_gradient: (a boolean)\n",
      "                run search on gradient images\n",
      "                argument: ``-gdt``\n",
      "        use_contour: (a boolean)\n",
      "                run search on contour images\n",
      "                argument: ``-edge``\n",
      "        mean_vol: (a boolean)\n",
      "                register to mean volume\n",
      "                argument: ``-meanvol``\n",
      "        stats_imgs: (a boolean)\n",
      "                produce variance and std. dev. images\n",
      "                argument: ``-stats``\n",
      "        save_mats: (a boolean)\n",
      "                save transformation matrices\n",
      "                argument: ``-mats``\n",
      "        save_plots: (a boolean)\n",
      "                save transformation parameters\n",
      "                argument: ``-plots``\n",
      "        save_rms: (a boolean)\n",
      "                save rms displacement parameters\n",
      "                argument: ``-rmsabs -rmsrel``\n",
      "        ref_file: (a pathlike object or string representing an existing file)\n",
      "                target image for motion correction\n",
      "                argument: ``-reffile %s``\n",
      "        output_type: ('NIFTI' or 'NIFTI_PAIR' or 'NIFTI_GZ' or\n",
      "                  'NIFTI_PAIR_GZ')\n",
      "                FSL output type\n",
      "        args: (a string)\n",
      "                Additional parameters to the command\n",
      "                argument: ``%s``\n",
      "        environ: (a dictionary with keys which are a bytes or None or a value\n",
      "                  of class 'str' and with values which are a bytes or None or a\n",
      "                  value of class 'str', nipype default value: {})\n",
      "                Environment variables\n",
      "\n",
      "Outputs::\n",
      "\n",
      "        out_file: (a pathlike object or string representing an existing file)\n",
      "                motion-corrected timeseries\n",
      "        variance_img: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                variance image\n",
      "        std_img: (a pathlike object or string representing an existing file)\n",
      "                standard deviation image\n",
      "        mean_img: (a pathlike object or string representing an existing file)\n",
      "                mean timeseries image (if mean_vol=True)\n",
      "        par_file: (a pathlike object or string representing an existing file)\n",
      "                text-file with motion parameters\n",
      "        mat_file: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                transformation matrices\n",
      "        rms_files: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                absolute and relative displacement parameters\n",
      "\n",
      "References:\n",
      "-----------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "MCFLIRT.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a2faf3",
   "metadata": {},
   "source": [
    "##### Concatenate transformation matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f440be0",
   "metadata": {},
   "source": [
    "Select given session's transformation mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b35c9d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenMat = Node(Select(), name='betweenMat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "308cbe57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:58,438 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.mcflirtBetweenSess, wf_func_preproc.betweenMat): No edge data\n",
      "230402-10:23:58,439 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.mcflirtBetweenSess, wf_func_preproc.betweenMat): new edge data: {'connect': [('mat_file', 'inlist')]}\n",
      "230402-10:23:58,440 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sessions, wf_func_preproc.betweenMat): No edge data\n",
      "230402-10:23:58,440 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sessions, wf_func_preproc.betweenMat): new edge data: {'connect': [('sess_nr', 'index')]}\n"
     ]
    }
   ],
   "source": [
    "wf.connect([(mcflirtBetweenSess, betweenMat, [('mat_file', 'inlist')])])\n",
    "wf.connect([(sessions, betweenMat, [('sess_nr', 'index')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea8aabb",
   "metadata": {},
   "source": [
    "Concatenate within-session mat_files with corresponding session's between-session realignment mat_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e67b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_xfm = True         # (a boolean) write joint transformation of two input matrices\n",
    "                          # flag: -concat, position: -3\n",
    "                          # mutually_exclusive: invert_xfm, concat_xfm, fix_scale_skew\n",
    "                          # requires: in_file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7669c521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:58,516 nipype.workflow DEBUG:\n",
      "\t adding multipath trait: in_file2\n"
     ]
    }
   ],
   "source": [
    "concatenateTransforms = MapNode(ConvertXFM(concat_xfm=concat_xfm),\n",
    "                            name = 'concatenateTransforms', iterfield=['in_file2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a0ba131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:58,574 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.betweenMat, wf_func_preproc.concatenateTransforms): No edge data\n",
      "230402-10:23:58,575 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.betweenMat, wf_func_preproc.concatenateTransforms): new edge data: {'connect': [('out', 'in_file')]}\n",
      "230402-10:23:58,576 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.mcflirtWithinSess, wf_func_preproc.concatenateTransforms): No edge data\n",
      "230402-10:23:58,576 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.mcflirtWithinSess, wf_func_preproc.concatenateTransforms): new edge data: {'connect': [('mat_file', 'in_file2')]}\n"
     ]
    }
   ],
   "source": [
    "wf.connect([(betweenMat,concatenateTransforms,[('out','in_file')])])\n",
    "wf.connect([(mcflirtWithinSess,concatenateTransforms,[('mat_file','in_file2')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e98942d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ConvertXFM.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb5b4d2",
   "metadata": {},
   "source": [
    "Put all transformation matrices for given session in one folder\n",
    "\n",
    "(Not the most elegant solution, but ApplyXfm4D requires a directory of tranformation mat files as input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "285fc4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_transforms(subject_id,sess_id,sess_nr,sess_nvol,mat_files,working_dir):\n",
    "    from os.path import join as opj\n",
    "    import shutil\n",
    "    import os\n",
    "    \n",
    "    transformMatDir = opj(working_dir,'_subject_id_'+subject_id,\n",
    "                         '_sess_id_'+sess_id+'_sess_nr_'+str(sess_nr)+'_sess_nvol_'+str(sess_nvol),\n",
    "                         'transformMats')\n",
    "    \n",
    "    if not os.path.isdir(transformMatDir):\n",
    "        os.mkdir(transformMatDir)\n",
    "    \n",
    "    for mat in mat_files:\n",
    "        print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "        print(mat)\n",
    "        print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "\n",
    "        # copy file\n",
    "        shutil.copy(mat, transformMatDir)\n",
    "        \n",
    "        # remove .mat extension (this is how the ApplyXfm4D interface likes it)\n",
    "        base=os.path.basename(mat)\n",
    "        filename=os.path.splitext(base)[0]\n",
    "        shutil.move(opj(transformMatDir,filename+'.mat'), opj(transformMatDir,filename)) \n",
    "\n",
    "    # session-dependent filename prefix\n",
    "    prefix = f\"MAT_000{sess_nr}_MAT_\"\n",
    "\n",
    "    return transformMatDir, prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e3c81be",
   "metadata": {},
   "outputs": [],
   "source": [
    "copyTransforms = Node(Function(input_names = ['subject_id','sess_id','sess_nr', 'sess_nvol',\n",
    "                                             'mat_files','working_dir'],\n",
    "                               output_names=['transformMatDir','prefix'],\n",
    "                               function=copy_transforms),\n",
    "                      name='copyTransforms')\n",
    "copyTransforms.inputs.working_dir = opj(der_dir,wf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "483107bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:58,705 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.subjects, wf_func_preproc.copyTransforms): No edge data\n",
      "230402-10:23:58,706 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.subjects, wf_func_preproc.copyTransforms): new edge data: {'connect': [('subject_id', 'subject_id')]}\n",
      "230402-10:23:58,706 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sessions, wf_func_preproc.copyTransforms): No edge data\n",
      "230402-10:23:58,707 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sessions, wf_func_preproc.copyTransforms): new edge data: {'connect': [('sess_id', 'sess_id')]}\n",
      "230402-10:23:58,708 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sessions, wf_func_preproc.copyTransforms): Edge data exists: {'connect': [('sess_id', 'sess_id')]}\n",
      "230402-10:23:58,708 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sessions, wf_func_preproc.copyTransforms): new edge data: {'connect': [('sess_id', 'sess_id'), ('sess_nr', 'sess_nr')]}\n",
      "230402-10:23:58,709 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sessions, wf_func_preproc.copyTransforms): Edge data exists: {'connect': [('sess_id', 'sess_id'), ('sess_nr', 'sess_nr')]}\n",
      "230402-10:23:58,710 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sessions, wf_func_preproc.copyTransforms): new edge data: {'connect': [('sess_id', 'sess_id'), ('sess_nr', 'sess_nr'), ('sess_nvol', 'sess_nvol')]}\n",
      "230402-10:23:58,711 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.concatenateTransforms, wf_func_preproc.copyTransforms): No edge data\n",
      "230402-10:23:58,711 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.concatenateTransforms, wf_func_preproc.copyTransforms): new edge data: {'connect': [('out_file', 'mat_files')]}\n"
     ]
    }
   ],
   "source": [
    "wf.connect([(subjects, copyTransforms, [('subject_id', 'subject_id')])])\n",
    "wf.connect([(sessions, copyTransforms, [('sess_id', 'sess_id')])])\n",
    "wf.connect([(sessions, copyTransforms, [('sess_nr', 'sess_nr')])])\n",
    "wf.connect([(sessions, copyTransforms, [('sess_nvol', 'sess_nvol')])])\n",
    "wf.connect([(concatenateTransforms, copyTransforms, [('out_file', 'mat_files')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43df2b91",
   "metadata": {},
   "source": [
    "Apply transformation matrices to realign within and between sessions in one step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c7e2dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "applyRealign = Node(ApplyXfm4D(),name='applyRealign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef609187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:23:58,764 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.discardDummies, wf_func_preproc.applyRealign): No edge data\n",
      "230402-10:23:58,765 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.discardDummies, wf_func_preproc.applyRealign): new edge data: {'connect': [('roi_file', 'in_file')]}\n",
      "230402-10:23:58,766 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.discardDummies, wf_func_preproc.applyRealign): Edge data exists: {'connect': [('roi_file', 'in_file')]}\n",
      "230402-10:23:58,766 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.discardDummies, wf_func_preproc.applyRealign): new edge data: {'connect': [('roi_file', 'in_file'), ('roi_file', 'ref_vol')]}\n",
      "230402-10:23:58,767 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.copyTransforms, wf_func_preproc.applyRealign): No edge data\n",
      "230402-10:23:58,768 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.copyTransforms, wf_func_preproc.applyRealign): new edge data: {'connect': [('transformMatDir', 'trans_dir')]}\n",
      "230402-10:23:58,769 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.copyTransforms, wf_func_preproc.applyRealign): Edge data exists: {'connect': [('transformMatDir', 'trans_dir')]}\n",
      "230402-10:23:58,769 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.copyTransforms, wf_func_preproc.applyRealign): new edge data: {'connect': [('transformMatDir', 'trans_dir'), ('prefix', 'user_prefix')]}\n"
     ]
    }
   ],
   "source": [
    "wf.connect([(discardDummies,applyRealign,[('roi_file','in_file')])])\n",
    "wf.connect([(discardDummies,applyRealign,[('roi_file','ref_vol')])])\n",
    "wf.connect([(copyTransforms,applyRealign,[('transformMatDir','trans_dir')])])\n",
    "wf.connect([(copyTransforms,applyRealign,[('prefix','user_prefix')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9efebacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ApplyXfm4D.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059cb5e",
   "metadata": {},
   "source": [
    "### Unwarping\n",
    "\n",
    "fugue (FMRIB's Utility for Geometrically Unwarping EPIs) performs unwarping of an EPI image based on fieldmap data. The input required consists of the EPI image, the fieldmap (as an unwrapped phase map or a scaled fieldmap in rad/s) and appropriate image sequence parameters for the EPI and fieldmap acquisitions: the dwell time for EPI (also known as the echo spacing); and the echo time difference (called asym time herein). \n",
    "\n",
    "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FUGUE/Guide\n",
    "\n",
    "https://nipype.readthedocs.io/en/0.12.0/interfaces/generated/nipype.interfaces.fsl.preprocess.html#fugue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84bb00b",
   "metadata": {},
   "source": [
    "#### Get first dimension of 4D fieldmap image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0e550d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitFieldMapImage = Node(fslSplit(dimension='t'),name='splitFieldMapImage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e1814e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if unwarp and not precalc_fmap:\n",
    "    wf.connect([(prepFieldMap,splitFieldMapImage,[('out_fieldmap','in_file')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d148751",
   "metadata": {},
   "outputs": [],
   "source": [
    "getFieldMap = Node(utilSelect(index=[0]),name='getFieldMap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e7cd98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if unwarp and not precalc_fmap:\n",
    "    wf.connect([(splitFieldMapImage,getFieldMap,[('out_files','inlist')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19e55ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fslSplit.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb231b4",
   "metadata": {},
   "source": [
    "#### Reslice fmap to functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8469f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:25:27,530 nipype.interface DEBUG:\n",
      "\t matlab command or path has changed. recomputing version.\n",
      "230402-10:25:27,537 nipype.interface DEBUG:\n",
      "\t nodesktop_True\n",
      "230402-10:25:27,538 nipype.interface DEBUG:\n",
      "\t nosplash_True\n",
      "230402-10:25:27,539 nipype.interface DEBUG:\n",
      "\t single_comp_thread_True\n",
      "230402-10:25:27,539 nipype.interface DEBUG:\n",
      "\t nodesktop_True\n",
      "230402-10:25:27,540 nipype.interface DEBUG:\n",
      "\t nosplash_True\n",
      "230402-10:25:27,541 nipype.interface DEBUG:\n",
      "\t single_comp_thread_True\n",
      "230402-10:25:47,979 nipype.interface DEBUG:\n",
      "\t Command:\n",
      "matlab -nodesktop -nosplash -nodesktop -nosplash -singleCompThread -r \"fprintf(1,'Executing code at %s:\\n',datestr(now));fprintf(1,'Executing code at %s:\\n',datestr(now));ver,try,,if isempty(which('spm')),,throw(MException('SPMCheck:NotFound','SPM not in matlab path'));,end;,spm_path = spm('dir');,[name, version] = spm('ver');,fprintf(1, 'NIPYPE path:%s|name:%s|release:%s', spm_path, name, version);,exit;,        ,catch ME,fprintf(2,'MATLAB code threw an exception:\\n');fprintf(2,'%s\\n',ME.message);if length(ME.stack) ~= 0, fprintf(2,'File:%s\\nName:%s\\nLine:%d\\n',ME.stack.file,ME.stack.name,ME.stack.line);, end;end;;exit\"\n",
      "Standard output:\n",
      "MATLAB is selecting SOFTWARE OPENGL rendering.\n",
      "Opening log file:  /home/mayaaj90/java.log.47721\n",
      "\n",
      "                            < M A T L A B (R) >\n",
      "                  Copyright 1984-2021 The MathWorks, Inc.\n",
      "                  R2021a (9.10.0.1602886) 64-bit (glnxa64)\n",
      "                             February 17, 2021\n",
      "\n",
      " \n",
      "To get started, type doc.\n",
      "For product information, visit www.mathworks.com.\n",
      " \n",
      "Executing code at 02-Apr-2023 10:25:42:\n",
      "Executing code at 02-Apr-2023 10:25:42:\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "MATLAB Version: 9.10.0.1602886 (R2021a)\n",
      "MATLAB License Number: 40871342\n",
      "Operating System: Linux 3.10.0-1160.83.1.el7.x86_64 #1 SMP Wed Jan 25 16:41:43 UTC 2023 x86_64\n",
      "Java Version: Java 1.8.0_202-b08 with Oracle Corporation Java HotSpot(TM) 64-Bit Server VM mixed mode\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "MATLAB                                                Version 9.10        (R2021a)\n",
      "Simulink                                              Version 10.3        (R2021a)\n",
      "5G Toolbox                                            Version 2.2         (R2021a)\n",
      "AUTOSAR Blockset                                      Version 2.4         (R2021a)\n",
      "Aerospace Blockset                                    Version 5.0         (R2021a)\n",
      "Aerospace Toolbox                                     Version 4.0         (R2021a)\n",
      "Antenna Toolbox                                       Version 5.0         (R2021a)\n",
      "Audio Toolbox                                         Version 3.0         (R2021a)\n",
      "Automated Driving Toolbox                             Version 3.3         (R2021a)\n",
      "Bioinformatics Toolbox                                Version 4.15.1      (R2021a)\n",
      "Communications Toolbox                                Version 7.5         (R2021a)\n",
      "Computer Vision Toolbox                               Version 10.0        (R2021a)\n",
      "Control System Toolbox                                Version 10.10       (R2021a)\n",
      "Curve Fitting Toolbox                                 Version 3.5.13      (R2021a)\n",
      "DDS Blockset                                          Version 1.0         (R2021a)\n",
      "DSP System Toolbox                                    Version 9.12        (R2021a)\n",
      "Database Toolbox                                      Version 10.1        (R2021a)\n",
      "Datafeed Toolbox                                      Version 6.0         (R2021a)\n",
      "Deep Learning HDL Toolbox                             Version 1.1         (R2021a)\n",
      "Deep Learning Toolbox                                 Version 14.2        (R2021a)\n",
      "Econometrics Toolbox                                  Version 5.6         (R2021a)\n",
      "Embedded Coder                                        Version 7.6         (R2021a)\n",
      "Filter Design HDL Coder                               Version 3.1.9       (R2021a)\n",
      "Financial Instruments Toolbox                         Version 3.2         (R2021a)\n",
      "Financial Toolbox                                     Version 6.1         (R2021a)\n",
      "Fixed-Point Designer                                  Version 7.2         (R2021a)\n",
      "Fuzzy Logic Toolbox                                   Version 2.8.1       (R2021a)\n",
      "GPU Coder                                             Version 2.1         (R2021a)\n",
      "Global Optimization Toolbox                           Version 4.5         (R2021a)\n",
      "HDL Coder                                             Version 3.18        (R2021a)\n",
      "HDL Verifier                                          Version 6.3         (R2021a)\n",
      "Image Acquisition Toolbox                             Version 6.4         (R2021a)\n",
      "Image Processing Toolbox                              Version 11.3        (R2021a)\n",
      "Instrument Control Toolbox                            Version 4.4         (R2021a)\n",
      "LTE Toolbox                                           Version 3.5         (R2021a)\n",
      "Lidar Toolbox                                         Version 1.1         (R2021a)\n",
      "MATLAB Coder                                          Version 5.2         (R2021a)\n",
      "MATLAB Compiler                                       Version 8.2         (R2021a)\n",
      "MATLAB Compiler SDK                                   Version 6.10        (R2021a)\n",
      "MATLAB Report Generator                               Version 5.10        (R2021a)\n",
      "Mapping Toolbox                                       Version 5.1         (R2021a)\n",
      "Mixed-Signal Blockset                                 Version 2.0         (R2021a)\n",
      "Model Predictive Control Toolbox                      Version 7.1         (R2021a)\n",
      "Motor Control Blockset                                Version 1.2         (R2021a)\n",
      "Navigation Toolbox                                    Version 2.0         (R2021a)\n",
      "Optimization Toolbox                                  Version 9.1         (R2021a)\n",
      "Parallel Computing Toolbox                            Version 7.4         (R2021a)\n",
      "Partial Differential Equation Toolbox                 Version 3.6         (R2021a)\n",
      "Phased Array System Toolbox                           Version 4.5         (R2021a)\n",
      "Powertrain Blockset                                   Version 1.9         (R2021a)\n",
      "Predictive Maintenance Toolbox                        Version 2.3         (R2021a)\n",
      "RF Blockset                                           Version 8.1         (R2021a)\n",
      "RF Toolbox                                            Version 4.1         (R2021a)\n",
      "ROS Toolbox                                           Version 1.3         (R2021a)\n",
      "Radar Toolbox                                         Version 1.0         (R2021a)\n",
      "Reinforcement Learning Toolbox                        Version 2.0         (R2021a)\n",
      "Risk Management Toolbox                               Version 1.9         (R2021a)\n",
      "Robotics System Toolbox                               Version 3.3         (R2021a)\n",
      "Robust Control Toolbox                                Version 6.10        (R2021a)\n",
      "Satellite Communications Toolbox                      Version 1.0         (R2021a)\n",
      "Sensor Fusion and Tracking Toolbox                    Version 2.1         (R2021a)\n",
      "SerDes Toolbox                                        Version 2.1         (R2021a)\n",
      "Signal Processing Toolbox                             Version 8.6         (R2021a)\n",
      "SimBiology                                            Version 6.1         (R2021a)\n",
      "SimEvents                                             Version 5.10        (R2021a)\n",
      "Simscape                                              Version 5.1         (R2021a)\n",
      "Simscape Driveline                                    Version 3.3         (R2021a)\n",
      "Simscape Electrical                                   Version 7.5         (R2021a)\n",
      "Simscape Fluids                                       Version 3.2         (R2021a)\n",
      "Simscape Multibody                                    Version 7.3         (R2021a)\n",
      "Simulink 3D Animation                                 Version 9.2         (R2021a)\n",
      "Simulink Check                                        Version 5.1         (R2021a)\n",
      "Simulink Code Inspector                               Version 3.8         (R2021a)\n",
      "Simulink Coder                                        Version 9.5         (R2021a)\n",
      "Simulink Compiler                                     Version 1.2         (R2021a)\n",
      "Simulink Control Design                               Version 5.7         (R2021a)\n",
      "Simulink Coverage                                     Version 5.2         (R2021a)\n",
      "Simulink Design Optimization                          Version 3.9.1       (R2021a)\n",
      "Simulink Design Verifier                              Version 4.5         (R2021a)\n",
      "Simulink PLC Coder                                    Version 3.4         (R2021a)\n",
      "Simulink Report Generator                             Version 5.10        (R2021a)\n",
      "Simulink Requirements                                 Version 1.7         (R2021a)\n",
      "Simulink Test                                         Version 3.4         (R2021a)\n",
      "SoC Blockset                                          Version 1.4         (R2021a)\n",
      "Stateflow                                             Version 10.4        (R2021a)\n",
      "Statistics and Machine Learning Toolbox               Version 12.1        (R2021a)\n",
      "Symbolic Math Toolbox                                 Version 8.7         (R2021a)\n",
      "System Composer                                       Version 2.0         (R2021a)\n",
      "System Identification Toolbox                         Version 9.14        (R2021a)\n",
      "Text Analytics Toolbox                                Version 1.7         (R2021a)\n",
      "UAV Toolbox                                           Version 1.1         (R2021a)\n",
      "Vehicle Dynamics Blockset                             Version 1.6         (R2021a)\n",
      "Vehicle Network Toolbox                               Version 5.0         (R2021a)\n",
      "Vision HDL Toolbox                                    Version 2.3         (R2021a)\n",
      "WLAN Toolbox                                          Version 3.2         (R2021a)\n",
      "Wavelet Toolbox                                       Version 5.6         (R2021a)\n",
      "Wireless HDL Toolbox                                  Version 2.2         (R2021a)\n",
      "Standard error:\n",
      "MATLAB code threw an exception:\n",
      "SPM not in matlab path\n",
      "Return code: 0\n"
     ]
    }
   ],
   "source": [
    "resliceFieldMap = Node(Reslice(),name='resliceFieldMap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b0bd47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if unwarp and not precalc_fmap:\n",
    "    wf.connect([(getFieldMap,resliceFieldMap,[('out','in_file')])])\n",
    "    wf.connect([(mcflirtBetweenSess,resliceFieldMap,[('out_file','space_defining')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b11d53b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uses  spm_reslice to resample in_file into space of space_defining\n",
      "\n",
      "Inputs::\n",
      "\n",
      "        [Mandatory]\n",
      "        in_file: (a pathlike object or string representing an existing file)\n",
      "                file to apply transform to, (only updates header)\n",
      "        space_defining: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                Volume defining space to slice in_file into\n",
      "\n",
      "        [Optional]\n",
      "        interp: (0 <= an integer <= 7, nipype default value: 0)\n",
      "                degree of b-spline used for interpolation0 is nearest neighbor\n",
      "                (default)\n",
      "        out_file: (a pathlike object or string representing a file)\n",
      "                Optional file to save resliced volume\n",
      "        matlab_cmd: (a string)\n",
      "                matlab command to use\n",
      "        paths: (a list of items which are a pathlike object or string\n",
      "                  representing a directory)\n",
      "                Paths to add to matlabpath\n",
      "        mfile: (a boolean, nipype default value: True)\n",
      "                Run m-code using m-file\n",
      "        use_mcr: (a boolean)\n",
      "                Run m-code using SPM MCR\n",
      "        use_v8struct: (a boolean, nipype default value: True)\n",
      "                Generate SPM8 and higher compatible jobs\n",
      "\n",
      "Outputs::\n",
      "\n",
      "        out_file: (a pathlike object or string representing an existing file)\n",
      "                resliced volume\n",
      "\n",
      "References:\n",
      "-----------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Reslice.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e7ea12",
   "metadata": {},
   "source": [
    "#### Apply unwarping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e8aa5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "unwarp_direction = 'z-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1faeb4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if unwarp: \n",
    "    unwarping = Node(FUGUE(unwarp_direction=unwarp_direction),name='unwarping')\n",
    "\n",
    "# fugue -i epi --dwell=dwelltime --loadfmap=fieldmap -u result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7596546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if unwarp:\n",
    "    wf.connect([(applyRealign,unwarping,[('out_file','in_file')])])\n",
    "    wf.connect([(acquisitionParams,unwarping,[('effective_echo_spacing','dwell_time')])])\n",
    "    if precalc_fmap:\n",
    "        wf.connect([(datasourcePrecalcFmap,unwarping,[('precalc_fmap','fmap_in_file')])])\n",
    "    else:\n",
    "        wf.connect([(resliceFieldMap,unwarping,[('out_file','fmap_in_file')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7aabe8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps the executable command ``fugue``.\n",
      "\n",
      "FSL FUGUE set of tools for EPI distortion correction\n",
      "\n",
      "`FUGUE <http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FUGUE>`_ is, most generally,\n",
      "a set of tools for EPI distortion correction.\n",
      "\n",
      "Distortions may be corrected for\n",
      "    1. improving registration with non-distorted images (e.g. structurals),\n",
      "       or\n",
      "    2. dealing with motion-dependent changes.\n",
      "\n",
      "FUGUE is designed to deal only with the first case -\n",
      "improving registration.\n",
      "\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "\n",
      "Unwarping an input image (shift map is known):\n",
      "\n",
      ">>> from nipype.interfaces.fsl.preprocess import FUGUE\n",
      ">>> fugue = FUGUE()\n",
      ">>> fugue.inputs.in_file = 'epi.nii'\n",
      ">>> fugue.inputs.mask_file = 'epi_mask.nii'\n",
      ">>> fugue.inputs.shift_in_file = 'vsm.nii'  # Previously computed with fugue as well\n",
      ">>> fugue.inputs.unwarp_direction = 'y'\n",
      ">>> fugue.inputs.output_type = \"NIFTI_GZ\"\n",
      ">>> fugue.cmdline # doctest: +ELLIPSIS\n",
      "'fugue --in=epi.nii --mask=epi_mask.nii --loadshift=vsm.nii --unwarpdir=y --unwarp=epi_unwarped.nii.gz'\n",
      ">>> fugue.run() #doctest: +SKIP\n",
      "\n",
      "\n",
      "Warping an input image (shift map is known):\n",
      "\n",
      ">>> from nipype.interfaces.fsl.preprocess import FUGUE\n",
      ">>> fugue = FUGUE()\n",
      ">>> fugue.inputs.in_file = 'epi.nii'\n",
      ">>> fugue.inputs.forward_warping = True\n",
      ">>> fugue.inputs.mask_file = 'epi_mask.nii'\n",
      ">>> fugue.inputs.shift_in_file = 'vsm.nii'  # Previously computed with fugue as well\n",
      ">>> fugue.inputs.unwarp_direction = 'y'\n",
      ">>> fugue.inputs.output_type = \"NIFTI_GZ\"\n",
      ">>> fugue.cmdline # doctest: +ELLIPSIS\n",
      "'fugue --in=epi.nii --mask=epi_mask.nii --loadshift=vsm.nii --unwarpdir=y --warp=epi_warped.nii.gz'\n",
      ">>> fugue.run() #doctest: +SKIP\n",
      "\n",
      "\n",
      "Computing the vsm (unwrapped phase map is known):\n",
      "\n",
      ">>> from nipype.interfaces.fsl.preprocess import FUGUE\n",
      ">>> fugue = FUGUE()\n",
      ">>> fugue.inputs.phasemap_in_file = 'epi_phasediff.nii'\n",
      ">>> fugue.inputs.mask_file = 'epi_mask.nii'\n",
      ">>> fugue.inputs.dwell_to_asym_ratio = (0.77e-3 * 3) / 2.46e-3\n",
      ">>> fugue.inputs.unwarp_direction = 'y'\n",
      ">>> fugue.inputs.save_shift = True\n",
      ">>> fugue.inputs.output_type = \"NIFTI_GZ\"\n",
      ">>> fugue.cmdline # doctest: +ELLIPSIS\n",
      "'fugue --dwelltoasym=0.9390243902 --mask=epi_mask.nii --phasemap=epi_phasediff.nii --saveshift=epi_phasediff_vsm.nii.gz --unwarpdir=y'\n",
      ">>> fugue.run() #doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "        [Optional]\n",
      "        in_file: (a pathlike object or string representing an existing file)\n",
      "                filename of input volume\n",
      "                argument: ``--in=%s``\n",
      "        shift_in_file: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                filename for reading pixel shift volume\n",
      "                argument: ``--loadshift=%s``\n",
      "        phasemap_in_file: (a pathlike object or string representing an\n",
      "                  existing file)\n",
      "                filename for input phase image\n",
      "                argument: ``--phasemap=%s``\n",
      "        fmap_in_file: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                filename for loading fieldmap (rad/s)\n",
      "                argument: ``--loadfmap=%s``\n",
      "        unwarped_file: (a pathlike object or string representing a file)\n",
      "                apply unwarping and save as filename\n",
      "                argument: ``--unwarp=%s``\n",
      "                mutually_exclusive: warped_file\n",
      "                requires: in_file\n",
      "        warped_file: (a pathlike object or string representing a file)\n",
      "                apply forward warping and save as filename\n",
      "                argument: ``--warp=%s``\n",
      "                mutually_exclusive: unwarped_file\n",
      "                requires: in_file\n",
      "        forward_warping: (a boolean, nipype default value: False)\n",
      "                apply forward warping instead of unwarping\n",
      "        dwell_to_asym_ratio: (a float)\n",
      "                set the dwell to asym time ratio\n",
      "                argument: ``--dwelltoasym=%.10f``\n",
      "        dwell_time: (a float)\n",
      "                set the EPI dwell time per phase-encode line - same as echo spacing\n",
      "                - (sec)\n",
      "                argument: ``--dwell=%.10f``\n",
      "        asym_se_time: (a float)\n",
      "                set the fieldmap asymmetric spin echo time (sec)\n",
      "                argument: ``--asym=%.10f``\n",
      "        median_2dfilter: (a boolean)\n",
      "                apply 2D median filtering\n",
      "                argument: ``--median``\n",
      "        despike_2dfilter: (a boolean)\n",
      "                apply a 2D de-spiking filter\n",
      "                argument: ``--despike``\n",
      "        no_gap_fill: (a boolean)\n",
      "                do not apply gap-filling measure to the fieldmap\n",
      "                argument: ``--nofill``\n",
      "        no_extend: (a boolean)\n",
      "                do not apply rigid-body extrapolation to the fieldmap\n",
      "                argument: ``--noextend``\n",
      "        smooth2d: (a float)\n",
      "                apply 2D Gaussian smoothing of sigma N (in mm)\n",
      "                argument: ``--smooth2=%.2f``\n",
      "        smooth3d: (a float)\n",
      "                apply 3D Gaussian smoothing of sigma N (in mm)\n",
      "                argument: ``--smooth3=%.2f``\n",
      "        poly_order: (an integer)\n",
      "                apply polynomial fitting of order N\n",
      "                argument: ``--poly=%d``\n",
      "        fourier_order: (an integer)\n",
      "                apply Fourier (sinusoidal) fitting of order N\n",
      "                argument: ``--fourier=%d``\n",
      "        pava: (a boolean)\n",
      "                apply monotonic enforcement via PAVA\n",
      "                argument: ``--pava``\n",
      "        despike_threshold: (a float)\n",
      "                specify the threshold for de-spiking (default=3.0)\n",
      "                argument: ``--despikethreshold=%s``\n",
      "        unwarp_direction: ('x' or 'y' or 'z' or 'x-' or 'y-' or 'z-')\n",
      "                specifies direction of warping (default y)\n",
      "                argument: ``--unwarpdir=%s``\n",
      "        phase_conjugate: (a boolean)\n",
      "                apply phase conjugate method of unwarping\n",
      "                argument: ``--phaseconj``\n",
      "        icorr: (a boolean)\n",
      "                apply intensity correction to unwarping (pixel shift method only)\n",
      "                argument: ``--icorr``\n",
      "                requires: shift_in_file\n",
      "        icorr_only: (a boolean)\n",
      "                apply intensity correction only\n",
      "                argument: ``--icorronly``\n",
      "                requires: unwarped_file\n",
      "        mask_file: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                filename for loading valid mask\n",
      "                argument: ``--mask=%s``\n",
      "        nokspace: (a boolean)\n",
      "                do not use k-space forward warping\n",
      "                argument: ``--nokspace``\n",
      "        save_shift: (a boolean)\n",
      "                write pixel shift volume\n",
      "                mutually_exclusive: save_unmasked_shift\n",
      "        shift_out_file: (a pathlike object or string representing a file)\n",
      "                filename for saving pixel shift volume\n",
      "                argument: ``--saveshift=%s``\n",
      "        save_unmasked_shift: (a boolean)\n",
      "                saves the unmasked shiftmap when using --saveshift\n",
      "                argument: ``--unmaskshift``\n",
      "                mutually_exclusive: save_shift\n",
      "        save_fmap: (a boolean)\n",
      "                write field map volume\n",
      "                mutually_exclusive: save_unmasked_fmap\n",
      "        fmap_out_file: (a pathlike object or string representing a file)\n",
      "                filename for saving fieldmap (rad/s)\n",
      "                argument: ``--savefmap=%s``\n",
      "        save_unmasked_fmap: (a boolean)\n",
      "                saves the unmasked fieldmap when using --savefmap\n",
      "                argument: ``--unmaskfmap``\n",
      "                mutually_exclusive: save_fmap\n",
      "        output_type: ('NIFTI' or 'NIFTI_PAIR' or 'NIFTI_GZ' or\n",
      "                  'NIFTI_PAIR_GZ')\n",
      "                FSL output type\n",
      "        args: (a string)\n",
      "                Additional parameters to the command\n",
      "                argument: ``%s``\n",
      "        environ: (a dictionary with keys which are a bytes or None or a value\n",
      "                  of class 'str' and with values which are a bytes or None or a\n",
      "                  value of class 'str', nipype default value: {})\n",
      "                Environment variables\n",
      "\n",
      "Outputs::\n",
      "\n",
      "        unwarped_file: (a pathlike object or string representing a file)\n",
      "                unwarped file\n",
      "        warped_file: (a pathlike object or string representing a file)\n",
      "                forward warped file\n",
      "        shift_out_file: (a pathlike object or string representing a file)\n",
      "                voxel shift map file\n",
      "        fmap_out_file: (a pathlike object or string representing a file)\n",
      "                fieldmap file\n",
      "\n",
      "References:\n",
      "-----------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "FUGUE.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8aff15",
   "metadata": {},
   "source": [
    "### Slice-timing correction (SPM)\n",
    "\n",
    "Parker & Razlighi, 2019: \"The Benefit of Slice Timing Correction in Common fMRI Preprocessing Pipelines.\"\n",
    "https://www.frontiersin.org/articles/10.3389/fnins.2019.00821/full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6866051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_slice = 1                           # (an integer (int or long))\n",
    "                                        # 1-based Number of the reference slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b35b2256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:26:01,408 nipype.interface DEBUG:\n",
      "\t matlab command or path has changed. recomputing version.\n",
      "230402-10:26:01,415 nipype.interface DEBUG:\n",
      "\t nodesktop_True\n",
      "230402-10:26:01,416 nipype.interface DEBUG:\n",
      "\t nosplash_True\n",
      "230402-10:26:01,416 nipype.interface DEBUG:\n",
      "\t single_comp_thread_True\n",
      "230402-10:26:01,417 nipype.interface DEBUG:\n",
      "\t nodesktop_True\n",
      "230402-10:26:01,418 nipype.interface DEBUG:\n",
      "\t nosplash_True\n",
      "230402-10:26:01,418 nipype.interface DEBUG:\n",
      "\t single_comp_thread_True\n",
      "230402-10:26:19,620 nipype.interface DEBUG:\n",
      "\t Command:\n",
      "matlab -nodesktop -nosplash -nodesktop -nosplash -singleCompThread -r \"fprintf(1,'Executing code at %s:\\n',datestr(now));fprintf(1,'Executing code at %s:\\n',datestr(now));ver,try,,if isempty(which('spm')),,throw(MException('SPMCheck:NotFound','SPM not in matlab path'));,end;,spm_path = spm('dir');,[name, version] = spm('ver');,fprintf(1, 'NIPYPE path:%s|name:%s|release:%s', spm_path, name, version);,exit;,        ,catch ME,fprintf(2,'MATLAB code threw an exception:\\n');fprintf(2,'%s\\n',ME.message);if length(ME.stack) ~= 0, fprintf(2,'File:%s\\nName:%s\\nLine:%d\\n',ME.stack.file,ME.stack.name,ME.stack.line);, end;end;;exit\"\n",
      "Standard output:\n",
      "MATLAB is selecting SOFTWARE OPENGL rendering.\n",
      "Opening log file:  /home/mayaaj90/java.log.48222\n",
      "\n",
      "                            < M A T L A B (R) >\n",
      "                  Copyright 1984-2021 The MathWorks, Inc.\n",
      "                  R2021a (9.10.0.1602886) 64-bit (glnxa64)\n",
      "                             February 17, 2021\n",
      "\n",
      " \n",
      "To get started, type doc.\n",
      "For product information, visit www.mathworks.com.\n",
      " \n",
      "Executing code at 02-Apr-2023 10:26:15:\n",
      "Executing code at 02-Apr-2023 10:26:15:\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "MATLAB Version: 9.10.0.1602886 (R2021a)\n",
      "MATLAB License Number: 40871342\n",
      "Operating System: Linux 3.10.0-1160.83.1.el7.x86_64 #1 SMP Wed Jan 25 16:41:43 UTC 2023 x86_64\n",
      "Java Version: Java 1.8.0_202-b08 with Oracle Corporation Java HotSpot(TM) 64-Bit Server VM mixed mode\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "MATLAB                                                Version 9.10        (R2021a)\n",
      "Simulink                                              Version 10.3        (R2021a)\n",
      "5G Toolbox                                            Version 2.2         (R2021a)\n",
      "AUTOSAR Blockset                                      Version 2.4         (R2021a)\n",
      "Aerospace Blockset                                    Version 5.0         (R2021a)\n",
      "Aerospace Toolbox                                     Version 4.0         (R2021a)\n",
      "Antenna Toolbox                                       Version 5.0         (R2021a)\n",
      "Audio Toolbox                                         Version 3.0         (R2021a)\n",
      "Automated Driving Toolbox                             Version 3.3         (R2021a)\n",
      "Bioinformatics Toolbox                                Version 4.15.1      (R2021a)\n",
      "Communications Toolbox                                Version 7.5         (R2021a)\n",
      "Computer Vision Toolbox                               Version 10.0        (R2021a)\n",
      "Control System Toolbox                                Version 10.10       (R2021a)\n",
      "Curve Fitting Toolbox                                 Version 3.5.13      (R2021a)\n",
      "DDS Blockset                                          Version 1.0         (R2021a)\n",
      "DSP System Toolbox                                    Version 9.12        (R2021a)\n",
      "Database Toolbox                                      Version 10.1        (R2021a)\n",
      "Datafeed Toolbox                                      Version 6.0         (R2021a)\n",
      "Deep Learning HDL Toolbox                             Version 1.1         (R2021a)\n",
      "Deep Learning Toolbox                                 Version 14.2        (R2021a)\n",
      "Econometrics Toolbox                                  Version 5.6         (R2021a)\n",
      "Embedded Coder                                        Version 7.6         (R2021a)\n",
      "Filter Design HDL Coder                               Version 3.1.9       (R2021a)\n",
      "Financial Instruments Toolbox                         Version 3.2         (R2021a)\n",
      "Financial Toolbox                                     Version 6.1         (R2021a)\n",
      "Fixed-Point Designer                                  Version 7.2         (R2021a)\n",
      "Fuzzy Logic Toolbox                                   Version 2.8.1       (R2021a)\n",
      "GPU Coder                                             Version 2.1         (R2021a)\n",
      "Global Optimization Toolbox                           Version 4.5         (R2021a)\n",
      "HDL Coder                                             Version 3.18        (R2021a)\n",
      "HDL Verifier                                          Version 6.3         (R2021a)\n",
      "Image Acquisition Toolbox                             Version 6.4         (R2021a)\n",
      "Image Processing Toolbox                              Version 11.3        (R2021a)\n",
      "Instrument Control Toolbox                            Version 4.4         (R2021a)\n",
      "LTE Toolbox                                           Version 3.5         (R2021a)\n",
      "Lidar Toolbox                                         Version 1.1         (R2021a)\n",
      "MATLAB Coder                                          Version 5.2         (R2021a)\n",
      "MATLAB Compiler                                       Version 8.2         (R2021a)\n",
      "MATLAB Compiler SDK                                   Version 6.10        (R2021a)\n",
      "MATLAB Report Generator                               Version 5.10        (R2021a)\n",
      "Mapping Toolbox                                       Version 5.1         (R2021a)\n",
      "Mixed-Signal Blockset                                 Version 2.0         (R2021a)\n",
      "Model Predictive Control Toolbox                      Version 7.1         (R2021a)\n",
      "Motor Control Blockset                                Version 1.2         (R2021a)\n",
      "Navigation Toolbox                                    Version 2.0         (R2021a)\n",
      "Optimization Toolbox                                  Version 9.1         (R2021a)\n",
      "Parallel Computing Toolbox                            Version 7.4         (R2021a)\n",
      "Partial Differential Equation Toolbox                 Version 3.6         (R2021a)\n",
      "Phased Array System Toolbox                           Version 4.5         (R2021a)\n",
      "Powertrain Blockset                                   Version 1.9         (R2021a)\n",
      "Predictive Maintenance Toolbox                        Version 2.3         (R2021a)\n",
      "RF Blockset                                           Version 8.1         (R2021a)\n",
      "RF Toolbox                                            Version 4.1         (R2021a)\n",
      "ROS Toolbox                                           Version 1.3         (R2021a)\n",
      "Radar Toolbox                                         Version 1.0         (R2021a)\n",
      "Reinforcement Learning Toolbox                        Version 2.0         (R2021a)\n",
      "Risk Management Toolbox                               Version 1.9         (R2021a)\n",
      "Robotics System Toolbox                               Version 3.3         (R2021a)\n",
      "Robust Control Toolbox                                Version 6.10        (R2021a)\n",
      "Satellite Communications Toolbox                      Version 1.0         (R2021a)\n",
      "Sensor Fusion and Tracking Toolbox                    Version 2.1         (R2021a)\n",
      "SerDes Toolbox                                        Version 2.1         (R2021a)\n",
      "Signal Processing Toolbox                             Version 8.6         (R2021a)\n",
      "SimBiology                                            Version 6.1         (R2021a)\n",
      "SimEvents                                             Version 5.10        (R2021a)\n",
      "Simscape                                              Version 5.1         (R2021a)\n",
      "Simscape Driveline                                    Version 3.3         (R2021a)\n",
      "Simscape Electrical                                   Version 7.5         (R2021a)\n",
      "Simscape Fluids                                       Version 3.2         (R2021a)\n",
      "Simscape Multibody                                    Version 7.3         (R2021a)\n",
      "Simulink 3D Animation                                 Version 9.2         (R2021a)\n",
      "Simulink Check                                        Version 5.1         (R2021a)\n",
      "Simulink Code Inspector                               Version 3.8         (R2021a)\n",
      "Simulink Coder                                        Version 9.5         (R2021a)\n",
      "Simulink Compiler                                     Version 1.2         (R2021a)\n",
      "Simulink Control Design                               Version 5.7         (R2021a)\n",
      "Simulink Coverage                                     Version 5.2         (R2021a)\n",
      "Simulink Design Optimization                          Version 3.9.1       (R2021a)\n",
      "Simulink Design Verifier                              Version 4.5         (R2021a)\n",
      "Simulink PLC Coder                                    Version 3.4         (R2021a)\n",
      "Simulink Report Generator                             Version 5.10        (R2021a)\n",
      "Simulink Requirements                                 Version 1.7         (R2021a)\n",
      "Simulink Test                                         Version 3.4         (R2021a)\n",
      "SoC Blockset                                          Version 1.4         (R2021a)\n",
      "Stateflow                                             Version 10.4        (R2021a)\n",
      "Statistics and Machine Learning Toolbox               Version 12.1        (R2021a)\n",
      "Symbolic Math Toolbox                                 Version 8.7         (R2021a)\n",
      "System Composer                                       Version 2.0         (R2021a)\n",
      "System Identification Toolbox                         Version 9.14        (R2021a)\n",
      "Text Analytics Toolbox                                Version 1.7         (R2021a)\n",
      "UAV Toolbox                                           Version 1.1         (R2021a)\n",
      "Vehicle Dynamics Blockset                             Version 1.6         (R2021a)\n",
      "Vehicle Network Toolbox                               Version 5.0         (R2021a)\n",
      "Vision HDL Toolbox                                    Version 2.3         (R2021a)\n",
      "WLAN Toolbox                                          Version 3.2         (R2021a)\n",
      "Wavelet Toolbox                                       Version 5.6         (R2021a)\n",
      "Wireless HDL Toolbox                                  Version 2.2         (R2021a)\n",
      "Standard error:\n",
      "MATLAB code threw an exception:\n",
      "SPM not in matlab path\n",
      "Return code: 0\n"
     ]
    }
   ],
   "source": [
    "sliceTimingCorr = Node(SliceTiming(ref_slice=ref_slice),name='sliceTimingCorr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "26c55a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:26:19,636 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.applyRealign, wf_func_preproc.sliceTimingCorr): No edge data\n",
      "230402-10:26:19,637 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.applyRealign, wf_func_preproc.sliceTimingCorr): new edge data: {'connect': [('out_file', 'in_files')]}\n",
      "230402-10:26:19,638 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.acquisitionParams, wf_func_preproc.sliceTimingCorr): No edge data\n",
      "230402-10:26:19,639 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.acquisitionParams, wf_func_preproc.sliceTimingCorr): new edge data: {'connect': [('num_slices', 'num_slices')]}\n",
      "230402-10:26:19,640 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.acquisitionParams, wf_func_preproc.sliceTimingCorr): Edge data exists: {'connect': [('num_slices', 'num_slices')]}\n",
      "230402-10:26:19,640 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.acquisitionParams, wf_func_preproc.sliceTimingCorr): new edge data: {'connect': [('num_slices', 'num_slices'), ('slice_timing', 'slice_order')]}\n",
      "230402-10:26:19,641 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.acquisitionParams, wf_func_preproc.sliceTimingCorr): Edge data exists: {'connect': [('num_slices', 'num_slices'), ('slice_timing', 'slice_order')]}\n",
      "230402-10:26:19,641 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.acquisitionParams, wf_func_preproc.sliceTimingCorr): new edge data: {'connect': [('num_slices', 'num_slices'), ('slice_timing', 'slice_order'), ('TR', 'time_repetition')]}\n",
      "230402-10:26:19,642 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.acquisitionParams, wf_func_preproc.sliceTimingCorr): Edge data exists: {'connect': [('num_slices', 'num_slices'), ('slice_timing', 'slice_order'), ('TR', 'time_repetition')]}\n",
      "230402-10:26:19,643 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.acquisitionParams, wf_func_preproc.sliceTimingCorr): new edge data: {'connect': [('num_slices', 'num_slices'), ('slice_timing', 'slice_order'), ('TR', 'time_repetition'), ('TA', 'time_acquisition')]}\n"
     ]
    }
   ],
   "source": [
    "if unwarp:\n",
    "    wf.connect([(unwarping,sliceTimingCorr,[('unwarped_file','in_files')])])\n",
    "else:\n",
    "    wf.connect([(applyRealign,sliceTimingCorr,[('out_file','in_files')])])\n",
    "wf.connect([(acquisitionParams,sliceTimingCorr,[('num_slices','num_slices')])])\n",
    "wf.connect([(acquisitionParams,sliceTimingCorr,[('slice_timing','slice_order')])])\n",
    "wf.connect([(acquisitionParams,sliceTimingCorr,[('TR','time_repetition')])])\n",
    "wf.connect([(acquisitionParams,sliceTimingCorr,[('TA','time_acquisition')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7cc5f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SliceTiming.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30324643",
   "metadata": {},
   "source": [
    "### Co-registration of functional and structural data (FreeSurfer bbregister, FLIRT FSL) \n",
    "\n",
    "Note: structural data is brought into functional space to avoid superfluous interpolation of functional volumes!\n",
    "\n",
    "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FLIRT\n",
    "\n",
    "https://nipype.readthedocs.io/en/0.12.0/interfaces/generated/nipype.interfaces.fsl.preprocess.html#flirt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e186f",
   "metadata": {},
   "source": [
    "#### Concatenate functional runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a959571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 't'\n",
    "output_type = 'NIFTI'\n",
    "merged_file = 'merged_func.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0dba8206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:26:28,524 nipype.workflow DEBUG:\n",
      "\t Converted the join node concatenateFunc field in_files trait type from a legal value to a pathlike object or string representing an existing file\n"
     ]
    }
   ],
   "source": [
    "concatenateFunc = JoinNode(fslMerge(dimension=dimension, output_type=output_type, merged_file=merged_file),\n",
    "                        joinfield='in_files',\n",
    "                        joinsource='sessions',\n",
    "                        name=\"concatenateFunc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e209cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:26:29,102 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sliceTimingCorr, wf_func_preproc.concatenateFunc): No edge data\n",
      "230402-10:26:29,103 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sliceTimingCorr, wf_func_preproc.concatenateFunc): new edge data: {'connect': [('timecorrected_files', 'in_files')]}\n"
     ]
    }
   ],
   "source": [
    "wf.connect([(sliceTimingCorr, concatenateFunc,[('timecorrected_files', 'in_files')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b39dfe",
   "metadata": {},
   "source": [
    "#### Get mean functional volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "43c57141",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vol = True                 # (a boolean) register to mean volume\n",
    "save_mats = False               # (a boolean) save transformation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "581b5853",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanFunc = Node(MCFLIRT(mean_vol = mean_vol, save_mats=save_mats), \n",
    "                    name='meanFunc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0d797fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:26:32,118 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.concatenateFunc, wf_func_preproc.meanFunc): No edge data\n",
      "230402-10:26:32,118 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.concatenateFunc, wf_func_preproc.meanFunc): new edge data: {'connect': [('merged_file', 'in_file')]}\n"
     ]
    }
   ],
   "source": [
    "wf.connect([(concatenateFunc, meanFunc,[('merged_file', 'in_file')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b56845bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps the executable command ``mcflirt``.\n",
      "\n",
      "FSL MCFLIRT wrapper for within-modality motion correction\n",
      "\n",
      "For complete details, see the `MCFLIRT Documentation.\n",
      "<https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/MCFLIRT>`_\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from nipype.interfaces import fsl\n",
      ">>> mcflt = fsl.MCFLIRT()\n",
      ">>> mcflt.inputs.in_file = 'functional.nii'\n",
      ">>> mcflt.inputs.cost = 'mutualinfo'\n",
      ">>> mcflt.inputs.out_file = 'moco.nii'\n",
      ">>> mcflt.cmdline\n",
      "'mcflirt -in functional.nii -cost mutualinfo -out moco.nii'\n",
      ">>> res = mcflt.run()  # doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "        [Mandatory]\n",
      "        in_file: (a pathlike object or string representing an existing file)\n",
      "                timeseries to motion-correct\n",
      "                argument: ``-in %s``, position: 0\n",
      "\n",
      "        [Optional]\n",
      "        out_file: (a pathlike object or string representing a file)\n",
      "                file to write\n",
      "                argument: ``-out %s``\n",
      "        cost: ('mutualinfo' or 'woods' or 'corratio' or 'normcorr' or\n",
      "                  'normmi' or 'leastsquares')\n",
      "                cost function to optimize\n",
      "                argument: ``-cost %s``\n",
      "        bins: (an integer)\n",
      "                number of histogram bins\n",
      "                argument: ``-bins %d``\n",
      "        dof: (an integer)\n",
      "                degrees of freedom for the transformation\n",
      "                argument: ``-dof %d``\n",
      "        ref_vol: (an integer)\n",
      "                volume to align frames to\n",
      "                argument: ``-refvol %d``\n",
      "        scaling: (a float)\n",
      "                scaling factor to use\n",
      "                argument: ``-scaling %.2f``\n",
      "        smooth: (a float)\n",
      "                smoothing factor for the cost function\n",
      "                argument: ``-smooth %.2f``\n",
      "        rotation: (an integer)\n",
      "                scaling factor for rotation tolerances\n",
      "                argument: ``-rotation %d``\n",
      "        stages: (an integer)\n",
      "                stages (if 4, perform final search with sinc interpolation\n",
      "                argument: ``-stages %d``\n",
      "        init: (a pathlike object or string representing an existing file)\n",
      "                inital transformation matrix\n",
      "                argument: ``-init %s``\n",
      "        interpolation: ('spline' or 'nn' or 'sinc')\n",
      "                interpolation method for transformation\n",
      "                argument: ``-%s_final``\n",
      "        use_gradient: (a boolean)\n",
      "                run search on gradient images\n",
      "                argument: ``-gdt``\n",
      "        use_contour: (a boolean)\n",
      "                run search on contour images\n",
      "                argument: ``-edge``\n",
      "        mean_vol: (a boolean)\n",
      "                register to mean volume\n",
      "                argument: ``-meanvol``\n",
      "        stats_imgs: (a boolean)\n",
      "                produce variance and std. dev. images\n",
      "                argument: ``-stats``\n",
      "        save_mats: (a boolean)\n",
      "                save transformation matrices\n",
      "                argument: ``-mats``\n",
      "        save_plots: (a boolean)\n",
      "                save transformation parameters\n",
      "                argument: ``-plots``\n",
      "        save_rms: (a boolean)\n",
      "                save rms displacement parameters\n",
      "                argument: ``-rmsabs -rmsrel``\n",
      "        ref_file: (a pathlike object or string representing an existing file)\n",
      "                target image for motion correction\n",
      "                argument: ``-reffile %s``\n",
      "        output_type: ('NIFTI' or 'NIFTI_PAIR' or 'NIFTI_GZ' or\n",
      "                  'NIFTI_PAIR_GZ')\n",
      "                FSL output type\n",
      "        args: (a string)\n",
      "                Additional parameters to the command\n",
      "                argument: ``%s``\n",
      "        environ: (a dictionary with keys which are a bytes or None or a value\n",
      "                  of class 'str' and with values which are a bytes or None or a\n",
      "                  value of class 'str', nipype default value: {})\n",
      "                Environment variables\n",
      "\n",
      "Outputs::\n",
      "\n",
      "        out_file: (a pathlike object or string representing an existing file)\n",
      "                motion-corrected timeseries\n",
      "        variance_img: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                variance image\n",
      "        std_img: (a pathlike object or string representing an existing file)\n",
      "                standard deviation image\n",
      "        mean_img: (a pathlike object or string representing an existing file)\n",
      "                mean timeseries image (if mean_vol=True)\n",
      "        par_file: (a pathlike object or string representing an existing file)\n",
      "                text-file with motion parameters\n",
      "        mat_file: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                transformation matrices\n",
      "        rms_files: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                absolute and relative displacement parameters\n",
      "\n",
      "References:\n",
      "-----------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "MCFLIRT.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73863263",
   "metadata": {},
   "source": [
    "#### Make functional brain mask for coregistration\n",
    "Note: this doesn't necessarily work well for all subjects. Therefore, this mask must be corrected manually. When the manual edits flag is true, the corrected binarized image is expected to be saved in the manual edits subject folder. Editing is done by loading the output of this node as a segmentation in ITKSNAP and then saving as a nifti file named brainMask.nii in the manual edits folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a378fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 350\n",
    "\n",
    "dilate = 3 # voxels\n",
    "erode = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d365738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizeMeanFunc = Node(Binarize(min=thresh, dilate=dilate, erode=erode),name='binarizeMeanFunc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e9c2545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:26:35,692 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.meanFunc, wf_func_preproc.binarizeMeanFunc): No edge data\n",
      "230402-10:26:35,693 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.meanFunc, wf_func_preproc.binarizeMeanFunc): new edge data: {'connect': [('mean_img', 'in_file')]}\n"
     ]
    }
   ],
   "source": [
    "wf.connect([(meanFunc,binarizeMeanFunc,[('mean_img','in_file')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059c416a",
   "metadata": {},
   "source": [
    "#### Coregister structural image to mean functional (FLIRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "194b7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_matrix_file = 'struct2func.mat'     # (a pathlike object or string representing a file)\n",
    "                                        # output affine matrix in 4x4 asciii format\n",
    "apply_xfm = True                        # (a boolean)\n",
    "                                        # apply transformation supplied by in_matrix_file or uses_qform to use\n",
    "                                        # the affine matrix stored in the reference header\n",
    "coarse_search = 4\n",
    "fine_search = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "43f660f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if coregister and coreg_method == 'flirt':\n",
    "    coreg = Node(FLIRT(),name='coreg')\n",
    "    \n",
    "    # out_matrix_file=out_matrix_file, coarse_search=coarse_search, fine_search=fine_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cd48ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "if coregister and coreg_method == 'flirt':\n",
    "    wf.connect([(datasource, coreg,[('T1', 'in_file')])])        \n",
    "    #wf.connect([(convertT1ToNii, coreg,[('out_file', 'reference')])])   \n",
    "    wf.connect([(meanFunc, coreg,[('mean_img', 'reference')])])  \n",
    "    \n",
    "    if manual_edits:\n",
    "        wf.connect([(datasourceManualEdits, coreg,[('coreg_itksnap_struct2func_txt', 'in_matrix_file')])])\n",
    "        coreg.inputs.apply_xfm = apply_xfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ea4ae306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps the executable command ``flirt``.\n",
      "\n",
      "FSL FLIRT wrapper for coregistration\n",
      "\n",
      "For complete details, see the `FLIRT Documentation.\n",
      "<https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FLIRT>`_\n",
      "\n",
      "To print out the command line help, use:\n",
      "    fsl.FLIRT().inputs_help()\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from nipype.interfaces import fsl\n",
      ">>> from nipype.testing import example_data\n",
      ">>> flt = fsl.FLIRT(bins=640, cost_func='mutualinfo')\n",
      ">>> flt.inputs.in_file = 'structural.nii'\n",
      ">>> flt.inputs.reference = 'mni.nii'\n",
      ">>> flt.inputs.output_type = \"NIFTI_GZ\"\n",
      ">>> flt.cmdline # doctest: +ELLIPSIS\n",
      "'flirt -in structural.nii -ref mni.nii -out structural_flirt.nii.gz -omat structural_flirt.mat -bins 640 -searchcost mutualinfo'\n",
      ">>> res = flt.run() #doctest: +SKIP\n",
      "\n",
      "Inputs::\n",
      "\n",
      "        [Mandatory]\n",
      "        in_file: (a pathlike object or string representing an existing file)\n",
      "                input file\n",
      "                argument: ``-in %s``, position: 0\n",
      "        reference: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                reference file\n",
      "                argument: ``-ref %s``, position: 1\n",
      "\n",
      "        [Optional]\n",
      "        out_file: (a pathlike object or string representing a file)\n",
      "                registered output file\n",
      "                argument: ``-out %s``, position: 2\n",
      "        out_matrix_file: (a pathlike object or string representing a file)\n",
      "                output affine matrix in 4x4 asciii format\n",
      "                argument: ``-omat %s``, position: 3\n",
      "        out_log: (a pathlike object or string representing a file)\n",
      "                output log\n",
      "                requires: save_log\n",
      "        in_matrix_file: (a pathlike object or string representing a file)\n",
      "                input 4x4 affine matrix\n",
      "                argument: ``-init %s``\n",
      "        apply_xfm: (a boolean)\n",
      "                apply transformation supplied by in_matrix_file or uses_qform to use\n",
      "                the affine matrix stored in the reference header\n",
      "                argument: ``-applyxfm``\n",
      "        apply_isoxfm: (a float)\n",
      "                as applyxfm but forces isotropic resampling\n",
      "                argument: ``-applyisoxfm %f``\n",
      "                mutually_exclusive: apply_xfm\n",
      "        datatype: ('char' or 'short' or 'int' or 'float' or 'double')\n",
      "                force output data type\n",
      "                argument: ``-datatype %s``\n",
      "        cost: ('mutualinfo' or 'corratio' or 'normcorr' or 'normmi' or\n",
      "                  'leastsq' or 'labeldiff' or 'bbr')\n",
      "                cost function\n",
      "                argument: ``-cost %s``\n",
      "        cost_func: ('mutualinfo' or 'corratio' or 'normcorr' or 'normmi' or\n",
      "                  'leastsq' or 'labeldiff' or 'bbr')\n",
      "                cost function\n",
      "                argument: ``-searchcost %s``\n",
      "        uses_qform: (a boolean)\n",
      "                initialize using sform or qform\n",
      "                argument: ``-usesqform``\n",
      "        display_init: (a boolean)\n",
      "                display initial matrix\n",
      "                argument: ``-displayinit``\n",
      "        angle_rep: ('quaternion' or 'euler')\n",
      "                representation of rotation angles\n",
      "                argument: ``-anglerep %s``\n",
      "        interp: ('trilinear' or 'nearestneighbour' or 'sinc' or 'spline')\n",
      "                final interpolation method used in reslicing\n",
      "                argument: ``-interp %s``\n",
      "        sinc_width: (an integer)\n",
      "                full-width in voxels\n",
      "                argument: ``-sincwidth %d``\n",
      "        sinc_window: ('rectangular' or 'hanning' or 'blackman')\n",
      "                sinc window\n",
      "                argument: ``-sincwindow %s``\n",
      "        bins: (an integer)\n",
      "                number of histogram bins\n",
      "                argument: ``-bins %d``\n",
      "        dof: (an integer)\n",
      "                number of transform degrees of freedom\n",
      "                argument: ``-dof %d``\n",
      "        no_resample: (a boolean)\n",
      "                do not change input sampling\n",
      "                argument: ``-noresample``\n",
      "        force_scaling: (a boolean)\n",
      "                force rescaling even for low-res images\n",
      "                argument: ``-forcescaling``\n",
      "        min_sampling: (a float)\n",
      "                set minimum voxel dimension for sampling\n",
      "                argument: ``-minsampling %f``\n",
      "        padding_size: (an integer)\n",
      "                for applyxfm: interpolates outside image by size\n",
      "                argument: ``-paddingsize %d``\n",
      "        searchr_x: (a list of from 2 to 2 items which are an integer)\n",
      "                search angles along x-axis, in degrees\n",
      "                argument: ``-searchrx %s``\n",
      "        searchr_y: (a list of from 2 to 2 items which are an integer)\n",
      "                search angles along y-axis, in degrees\n",
      "                argument: ``-searchry %s``\n",
      "        searchr_z: (a list of from 2 to 2 items which are an integer)\n",
      "                search angles along z-axis, in degrees\n",
      "                argument: ``-searchrz %s``\n",
      "        no_search: (a boolean)\n",
      "                set all angular searches to ranges 0 to 0\n",
      "                argument: ``-nosearch``\n",
      "        coarse_search: (an integer)\n",
      "                coarse search delta angle\n",
      "                argument: ``-coarsesearch %d``\n",
      "        fine_search: (an integer)\n",
      "                fine search delta angle\n",
      "                argument: ``-finesearch %d``\n",
      "        schedule: (a pathlike object or string representing an existing file)\n",
      "                replaces default schedule\n",
      "                argument: ``-schedule %s``\n",
      "        ref_weight: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                File for reference weighting volume\n",
      "                argument: ``-refweight %s``\n",
      "        in_weight: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                File for input weighting volume\n",
      "                argument: ``-inweight %s``\n",
      "        no_clamp: (a boolean)\n",
      "                do not use intensity clamping\n",
      "                argument: ``-noclamp``\n",
      "        no_resample_blur: (a boolean)\n",
      "                do not use blurring on downsampling\n",
      "                argument: ``-noresampblur``\n",
      "        rigid2D: (a boolean)\n",
      "                use 2D rigid body mode - ignores dof\n",
      "                argument: ``-2D``\n",
      "        save_log: (a boolean)\n",
      "                save to log file\n",
      "        verbose: (an integer)\n",
      "                verbose mode, 0 is least\n",
      "                argument: ``-verbose %d``\n",
      "        bgvalue: (a float)\n",
      "                use specified background value for points outside FOV\n",
      "                argument: ``-setbackground %f``\n",
      "        wm_seg: (a pathlike object or string representing a file)\n",
      "                white matter segmentation volume needed by BBR cost function\n",
      "                argument: ``-wmseg %s``\n",
      "        wmcoords: (a pathlike object or string representing a file)\n",
      "                white matter boundary coordinates for BBR cost function\n",
      "                argument: ``-wmcoords %s``\n",
      "        wmnorms: (a pathlike object or string representing a file)\n",
      "                white matter boundary normals for BBR cost function\n",
      "                argument: ``-wmnorms %s``\n",
      "        fieldmap: (a pathlike object or string representing a file)\n",
      "                fieldmap image in rads/s - must be already registered to the\n",
      "                reference image\n",
      "                argument: ``-fieldmap %s``\n",
      "        fieldmapmask: (a pathlike object or string representing a file)\n",
      "                mask for fieldmap image\n",
      "                argument: ``-fieldmapmask %s``\n",
      "        pedir: (an integer)\n",
      "                phase encode direction of EPI - 1/2/3=x/y/z & -1/-2/-3=-x/-y/-z\n",
      "                argument: ``-pedir %d``\n",
      "        echospacing: (a float)\n",
      "                value of EPI echo spacing - units of seconds\n",
      "                argument: ``-echospacing %f``\n",
      "        bbrtype: ('signed' or 'global_abs' or 'local_abs')\n",
      "                type of bbr cost function: signed [default], global_abs, local_abs\n",
      "                argument: ``-bbrtype %s``\n",
      "        bbrslope: (a float)\n",
      "                value of bbr slope\n",
      "                argument: ``-bbrslope %f``\n",
      "        output_type: ('NIFTI' or 'NIFTI_PAIR' or 'NIFTI_GZ' or\n",
      "                  'NIFTI_PAIR_GZ')\n",
      "                FSL output type\n",
      "        args: (a string)\n",
      "                Additional parameters to the command\n",
      "                argument: ``%s``\n",
      "        environ: (a dictionary with keys which are a bytes or None or a value\n",
      "                  of class 'str' and with values which are a bytes or None or a\n",
      "                  value of class 'str', nipype default value: {})\n",
      "                Environment variables\n",
      "\n",
      "Outputs::\n",
      "\n",
      "        out_file: (a pathlike object or string representing an existing file)\n",
      "                path/name of registered file (if generated)\n",
      "        out_matrix_file: (a pathlike object or string representing an\n",
      "                  existing file)\n",
      "                path/name of calculated affine transform (if generated)\n",
      "        out_log: (a pathlike object or string representing a file)\n",
      "                path/name of output log (if generated)\n",
      "\n",
      "References:\n",
      "-----------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "FLIRT.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17edea11",
   "metadata": {},
   "source": [
    "#### Coregister structural image to mean functional (FS)\n",
    "\n",
    "not done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "202b0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrast_type = 't2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5c84d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if coreg_method == 'freesurfer':\n",
    "#     #coreg = Node(MRICoreg(),name='coreg')\n",
    "    \n",
    "#     coreg = Node(BBRegister(contrast_type=contrast_type),name='coreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "af4eb926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if coreg_method == 'freesurfer':\n",
    "#     wf.connect([(convertT1ToNii, coreg,[('out_file', 'source_file')])])\n",
    "#     if manual_edits:\n",
    "#         wf.connect([(datasourceManualEdits, coreg,[('coreg_itksnap_txt','init_reg_file')])])\n",
    "            \n",
    "#     wf.connect([(meanFunc, coreg,[('mean_img', 'source_file')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5e5c0de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BBRegister.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab9023",
   "metadata": {},
   "source": [
    "#### Coregister structural image to mean functional (apply manual ITK-snap correction)\n",
    "https://layerfmri.com/2019/02/11/high-quality-registration/\n",
    "\n",
    "\n",
    "##### Mandatory inputs\n",
    "input_image (a pathlike object or string representing an existing file) – Image to apply transformation to (generally a coregistered functional). Maps to a command-line argument: --input %s.\n",
    "\n",
    "reference_image (a pathlike object or string representing an existing file) – Reference image space that you wish to warp INTO. Maps to a command-line argument: --reference-image %s.\n",
    "\n",
    "transforms (a list of items which are a pathlike object or string representing an existing file or ‘identity’) – Transform files: will be applied in reverse order. For example, the last specified transform will be applied first. Maps to a command-line argument: %s.\n",
    "\n",
    "##### Optional inputs\n",
    "args (a string) – Additional parameters to the command. Maps to a command-line argument: %s.\n",
    "\n",
    "default_value (a float) – Maps to a command-line argument: --default-value %g. (Nipype default value: 0.0)\n",
    "\n",
    "dimension (2 or 3 or 4) – This option forces the image to be treated as a specified-dimensional image. If not specified, antsWarp tries to infer the dimensionality from the input image. Maps to a command-line argument: --dimensionality %d.\n",
    "\n",
    "environ (a dictionary with keys which are a bytes or None or a value of class ‘str’ and with values which are a bytes or None or a value of class ‘str’) – Environment variables. (Nipype default value: {})\n",
    "\n",
    "float (a boolean) – Use float instead of double for computations. Maps to a command-line argument: --float %d. (Nipype default value: False)\n",
    "\n",
    "input_image_type (0 or 1 or 2 or 3) – Option specifying the input image type of scalar (default), vector, tensor, or time series. Maps to a command-line argument: --input-image-type %d.\n",
    "\n",
    "interpolation (‘Linear’ or ‘NearestNeighbor’ or ‘CosineWindowedSinc’ or ‘WelchWindowedSinc’ or ‘HammingWindowedSinc’ or ‘LanczosWindowedSinc’ or ‘MultiLabel’ or ‘Gaussian’ or ‘BSpline’) – Maps to a command-line argument: %s. (Nipype default value: Linear)\n",
    "\n",
    "interpolation_parameters (a tuple of the form: (an integer) or a tuple of the form: (a float, a float))\n",
    "\n",
    "invert_transform_flags (a list of items which are a boolean)\n",
    "\n",
    "num_threads (an integer) – Number of ITK threads to use. (Nipype default value: 1)\n",
    "\n",
    "out_postfix (a string) – Postfix that is appended to all output files (default = _trans). (Nipype default value: _trans)\n",
    "\n",
    "output_image (a string) – Output file name. Maps to a command-line argument: --output %s.\n",
    "\n",
    "print_out_composite_warp_file (a boolean) – Output a composite warp file instead of a transformed image. Requires inputs: output_image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b1b370c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#antsApplyTransforms --interpolation BSpline[5] -d 3 -i MP2RAGE.nii -r EPI.nii -t initial_matrix.txt -o registered_applied.nii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "92454d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation = 'BSpline'\n",
    "input_image_type = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9d6e969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if coregister and coreg_method == 'itk-snap':\n",
    "    coreg = Node(ApplyTransforms(interpolation=interpolation,\n",
    "                                input_image_type=input_image_type), name='coreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "076b8a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if coregister and coreg_method == 'itk-snap':\n",
    "    wf.connect([(datasource, coreg,[('T1', 'input_image')])])        \n",
    "    wf.connect([(meanFunc, coreg,[('mean_img', 'reference_image')])])  \n",
    "\n",
    "    wf.connect([(datasourceManualEdits, coreg,[('coreg_itksnap_struct2func_txt', 'transforms')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6bf8c3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps the executable command ``antsApplyTransforms``.\n",
      "\n",
      "ApplyTransforms, applied to an input image, transforms it according to a\n",
      "reference image and a transform (or a set of transforms).\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      ">>> from nipype.interfaces.ants import ApplyTransforms\n",
      ">>> at = ApplyTransforms()\n",
      ">>> at.inputs.input_image = 'moving1.nii'\n",
      ">>> at.inputs.reference_image = 'fixed1.nii'\n",
      ">>> at.inputs.transforms = 'identity'\n",
      ">>> at.cmdline\n",
      "'antsApplyTransforms --default-value 0 --float 0 --input moving1.nii --interpolation Linear --output moving1_trans.nii --reference-image fixed1.nii --transform identity'\n",
      "\n",
      ">>> at = ApplyTransforms()\n",
      ">>> at.inputs.dimension = 3\n",
      ">>> at.inputs.input_image = 'moving1.nii'\n",
      ">>> at.inputs.reference_image = 'fixed1.nii'\n",
      ">>> at.inputs.output_image = 'deformed_moving1.nii'\n",
      ">>> at.inputs.interpolation = 'Linear'\n",
      ">>> at.inputs.default_value = 0\n",
      ">>> at.inputs.transforms = ['ants_Warp.nii.gz', 'trans.mat']\n",
      ">>> at.inputs.invert_transform_flags = [False, True]\n",
      ">>> at.cmdline\n",
      "'antsApplyTransforms --default-value 0 --dimensionality 3 --float 0 --input moving1.nii --interpolation Linear --output deformed_moving1.nii --reference-image fixed1.nii --transform ants_Warp.nii.gz --transform [ trans.mat, 1 ]'\n",
      "\n",
      ">>> at1 = ApplyTransforms()\n",
      ">>> at1.inputs.dimension = 3\n",
      ">>> at1.inputs.input_image = 'moving1.nii'\n",
      ">>> at1.inputs.reference_image = 'fixed1.nii'\n",
      ">>> at1.inputs.output_image = 'deformed_moving1.nii'\n",
      ">>> at1.inputs.interpolation = 'BSpline'\n",
      ">>> at1.inputs.interpolation_parameters = (5,)\n",
      ">>> at1.inputs.default_value = 0\n",
      ">>> at1.inputs.transforms = ['ants_Warp.nii.gz', 'trans.mat']\n",
      ">>> at1.inputs.invert_transform_flags = [False, False]\n",
      ">>> at1.cmdline\n",
      "'antsApplyTransforms --default-value 0 --dimensionality 3 --float 0 --input moving1.nii --interpolation BSpline[ 5 ] --output deformed_moving1.nii --reference-image fixed1.nii --transform ants_Warp.nii.gz --transform trans.mat'\n",
      "\n",
      "Identity transforms may be used as part of a chain:\n",
      "\n",
      ">>> at2 = ApplyTransforms()\n",
      ">>> at2.inputs.dimension = 3\n",
      ">>> at2.inputs.input_image = 'moving1.nii'\n",
      ">>> at2.inputs.reference_image = 'fixed1.nii'\n",
      ">>> at2.inputs.output_image = 'deformed_moving1.nii'\n",
      ">>> at2.inputs.interpolation = 'BSpline'\n",
      ">>> at2.inputs.interpolation_parameters = (5,)\n",
      ">>> at2.inputs.default_value = 0\n",
      ">>> at2.inputs.transforms = ['identity', 'ants_Warp.nii.gz', 'trans.mat']\n",
      ">>> at2.cmdline\n",
      "'antsApplyTransforms --default-value 0 --dimensionality 3 --float 0 --input moving1.nii --interpolation BSpline[ 5 ] --output deformed_moving1.nii --reference-image fixed1.nii --transform identity --transform ants_Warp.nii.gz --transform trans.mat'\n",
      "\n",
      "Inputs::\n",
      "\n",
      "        [Mandatory]\n",
      "        input_image: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                image to apply transformation to (generally a coregistered\n",
      "                functional)\n",
      "                argument: ``--input %s``\n",
      "        reference_image: (a pathlike object or string representing an\n",
      "                  existing file)\n",
      "                reference image space that you wish to warp INTO\n",
      "                argument: ``--reference-image %s``\n",
      "        transforms: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file or 'identity')\n",
      "                transform files: will be applied in reverse order. For example, the\n",
      "                last specified transform will be applied first.\n",
      "                argument: ``%s``\n",
      "\n",
      "        [Optional]\n",
      "        dimension: (2 or 3 or 4)\n",
      "                This option forces the image to be treated as a specified-\n",
      "                dimensional image. If not specified, antsWarp tries to infer the\n",
      "                dimensionality from the input image.\n",
      "                argument: ``--dimensionality %d``\n",
      "        input_image_type: (0 or 1 or 2 or 3)\n",
      "                Option specifying the input image type of scalar (default), vector,\n",
      "                tensor, or time series.\n",
      "                argument: ``--input-image-type %d``\n",
      "        output_image: (a string)\n",
      "                output file name\n",
      "                argument: ``--output %s``\n",
      "        out_postfix: (a string, nipype default value: _trans)\n",
      "                Postfix that is appended to all output files (default = _trans)\n",
      "        interpolation: ('Linear' or 'NearestNeighbor' or 'CosineWindowedSinc'\n",
      "                  or 'WelchWindowedSinc' or 'HammingWindowedSinc' or\n",
      "                  'LanczosWindowedSinc' or 'MultiLabel' or 'Gaussian' or 'BSpline',\n",
      "                  nipype default value: Linear)\n",
      "                argument: ``%s``\n",
      "        interpolation_parameters: (a tuple of the form: (an integer) or a\n",
      "                  tuple of the form: (a float, a float))\n",
      "        invert_transform_flags: (a list of items which are a boolean)\n",
      "        default_value: (a float, nipype default value: 0.0)\n",
      "                argument: ``--default-value %g``\n",
      "        print_out_composite_warp_file: (a boolean)\n",
      "                output a composite warp file instead of a transformed image\n",
      "                requires: output_image\n",
      "        float: (a boolean, nipype default value: False)\n",
      "                Use float instead of double for computations.\n",
      "                argument: ``--float %d``\n",
      "        num_threads: (an integer, nipype default value: 1)\n",
      "                Number of ITK threads to use\n",
      "        args: (a string)\n",
      "                Additional parameters to the command\n",
      "                argument: ``%s``\n",
      "        environ: (a dictionary with keys which are a bytes or None or a value\n",
      "                  of class 'str' and with values which are a bytes or None or a\n",
      "                  value of class 'str', nipype default value: {})\n",
      "                Environment variables\n",
      "\n",
      "Outputs::\n",
      "\n",
      "        output_image: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                Warped image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ApplyTransforms.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda37120",
   "metadata": {},
   "source": [
    "#### Coregister mean functional to anatomical image (ANTs)\n",
    "https://layerfmri.com/2019/02/11/high-quality-registration/\n",
    "\n",
    "antsRegistration \\\n",
    "--verbose 1 \\\n",
    "--dimensionality 3 \\\n",
    "--float 1 \\\n",
    "--output [registered_,registered_Warped.nii.gz,registered_InverseWarped.nii.gz] \\\n",
    "--interpolation Linear \\\n",
    "--use-histogram-matching 0 \\\n",
    "--winsorize-image-intensities [0.005,0.995] \\\n",
    "--initial-moving-transform initial_matrix.txt \\\n",
    "--transform Rigid[0.05] \\\n",
    "--metric CC[static_image.nii,moving_image.nii,0.7,32,Regular,0.1] \\\n",
    "--convergence [1000x500,1e-6,10] \\\n",
    "--shrink-factors 2x1 \\\n",
    "--smoothing-sigmas 1x0vox \\\n",
    "--transform Affine[0.1] \\\n",
    "--metric MI[static_image.nii,moving_image.nii,0.7,32,Regular,0.1] \\\n",
    "--convergence [1000x500,1e-6,10] \\\n",
    "--shrink-factors 2x1 \\\n",
    "--smoothing-sigmas 1x0vox \\\n",
    "--transform SyN[0.1,2,0] \\\n",
    "--metric CC[static_image.nii,moving_image.nii,1,2] \\\n",
    "--convergence [500x100,1e-6,10] \\\n",
    "--shrink-factors 2x1 \\\n",
    "--smoothing-sigmas 1x0vox \\\n",
    "-x mask.nii\n",
    "\n",
    "\n",
    "See also: https://github.com/ANTsX/ANTs/wiki/Anatomy-of-an-antsRegistration-call\n",
    "\n",
    "about masking: https://github.com/ANTsX/ANTs/issues/483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "86cdc4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True                          # (a boolean, nipype default value: False)\n",
    "                                        # argument: ``-v``\n",
    "    \n",
    "dimension = 3                           # dimension: (3 or 2, nipype default value: 3)\n",
    "                                        # image dimension (2 or 3)\n",
    "                                        # argument: ``--dimensionality %d``\n",
    "        \n",
    "float = True                            # (a boolean)\n",
    "                                        # Use float instead of double for computations.\n",
    "                                        # argument: ``--float %d``\n",
    "        \n",
    "output_transform_prefix = 'registered_' # (a string, nipype default value: transform)\n",
    "                                        # argument: ``%s``\n",
    "    \n",
    "output_warped_image = 'registered_Warped.nii.gz'              \n",
    "                                        # (a boolean or a pathlike object or string\n",
    "                                        # representing a file)\n",
    "    \n",
    "output_inverse_warped_image = 'registered_InverseWarped.nii.gz'       \n",
    "                                        # (a boolean or a pathlike object or\n",
    "                                        # string representing a file)\n",
    "                                        # requires: output_warped_image\n",
    "        \n",
    "interpolation = 'Linear'                # ('Linear' or 'NearestNeighbor' or 'CosineWindowedSinc'\n",
    "                                        # or 'WelchWindowedSinc' or 'HammingWindowedSinc' or\n",
    "                                        # 'LanczosWindowedSinc' or 'BSpline' or 'MultiLabel' or 'Gaussian',\n",
    "                                        # nipype default value: Linear)\n",
    "                                        # argument: ``%s``   \n",
    "                \n",
    "use_histogram_matching = False          #  (a boolean or a list of items which are a\n",
    "                                        # boolean, nipype default value: True)\n",
    "                                        # Histogram match the images before registration. \n",
    "        \n",
    "winsorize_lower_quantile = 0.005        # (0.0 <= a floating point number <= 1.0,\n",
    "                                        # nipype default value: 0.0)\n",
    "                                        # The Lower quantile to clip image ranges\n",
    "                                        # argument: ``%s``\n",
    "            \n",
    "winsorize_upper_quantile = 0.995        # (0.0 <= a floating point number <= 1.0,\n",
    "                                        # nipype default value: 1.0)\n",
    "                                        # The Upper quantile to clip image ranges\n",
    "                                        # argument: ``%s``\n",
    "            \n",
    "#initial_moving_transform = 'initial_matrix.txt'   # (a list of items which are an existing file\n",
    "                                        # name)\n",
    "                                        # A transform or a list of transforms that should be appliedbefore the\n",
    "                                        # registration begins. Note that, when a list is given,the\n",
    "                                        # transformations are applied in reverse order.\n",
    "                                        # argument: ``%s``\n",
    "                                        # mutually_exclusive: initial_moving_transform_com\n",
    "                        \n",
    "transforms = ['Rigid','Affine','SyN']   # (a list of items which are 'Rigid' or 'Affine' or\n",
    "                                        # 'CompositeAffine' or 'Similarity' or 'Translation' or 'BSpline' or\n",
    "                                        # 'GaussianDisplacementField' or 'TimeVaryingVelocityField' or\n",
    "                                        # 'TimeVaryingBSplineVelocityField' or 'SyN' or 'BSplineSyN' or\n",
    "                                        # 'Exponential' or 'BSplineExponential')\n",
    "                                        # argument: ``%s``\n",
    "                    \n",
    "transform_parameters = [(0.1,), (0.1,), (0.1, 3.0, 0.0)]        \n",
    "                                        # (a list of items which are a tuple of the form:\n",
    "                                        # (a float) or a tuple of the form: (a float, a float, a float) or a\n",
    "                                        # tuple of the form: (a float, an integer (int or long), an integer\n",
    "                                        # (int or long), an integer (int or long)) or a tuple of the form:\n",
    "                                        # (a float, an integer (int or long), a float, a float, a float, a\n",
    "                                        # float) or a tuple of the form: (a float, a float, a float, an\n",
    "                                        # integer (int or long)) or a tuple of the form: (a float, an\n",
    "                                        # integer (int or long), an integer (int or long), an integer (int\n",
    "                                        # or long), an integer (int or long)))\n",
    "                                \n",
    "metric = ['MI', 'MI', 'CC']             # (a list of items which are 'CC' or 'MeanSquares' or 'Demons'\n",
    "                                        # or 'GC' or 'MI' or 'Mattes' or a list of items which are 'CC' or\n",
    "                                        # 'MeanSquares' or 'Demons' or 'GC' or 'MI' or 'Mattes')\n",
    "                                        # the metric(s) to use for each stage. Note that multiple metrics per\n",
    "                                        # stage are not supported in ANTS 1.9.1 and earlier.\n",
    "                \n",
    "metric_weight = [1.0,1.0,1.0]           # (a list of items which are a float or a list of items\n",
    "                                        # which are a float, nipype default value: [1.0])\n",
    "                                        # the metric weight(s) for each stage. The weights must sum to 1 per\n",
    "                                        # stage.\n",
    "                                        # requires: metric\n",
    "                \n",
    "radius_or_number_of_bins = [32,32,4]    # (a list of items which are an integer (int\n",
    "                                        # or long) or a list of items which are an integer (int or long),\n",
    "                                        # nipype default value: [5])\n",
    "                                        # the number of bins in each stage for the MI and Mattes metric, the\n",
    "                                        # radius for other metrics\n",
    "                                        # requires: metric_weight\n",
    "                    \n",
    "sampling_strategy = ['Regular','Regular','None']              \n",
    "                                        # (a list of items which are 'None' or 'Regular' or\n",
    "                                        # 'Random' or None or a list of items which are 'None' or 'Regular'\n",
    "                                        # or 'Random' or None)\n",
    "                                        # the metric sampling strategy (strategies) for each stage\n",
    "                                        # requires: metric_weight\n",
    "                \n",
    "sampling_percentage = [0.25, 0.25, None]         \n",
    "                                        # (a list of items which are 0.0 <= a floating\n",
    "                                        # point number <= 1.0 or None or a list of items which are 0.0 <= a\n",
    "                                        # floating point number <= 1.0 or None)\n",
    "                                        # the metric sampling percentage(s) to use for each stage\n",
    "                                        # requires: sampling_strategy\n",
    "                \n",
    "convergence_threshold = [1e-6,1e-6,1e-6]# (a list of at least 1 items which are a float,\n",
    "                                        # nipype default value: [1e-06])\n",
    "                                        # requires: number_of_iterations\n",
    "        \n",
    "convergence_window_size = [10,10,10]    # (a list of at least 1 items which are an\n",
    "                                        # integer (int or long), nipype default value: [10])\n",
    "                                        # requires: convergence_threshold\n",
    "        \n",
    "number_of_iterations = [[1000,500,250,100], [1000,500,250,100],[100,70,50,20]]       \n",
    "                                        # (a list of items which are a list of items\n",
    "                                        # which are an integer (int or long))                \n",
    "                                        \n",
    "shrink_factors = [[8,4,2,1], [8,4,2,1], [8,4,2,1]]  \n",
    "                                        # (a list of items which are a list of items which are\n",
    "                                        # an integer (int or long))\n",
    "    \n",
    "smoothing_sigmas = [[3.0,2.0,1.0,0.0], [3.0,2.0,1.0,0.0], [3.0,2.0,1.0,0.0]]\n",
    "                                        # (a list of items which are a list of items which\n",
    "                                        # are a float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "62114e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if coregister and not precalc_coreg and coreg_method == 'antsRegistration':\n",
    "    coreg = Node(Registration(verbose=verbose,\n",
    "                              dimension=dimension,\n",
    "                              float=float,\n",
    "                              output_transform_prefix=output_transform_prefix,\n",
    "                              output_warped_image=output_warped_image,\n",
    "                              output_inverse_warped_image=output_inverse_warped_image,\n",
    "                              interpolation=interpolation, \n",
    "                              use_histogram_matching=use_histogram_matching,\n",
    "                              winsorize_lower_quantile=winsorize_lower_quantile,\n",
    "                              winsorize_upper_quantile=winsorize_upper_quantile, \n",
    "                              transforms=transforms, \n",
    "                              transform_parameters=transform_parameters,\n",
    "                              metric=metric, \n",
    "                              metric_weight=metric_weight, \n",
    "                              radius_or_number_of_bins=radius_or_number_of_bins,\n",
    "                              sampling_strategy=sampling_strategy, \n",
    "                              sampling_percentage=sampling_percentage,\n",
    "                              convergence_threshold=convergence_threshold, \n",
    "                              convergence_window_size=convergence_window_size,\n",
    "                              number_of_iterations=number_of_iterations, \n",
    "                              shrink_factors=shrink_factors, \n",
    "                              smoothing_sigmas=smoothing_sigmas),\n",
    "                 name='coreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a4615bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if coregister and not precalc_coreg and coreg_method == 'antsRegistration':\n",
    "    if coreg_dir == 'func2struct':\n",
    "        # when moving func 2 struct\n",
    "        wf.connect([(datasource, coreg,[('UNI', 'fixed_image')])])    \n",
    "        wf.connect([(meanFunc, coreg,[('mean_img', 'moving_image')])])\n",
    "        wf.connect([(datasourceManualEdits, coreg,[('coreg_itksnap_func2struct_txt', 'initial_moving_transform')])])    \n",
    "        #wf.connect([(datasource, coreg,[('brainmask', 'fixed_image_masks')])])\n",
    "        wf.connect([(datasourceManualEdits, coreg,[('manual_midoccmask', 'fixed_image_masks')])])\n",
    "        \n",
    "    elif coreg_dir == 'struct2func':\n",
    "        # when moving struct 2 func:\n",
    "        wf.connect([(meanFunc, coreg,[('mean_img', 'fixed_image')])]) \n",
    "        wf.connect([(datasource, coreg,[('UNI', 'moving_image')])])\n",
    "        wf.connect([(datasourceManualEdits, coreg,[('coreg_itksnap_struct2func_txt', 'initial_moving_transform')])])\n",
    "        #wf.connect([(datasource, coreg,[('brainmask', 'moving_image_masks')])])\n",
    "        wf.connect([(datasourceManualEdits, coreg,[('manual_midoccmask', 'moving_image_masks')])])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "342d3511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps the executable command ``antsRegistration``.\n",
      "\n",
      "ANTs Registration command for registration of images\n",
      "\n",
      "`antsRegistration <http://stnava.github.io/ANTs/>`_ registers a ``moving_image`` to a ``fixed_image``,\n",
      "using a predefined (sequence of) cost function(s) and transformation operations.\n",
      "The cost function is defined using one or more 'metrics', specifically\n",
      "local cross-correlation (``CC``), Mean Squares (``MeanSquares``), Demons (``Demons``),\n",
      "global correlation (``GC``), or Mutual Information (``Mattes`` or ``MI``).\n",
      "\n",
      "ANTS can use both linear (``Translation``, ``Rigid``, ``Affine``, ``CompositeAffine``,\n",
      "or ``Translation``) and non-linear transformations (``BSpline``, ``GaussianDisplacementField``,\n",
      "``TimeVaryingVelocityField``, ``TimeVaryingBSplineVelocityField``, ``SyN``, ``BSplineSyN``,\n",
      "``Exponential``, or ``BSplineExponential``). Usually, registration is done in multiple\n",
      "*stages*. For example first an Affine, then a Rigid, and ultimately a non-linear\n",
      "(Syn)-transformation.\n",
      "\n",
      "antsRegistration can be initialized using one ore more transforms from moving_image\n",
      "to fixed_image with the ``initial_moving_transform``-input. For example, when you\n",
      "already have a warpfield that corrects for geometrical distortions in an EPI (functional) image,\n",
      "that you want to apply before an Affine registration to a structural image.\n",
      "You could put this transform into 'intial_moving_transform'.\n",
      "\n",
      "The Registration-interface can output the resulting transform(s) that map moving_image to\n",
      "fixed_image in a single file as a ``composite_transform`` (if ``write_composite_transform``\n",
      "is set to ``True``), or a list of transforms as ``forwards_transforms``. It can also output\n",
      "inverse transforms (from ``fixed_image`` to ``moving_image``) in a similar fashion using\n",
      "``inverse_composite_transform``. Note that the order of ``forward_transforms`` is in 'natural'\n",
      "order: the first element should be applied first, the last element should be applied last.\n",
      "\n",
      "Note, however, that ANTS tools always apply lists of transformations in reverse order (the last\n",
      "transformation in the list is applied first). Therefore, if the output forward_transforms\n",
      "is a list, one can not directly feed it into, for example, ``ants.ApplyTransforms``. To\n",
      "make ``ants.ApplyTransforms`` apply the transformations in the same order as ``ants.Registration``,\n",
      "you have to provide the list of transformations in reverse order from ``forward_transforms``.\n",
      "``reverse_forward_transforms`` outputs ``forward_transforms`` in reverse order and can be used for\n",
      "this purpose. Note also that, because ``composite_transform`` is always a single file, this\n",
      "output is preferred for  most use-cases.\n",
      "\n",
      "More information can be found in the `ANTS\n",
      "manual <https://sourceforge.net/projects/advants/files/Documentation/ants.pdf/download>`_.\n",
      "\n",
      "See below for some useful examples.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "Set up a Registration node with some default settings. This Node registers\n",
      "'fixed1.nii' to 'moving1.nii' by first fitting a linear 'Affine' transformation, and\n",
      "then a non-linear 'SyN' transformation, both using the Mutual Information-cost\n",
      "metric.\n",
      "\n",
      "The registration is initialized by first applying the (linear) transform\n",
      "trans.mat.\n",
      "\n",
      ">>> import copy, pprint\n",
      ">>> from nipype.interfaces.ants import Registration\n",
      ">>> reg = Registration()\n",
      ">>> reg.inputs.fixed_image = 'fixed1.nii'\n",
      ">>> reg.inputs.moving_image = 'moving1.nii'\n",
      ">>> reg.inputs.output_transform_prefix = \"output_\"\n",
      ">>> reg.inputs.initial_moving_transform = 'trans.mat'\n",
      ">>> reg.inputs.transforms = ['Affine', 'SyN']\n",
      ">>> reg.inputs.transform_parameters = [(2.0,), (0.25, 3.0, 0.0)]\n",
      ">>> reg.inputs.number_of_iterations = [[1500, 200], [100, 50, 30]]\n",
      ">>> reg.inputs.dimension = 3\n",
      ">>> reg.inputs.write_composite_transform = True\n",
      ">>> reg.inputs.collapse_output_transforms = False\n",
      ">>> reg.inputs.initialize_transforms_per_stage = False\n",
      ">>> reg.inputs.metric = ['Mattes']*2\n",
      ">>> reg.inputs.metric_weight = [1]*2 # Default (value ignored currently by ANTs)\n",
      ">>> reg.inputs.radius_or_number_of_bins = [32]*2\n",
      ">>> reg.inputs.sampling_strategy = ['Random', None]\n",
      ">>> reg.inputs.sampling_percentage = [0.05, None]\n",
      ">>> reg.inputs.convergence_threshold = [1.e-8, 1.e-9]\n",
      ">>> reg.inputs.convergence_window_size = [20]*2\n",
      ">>> reg.inputs.smoothing_sigmas = [[1,0], [2,1,0]]\n",
      ">>> reg.inputs.sigma_units = ['vox'] * 2\n",
      ">>> reg.inputs.shrink_factors = [[2,1], [3,2,1]]\n",
      ">>> reg.inputs.use_estimate_learning_rate_once = [True, True]\n",
      ">>> reg.inputs.use_histogram_matching = [True, True] # This is the default\n",
      ">>> reg.inputs.output_warped_image = 'output_warped_image.nii.gz'\n",
      ">>> reg.cmdline\n",
      "'antsRegistration --collapse-output-transforms 0 --dimensionality 3 --initial-moving-transform [ trans.mat, 0 ] --initialize-transforms-per-stage 0 --interpolation Linear --output [ output_, output_warped_image.nii.gz ] --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --transform SyN[ 0.25, 3.0, 0.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --winsorize-image-intensities [ 0.0, 1.0 ]  --write-composite-transform 1'\n",
      ">>> reg.run()  # doctest: +SKIP\n",
      "\n",
      "Same as reg1, but first invert the initial transform ('trans.mat') before applying it.\n",
      "\n",
      ">>> reg.inputs.invert_initial_moving_transform = True\n",
      ">>> reg1 = copy.deepcopy(reg)\n",
      ">>> reg1.inputs.winsorize_lower_quantile = 0.025\n",
      ">>> reg1.cmdline\n",
      "'antsRegistration --collapse-output-transforms 0 --dimensionality 3 --initial-moving-transform [ trans.mat, 1 ] --initialize-transforms-per-stage 0 --interpolation Linear --output [ output_, output_warped_image.nii.gz ] --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --transform SyN[ 0.25, 3.0, 0.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --winsorize-image-intensities [ 0.025, 1.0 ]  --write-composite-transform 1'\n",
      ">>> reg1.run()  # doctest: +SKIP\n",
      "\n",
      "Clip extremely high intensity data points using winsorize_upper_quantile. All data points\n",
      "higher than the 0.975 quantile are set to the value of the 0.975 quantile.\n",
      "\n",
      ">>> reg2 = copy.deepcopy(reg)\n",
      ">>> reg2.inputs.winsorize_upper_quantile = 0.975\n",
      ">>> reg2.cmdline\n",
      "'antsRegistration --collapse-output-transforms 0 --dimensionality 3 --initial-moving-transform [ trans.mat, 1 ] --initialize-transforms-per-stage 0 --interpolation Linear --output [ output_, output_warped_image.nii.gz ] --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --transform SyN[ 0.25, 3.0, 0.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --winsorize-image-intensities [ 0.0, 0.975 ]  --write-composite-transform 1'\n",
      "\n",
      "Clip extremely low intensity data points using winsorize_lower_quantile. All data points\n",
      "lower than the 0.025 quantile are set to the original value at the 0.025 quantile.\n",
      "\n",
      "\n",
      ">>> reg3 = copy.deepcopy(reg)\n",
      ">>> reg3.inputs.winsorize_lower_quantile = 0.025\n",
      ">>> reg3.inputs.winsorize_upper_quantile = 0.975\n",
      ">>> reg3.cmdline\n",
      "'antsRegistration --collapse-output-transforms 0 --dimensionality 3 --initial-moving-transform [ trans.mat, 1 ] --initialize-transforms-per-stage 0 --interpolation Linear --output [ output_, output_warped_image.nii.gz ] --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --transform SyN[ 0.25, 3.0, 0.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --winsorize-image-intensities [ 0.025, 0.975 ]  --write-composite-transform 1'\n",
      "\n",
      "Use float instead of double for computations (saves memory usage)\n",
      "\n",
      ">>> reg3a = copy.deepcopy(reg)\n",
      ">>> reg3a.inputs.float = True\n",
      ">>> reg3a.cmdline\n",
      "'antsRegistration --collapse-output-transforms 0 --dimensionality 3 --float 1 --initial-moving-transform [ trans.mat, 1 ] --initialize-transforms-per-stage 0 --interpolation Linear --output [ output_, output_warped_image.nii.gz ] --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --transform SyN[ 0.25, 3.0, 0.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --winsorize-image-intensities [ 0.0, 1.0 ]  --write-composite-transform 1'\n",
      "\n",
      "Force to use double instead of float for computations (more precision and memory usage).\n",
      "\n",
      ">>> reg3b = copy.deepcopy(reg)\n",
      ">>> reg3b.inputs.float = False\n",
      ">>> reg3b.cmdline\n",
      "'antsRegistration --collapse-output-transforms 0 --dimensionality 3 --float 0 --initial-moving-transform [ trans.mat, 1 ] --initialize-transforms-per-stage 0 --interpolation Linear --output [ output_, output_warped_image.nii.gz ] --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --transform SyN[ 0.25, 3.0, 0.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --winsorize-image-intensities [ 0.0, 1.0 ]  --write-composite-transform 1'\n",
      "\n",
      "'collapse_output_transforms' can be used to put all transformation in a single 'composite_transform'-\n",
      "file. Note that forward_transforms will now be an empty list.\n",
      "\n",
      ">>> # Test collapse transforms flag\n",
      ">>> reg4 = copy.deepcopy(reg)\n",
      ">>> reg4.inputs.save_state = 'trans.mat'\n",
      ">>> reg4.inputs.restore_state = 'trans.mat'\n",
      ">>> reg4.inputs.initialize_transforms_per_stage = True\n",
      ">>> reg4.inputs.collapse_output_transforms = True\n",
      ">>> outputs = reg4._list_outputs()\n",
      ">>> pprint.pprint(outputs)  # doctest: +ELLIPSIS,\n",
      "{'composite_transform': '...data/output_Composite.h5',\n",
      " 'elapsed_time': <undefined>,\n",
      " 'forward_invert_flags': [],\n",
      " 'forward_transforms': [],\n",
      " 'inverse_composite_transform': '...data/output_InverseComposite.h5',\n",
      " 'inverse_warped_image': <undefined>,\n",
      " 'metric_value': <undefined>,\n",
      " 'reverse_forward_invert_flags': [],\n",
      " 'reverse_forward_transforms': [],\n",
      " 'reverse_invert_flags': [],\n",
      " 'reverse_transforms': [],\n",
      " 'save_state': '...data/trans.mat',\n",
      " 'warped_image': '...data/output_warped_image.nii.gz'}\n",
      ">>> reg4.cmdline\n",
      "'antsRegistration --collapse-output-transforms 1 --dimensionality 3 --initial-moving-transform [ trans.mat, 1 ] --initialize-transforms-per-stage 1 --interpolation Linear --output [ output_, output_warped_image.nii.gz ] --restore-state trans.mat --save-state trans.mat --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --transform SyN[ 0.25, 3.0, 0.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --winsorize-image-intensities [ 0.0, 1.0 ]  --write-composite-transform 1'\n",
      "\n",
      "\n",
      ">>> # Test collapse transforms flag\n",
      ">>> reg4b = copy.deepcopy(reg4)\n",
      ">>> reg4b.inputs.write_composite_transform = False\n",
      ">>> outputs = reg4b._list_outputs()\n",
      ">>> pprint.pprint(outputs)  # doctest: +ELLIPSIS,\n",
      "{'composite_transform': <undefined>,\n",
      " 'elapsed_time': <undefined>,\n",
      " 'forward_invert_flags': [False, False],\n",
      " 'forward_transforms': ['...data/output_0GenericAffine.mat',\n",
      " '...data/output_1Warp.nii.gz'],\n",
      " 'inverse_composite_transform': <undefined>,\n",
      " 'inverse_warped_image': <undefined>,\n",
      " 'metric_value': <undefined>,\n",
      " 'reverse_forward_invert_flags': [False, False],\n",
      " 'reverse_forward_transforms': ['...data/output_1Warp.nii.gz',\n",
      " '...data/output_0GenericAffine.mat'],\n",
      " 'reverse_invert_flags': [True, False],\n",
      " 'reverse_transforms': ['...data/output_0GenericAffine.mat',     '...data/output_1InverseWarp.nii.gz'],\n",
      " 'save_state': '...data/trans.mat',\n",
      " 'warped_image': '...data/output_warped_image.nii.gz'}\n",
      ">>> reg4b.aggregate_outputs()  # doctest: +SKIP\n",
      ">>> reg4b.cmdline\n",
      "'antsRegistration --collapse-output-transforms 1 --dimensionality 3 --initial-moving-transform [ trans.mat, 1 ] --initialize-transforms-per-stage 1 --interpolation Linear --output [ output_, output_warped_image.nii.gz ] --restore-state trans.mat --save-state trans.mat --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --transform SyN[ 0.25, 3.0, 0.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --winsorize-image-intensities [ 0.0, 1.0 ]  --write-composite-transform 0'\n",
      "\n",
      "One can use multiple similarity metrics in a single registration stage.The Node below first\n",
      "performs a linear registation using only the Mutual Information ('Mattes')-metric.\n",
      "In a second stage, it performs a non-linear registration ('Syn') using both a\n",
      "Mutual Information and a local cross-correlation ('CC')-metric. Both metrics are weighted\n",
      "equally ('metric_weight' is .5 for both). The Mutual Information- metric uses 32 bins.\n",
      "The local cross-correlations (correlations between every voxel's neighborhoods) is computed\n",
      "with a radius of 4.\n",
      "\n",
      ">>> # Test multiple metrics per stage\n",
      ">>> reg5 = copy.deepcopy(reg)\n",
      ">>> reg5.inputs.fixed_image = 'fixed1.nii'\n",
      ">>> reg5.inputs.moving_image = 'moving1.nii'\n",
      ">>> reg5.inputs.metric = ['Mattes', ['Mattes', 'CC']]\n",
      ">>> reg5.inputs.metric_weight = [1, [.5,.5]]\n",
      ">>> reg5.inputs.radius_or_number_of_bins = [32, [32, 4] ]\n",
      ">>> reg5.inputs.sampling_strategy = ['Random', None] # use default strategy in second stage\n",
      ">>> reg5.inputs.sampling_percentage = [0.05, [0.05, 0.10]]\n",
      ">>> reg5.cmdline\n",
      "'antsRegistration --collapse-output-transforms 0 --dimensionality 3 --initial-moving-transform [ trans.mat, 1 ] --initialize-transforms-per-stage 0 --interpolation Linear --output [ output_, output_warped_image.nii.gz ] --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --transform SyN[ 0.25, 3.0, 0.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 0.5, 32, None, 0.05 ] --metric CC[ fixed1.nii, moving1.nii, 0.5, 4, None, 0.1 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --winsorize-image-intensities [ 0.0, 1.0 ]  --write-composite-transform 1'\n",
      "\n",
      "ANTS Registration can also use multiple modalities to perform the registration. Here it is assumed\n",
      "that fixed1.nii and fixed2.nii are in the same space, and so are moving1.nii and\n",
      "moving2.nii. First, a linear registration is performed matching fixed1.nii to moving1.nii,\n",
      "then a non-linear registration is performed to match fixed2.nii to moving2.nii, starting from\n",
      "the transformation of the first step.\n",
      "\n",
      ">>> # Test multiple inputS\n",
      ">>> reg6 = copy.deepcopy(reg5)\n",
      ">>> reg6.inputs.fixed_image = ['fixed1.nii', 'fixed2.nii']\n",
      ">>> reg6.inputs.moving_image = ['moving1.nii', 'moving2.nii']\n",
      ">>> reg6.cmdline\n",
      "'antsRegistration --collapse-output-transforms 0 --dimensionality 3 --initial-moving-transform [ trans.mat, 1 ] --initialize-transforms-per-stage 0 --interpolation Linear --output [ output_, output_warped_image.nii.gz ] --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --transform SyN[ 0.25, 3.0, 0.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 0.5, 32, None, 0.05 ] --metric CC[ fixed2.nii, moving2.nii, 0.5, 4, None, 0.1 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --winsorize-image-intensities [ 0.0, 1.0 ]  --write-composite-transform 1'\n",
      "\n",
      "Different methods can be used for the interpolation when applying transformations.\n",
      "\n",
      ">>> # Test Interpolation Parameters (BSpline)\n",
      ">>> reg7a = copy.deepcopy(reg)\n",
      ">>> reg7a.inputs.interpolation = 'BSpline'\n",
      ">>> reg7a.inputs.interpolation_parameters = (3,)\n",
      ">>> reg7a.cmdline\n",
      "'antsRegistration --collapse-output-transforms 0 --dimensionality 3 --initial-moving-transform [ trans.mat, 1 ] --initialize-transforms-per-stage 0 --interpolation BSpline[ 3 ] --output [ output_, output_warped_image.nii.gz ] --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --transform SyN[ 0.25, 3.0, 0.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --winsorize-image-intensities [ 0.0, 1.0 ]  --write-composite-transform 1'\n",
      "\n",
      ">>> # Test Interpolation Parameters (MultiLabel/Gaussian)\n",
      ">>> reg7b = copy.deepcopy(reg)\n",
      ">>> reg7b.inputs.interpolation = 'Gaussian'\n",
      ">>> reg7b.inputs.interpolation_parameters = (1.0, 1.0)\n",
      ">>> reg7b.cmdline\n",
      "'antsRegistration --collapse-output-transforms 0 --dimensionality 3 --initial-moving-transform [ trans.mat, 1 ] --initialize-transforms-per-stage 0 --interpolation Gaussian[ 1.0, 1.0 ] --output [ output_, output_warped_image.nii.gz ] --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --transform SyN[ 0.25, 3.0, 0.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --winsorize-image-intensities [ 0.0, 1.0 ]  --write-composite-transform 1'\n",
      "\n",
      "BSplineSyN non-linear registration with custom parameters.\n",
      "\n",
      ">>> # Test Extended Transform Parameters\n",
      ">>> reg8 = copy.deepcopy(reg)\n",
      ">>> reg8.inputs.transforms = ['Affine', 'BSplineSyN']\n",
      ">>> reg8.inputs.transform_parameters = [(2.0,), (0.25, 26, 0, 3)]\n",
      ">>> reg8.cmdline\n",
      "'antsRegistration --collapse-output-transforms 0 --dimensionality 3 --initial-moving-transform [ trans.mat, 1 ] --initialize-transforms-per-stage 0 --interpolation Linear --output [ output_, output_warped_image.nii.gz ] --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --transform BSplineSyN[ 0.25, 26, 0, 3 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --winsorize-image-intensities [ 0.0, 1.0 ]  --write-composite-transform 1'\n",
      "\n",
      "Mask the fixed image in the second stage of the registration (but not the first).\n",
      "\n",
      ">>> # Test masking\n",
      ">>> reg9 = copy.deepcopy(reg)\n",
      ">>> reg9.inputs.fixed_image_masks = ['NULL', 'fixed1.nii']\n",
      ">>> reg9.cmdline\n",
      "'antsRegistration --collapse-output-transforms 0 --dimensionality 3 --initial-moving-transform [ trans.mat, 1 ] --initialize-transforms-per-stage 0 --interpolation Linear --output [ output_, output_warped_image.nii.gz ] --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --masks [ NULL, NULL ] --transform SyN[ 0.25, 3.0, 0.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --masks [ fixed1.nii, NULL ] --winsorize-image-intensities [ 0.0, 1.0 ]  --write-composite-transform 1'\n",
      "\n",
      "Here we use both a warpfield and a linear transformation, before registration commences.  Note that\n",
      "the first transformation that needs to be applied ('ants_Warp.nii.gz') is last in the list of\n",
      "'initial_moving_transform'.\n",
      "\n",
      ">>> # Test initialization with multiple transforms matrices (e.g., unwarp and affine transform)\n",
      ">>> reg10 = copy.deepcopy(reg)\n",
      ">>> reg10.inputs.initial_moving_transform = ['func_to_struct.mat', 'ants_Warp.nii.gz']\n",
      ">>> reg10.inputs.invert_initial_moving_transform = [False, False]\n",
      ">>> reg10.cmdline\n",
      "'antsRegistration --collapse-output-transforms 0 --dimensionality 3 --initial-moving-transform [ func_to_struct.mat, 0 ] [ ants_Warp.nii.gz, 0 ] --initialize-transforms-per-stage 0 --interpolation Linear --output [ output_, output_warped_image.nii.gz ] --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-08, 20 ] --smoothing-sigmas 1.0x0.0vox --shrink-factors 2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --transform SyN[ 0.25, 3.0, 0.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32 ] --convergence [ 100x50x30, 1e-09, 20 ] --smoothing-sigmas 2.0x1.0x0.0vox --shrink-factors 3x2x1 --use-estimate-learning-rate-once 1 --use-histogram-matching 1 --winsorize-image-intensities [ 0.0, 1.0 ]  --write-composite-transform 1'\n",
      "\n",
      "Inputs::\n",
      "\n",
      "        [Mandatory]\n",
      "        fixed_image: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                Image to which the moving_image should be transformed(usually a\n",
      "                structural image)\n",
      "        moving_image: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file)\n",
      "                Image that will be registered to the space of fixed_image. This is\n",
      "                theimage on which the transformations will be applied to\n",
      "        metric: (a list of items which are 'CC' or 'MeanSquares' or 'Demons'\n",
      "                  or 'GC' or 'MI' or 'Mattes' or a list of items which are 'CC' or\n",
      "                  'MeanSquares' or 'Demons' or 'GC' or 'MI' or 'Mattes')\n",
      "                the metric(s) to use for each stage. Note that multiple metrics per\n",
      "                stage are not supported in ANTS 1.9.1 and earlier.\n",
      "        metric_weight: (a list of items which are a float or a list of items\n",
      "                  which are a float, nipype default value: [1.0])\n",
      "                the metric weight(s) for each stage. The weights must sum to 1 per\n",
      "                stage.\n",
      "                requires: metric\n",
      "        transforms: (a list of items which are 'Rigid' or 'Affine' or\n",
      "                  'CompositeAffine' or 'Similarity' or 'Translation' or 'BSpline' or\n",
      "                  'GaussianDisplacementField' or 'TimeVaryingVelocityField' or\n",
      "                  'TimeVaryingBSplineVelocityField' or 'SyN' or 'BSplineSyN' or\n",
      "                  'Exponential' or 'BSplineExponential')\n",
      "                argument: ``%s``\n",
      "        smoothing_sigmas: (a list of items which are a list of items which\n",
      "                  are a float)\n",
      "        shrink_factors: (a list of items which are a list of items which are\n",
      "                  an integer)\n",
      "\n",
      "        [Optional]\n",
      "        dimension: (3 or 2, nipype default value: 3)\n",
      "                image dimension (2 or 3)\n",
      "                argument: ``--dimensionality %d``\n",
      "        fixed_image_mask: (a pathlike object or string representing an\n",
      "                  existing file)\n",
      "                Mask used to limit metric sampling region of the fixed imagein all\n",
      "                stages\n",
      "                argument: ``%s``\n",
      "                mutually_exclusive: fixed_image_masks\n",
      "        fixed_image_masks: (a list of items which are a pathlike object or\n",
      "                  string representing an existing file or 'NULL')\n",
      "                Masks used to limit metric sampling region of the fixed image,\n",
      "                defined per registration stage(Use \"NULL\" to omit a mask at a given\n",
      "                stage)\n",
      "                mutually_exclusive: fixed_image_mask\n",
      "        moving_image_mask: (a pathlike object or string representing an\n",
      "                  existing file)\n",
      "                mask used to limit metric sampling region of the moving imagein all\n",
      "                stages\n",
      "                mutually_exclusive: moving_image_masks\n",
      "                requires: fixed_image_mask\n",
      "        moving_image_masks: (a list of items which are a pathlike object or\n",
      "                  string representing an existing file or 'NULL')\n",
      "                Masks used to limit metric sampling region of the moving image,\n",
      "                defined per registration stage(Use \"NULL\" to omit a mask at a given\n",
      "                stage)\n",
      "                mutually_exclusive: moving_image_mask\n",
      "        save_state: (a pathlike object or string representing a file)\n",
      "                Filename for saving the internal restorable state of the\n",
      "                registration\n",
      "                argument: ``--save-state %s``\n",
      "        restore_state: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                Filename for restoring the internal restorable state of the\n",
      "                registration\n",
      "                argument: ``--restore-state %s``\n",
      "        initial_moving_transform: (a list of items which are a pathlike\n",
      "                  object or string representing an existing file)\n",
      "                A transform or a list of transforms that should be applied before\n",
      "                the registration begins. Note that, when a list is given, the\n",
      "                transformations are applied in reverse order.\n",
      "                argument: ``%s``\n",
      "                mutually_exclusive: initial_moving_transform_com\n",
      "        invert_initial_moving_transform: (a list of items which are a\n",
      "                  boolean)\n",
      "                One boolean or a list of booleans that indicatewhether the\n",
      "                inverse(s) of the transform(s) definedin initial_moving_transform\n",
      "                should be used.\n",
      "                mutually_exclusive: initial_moving_transform_com\n",
      "                requires: initial_moving_transform\n",
      "        initial_moving_transform_com: (0 or 1 or 2)\n",
      "                Align the moving_image and fixed_image before registration using the\n",
      "                geometric center of the images (=0), the image intensities (=1), or\n",
      "                the origin of the images (=2).\n",
      "                argument: ``%s``\n",
      "                mutually_exclusive: initial_moving_transform\n",
      "        metric_item_trait: ('CC' or 'MeanSquares' or 'Demons' or 'GC' or 'MI'\n",
      "                  or 'Mattes')\n",
      "        metric_stage_trait: ('CC' or 'MeanSquares' or 'Demons' or 'GC' or\n",
      "                  'MI' or 'Mattes' or a list of items which are 'CC' or\n",
      "                  'MeanSquares' or 'Demons' or 'GC' or 'MI' or 'Mattes')\n",
      "        metric_weight_item_trait: (a float, nipype default value: 1.0)\n",
      "        metric_weight_stage_trait: (a float or a list of items which are a\n",
      "                  float)\n",
      "        radius_bins_item_trait: (an integer, nipype default value: 5)\n",
      "        radius_bins_stage_trait: (an integer or a list of items which are an\n",
      "                  integer)\n",
      "        radius_or_number_of_bins: (a list of items which are an integer or a\n",
      "                  list of items which are an integer, nipype default value: [5])\n",
      "                the number of bins in each stage for the MI and Mattes metric, the\n",
      "                radius for other metrics\n",
      "                requires: metric_weight\n",
      "        sampling_strategy_item_trait: ('None' or 'Regular' or 'Random' or\n",
      "                  None)\n",
      "        sampling_strategy_stage_trait: ('None' or 'Regular' or 'Random' or\n",
      "                  None or a list of items which are 'None' or 'Regular' or 'Random'\n",
      "                  or None)\n",
      "        sampling_strategy: (a list of items which are 'None' or 'Regular' or\n",
      "                  'Random' or None or a list of items which are 'None' or 'Regular'\n",
      "                  or 'Random' or None)\n",
      "                the metric sampling strategy (strategies) for each stage\n",
      "                requires: metric_weight\n",
      "        sampling_percentage_item_trait: (0.0 <= a floating point number <=\n",
      "                  1.0 or None)\n",
      "        sampling_percentage_stage_trait: (0.0 <= a floating point number <=\n",
      "                  1.0 or None or a list of items which are 0.0 <= a floating point\n",
      "                  number <= 1.0 or None)\n",
      "        sampling_percentage: (a list of items which are 0.0 <= a floating\n",
      "                  point number <= 1.0 or None or a list of items which are 0.0 <= a\n",
      "                  floating point number <= 1.0 or None)\n",
      "                the metric sampling percentage(s) to use for each stage\n",
      "                requires: sampling_strategy\n",
      "        use_estimate_learning_rate_once: (a list of items which are a\n",
      "                  boolean)\n",
      "        use_histogram_matching: (a boolean or a list of items which are a\n",
      "                  boolean, nipype default value: True)\n",
      "                Histogram match the images before registration.\n",
      "        interpolation: ('Linear' or 'NearestNeighbor' or 'CosineWindowedSinc'\n",
      "                  or 'WelchWindowedSinc' or 'HammingWindowedSinc' or\n",
      "                  'LanczosWindowedSinc' or 'BSpline' or 'MultiLabel' or 'Gaussian'\n",
      "                  or 'GenericLabel', nipype default value: Linear)\n",
      "                argument: ``%s``\n",
      "        interpolation_parameters: (a tuple of the form: (an integer) or a\n",
      "                  tuple of the form: (a float, a float) or a tuple of the form: (a\n",
      "                  string))\n",
      "        write_composite_transform: (a boolean, nipype default value: False)\n",
      "                argument: ``--write-composite-transform %d``\n",
      "        collapse_output_transforms: (a boolean, nipype default value: True)\n",
      "                Collapse output transforms. Specifically, enabling this option\n",
      "                combines all adjacent linear transforms and composes all adjacent\n",
      "                displacement field transforms before writing the results to disk.\n",
      "                argument: ``--collapse-output-transforms %d``\n",
      "        initialize_transforms_per_stage: (a boolean, nipype default value:\n",
      "                  False)\n",
      "                Initialize linear transforms from the previous stage. By enabling\n",
      "                this option, the current linear stage transform is directly\n",
      "                intialized from the previous stages linear transform; this allows\n",
      "                multiple linear stages to be run where each stage directly updates\n",
      "                the estimated linear transform from the previous stage. (e.g.\n",
      "                Translation -> Rigid -> Affine).\n",
      "                argument: ``--initialize-transforms-per-stage %d``\n",
      "        float: (a boolean)\n",
      "                Use float instead of double for computations.\n",
      "                argument: ``--float %d``\n",
      "        transform_parameters: (a list of items which are a tuple of the form:\n",
      "                  (a float) or a tuple of the form: (a float, a float, a float) or a\n",
      "                  tuple of the form: (a float, an integer, an integer, an integer)\n",
      "                  or a tuple of the form: (a float, an integer, a float, a float, a\n",
      "                  float, a float) or a tuple of the form: (a float, a float, a\n",
      "                  float, an integer) or a tuple of the form: (a float, an integer,\n",
      "                  an integer, an integer, an integer))\n",
      "        restrict_deformation: (a list of items which are a list of items\n",
      "                  which are 0.0 <= a floating point number <= 1.0)\n",
      "                This option allows the user to restrict the optimization of the\n",
      "                displacement field, translation, rigid or affine transform on a per-\n",
      "                component basis. For example, if one wants to limit the deformation\n",
      "                or rotation of 3-D volume to the first two dimensions, this is\n",
      "                possible by specifying a weight vector of '1x1x0' for a deformation\n",
      "                field or '1x1x0x1x1x0' for a rigid transformation. Low-dimensional\n",
      "                restriction only works if there are no preceding transformations.\n",
      "        number_of_iterations: (a list of items which are a list of items\n",
      "                  which are an integer)\n",
      "        sigma_units: (a list of items which are 'mm' or 'vox')\n",
      "                units for smoothing sigmas\n",
      "                requires: smoothing_sigmas\n",
      "        convergence_threshold: (a list of at least 1 items which are a float,\n",
      "                  nipype default value: [1e-06])\n",
      "                requires: number_of_iterations\n",
      "        convergence_window_size: (a list of at least 1 items which are an\n",
      "                  integer, nipype default value: [10])\n",
      "                requires: convergence_threshold\n",
      "        output_transform_prefix: (a string, nipype default value: transform)\n",
      "                argument: ``%s``\n",
      "        output_warped_image: (a boolean or a pathlike object or string\n",
      "                  representing a file)\n",
      "        output_inverse_warped_image: (a boolean or a pathlike object or\n",
      "                  string representing a file)\n",
      "                requires: output_warped_image\n",
      "        winsorize_upper_quantile: (0.0 <= a floating point number <= 1.0,\n",
      "                  nipype default value: 1.0)\n",
      "                The Upper quantile to clip image ranges\n",
      "                argument: ``%s``\n",
      "        winsorize_lower_quantile: (0.0 <= a floating point number <= 1.0,\n",
      "                  nipype default value: 0.0)\n",
      "                The Lower quantile to clip image ranges\n",
      "                argument: ``%s``\n",
      "        verbose: (a boolean, nipype default value: False)\n",
      "                argument: ``-v``\n",
      "        num_threads: (an integer, nipype default value: 1)\n",
      "                Number of ITK threads to use\n",
      "        args: (a string)\n",
      "                Additional parameters to the command\n",
      "                argument: ``%s``\n",
      "        environ: (a dictionary with keys which are a bytes or None or a value\n",
      "                  of class 'str' and with values which are a bytes or None or a\n",
      "                  value of class 'str', nipype default value: {})\n",
      "                Environment variables\n",
      "\n",
      "Outputs::\n",
      "\n",
      "        forward_transforms: (a list of items which are a pathlike object or\n",
      "                  string representing an existing file)\n",
      "                List of output transforms for forward registration\n",
      "        reverse_forward_transforms: (a list of items which are a pathlike\n",
      "                  object or string representing an existing file)\n",
      "                List of output transforms for forward registration reversed for\n",
      "                antsApplyTransform\n",
      "        reverse_transforms: (a list of items which are a pathlike object or\n",
      "                  string representing an existing file)\n",
      "                List of output transforms for reverse registration\n",
      "        forward_invert_flags: (a list of items which are a boolean)\n",
      "                List of flags corresponding to the forward transforms\n",
      "        reverse_forward_invert_flags: (a list of items which are a boolean)\n",
      "                List of flags corresponding to the forward transforms reversed for\n",
      "                antsApplyTransform\n",
      "        reverse_invert_flags: (a list of items which are a boolean)\n",
      "                List of flags corresponding to the reverse transforms\n",
      "        composite_transform: (a pathlike object or string representing an\n",
      "                  existing file)\n",
      "                Composite transform file\n",
      "        inverse_composite_transform: (a pathlike object or string\n",
      "                  representing a file)\n",
      "                Inverse composite transform file\n",
      "        warped_image: (a pathlike object or string representing a file)\n",
      "                Outputs warped image\n",
      "        inverse_warped_image: (a pathlike object or string representing a\n",
      "                  file)\n",
      "                Outputs the inverse of the warped image\n",
      "        save_state: (a pathlike object or string representing a file)\n",
      "                The saved registration state to be restored\n",
      "        metric_value: (a float)\n",
      "                the final value of metric\n",
      "        elapsed_time: (a float)\n",
      "                the total elapsed time as reported by ANTs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Registration.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c617c7c",
   "metadata": {},
   "source": [
    "### Combine composite transforms into list\n",
    "coreg_regFUNC2UNI.hd5, coreg_regUNI2T1.hd5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b817c694",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_transforms = 2\n",
    "combineCoregTransforms = Node(utilMerge(n_transforms),name='combineCoregTransforms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cc6dd93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if coregister and precalc_coreg and coreg_method == 'antsRegistration' and coreg_dir == 'func2struct':\n",
    "    wf.connect([(datasourceManualEdits, combineCoregTransforms,[('coreg_regFUNC2INPLANE', 'in1')])]) \n",
    "    wf.connect([(datasourceManualEdits, combineCoregTransforms,[('coreg_regINPLANE2T1', 'in2')])]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c0316de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic interface class to merge inputs into a single list\n",
      "\n",
      "``Merge(1)`` will merge a list of lists\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      ">>> from nipype.interfaces.utility import Merge\n",
      ">>> mi = Merge(3)\n",
      ">>> mi.inputs.in1 = 1\n",
      ">>> mi.inputs.in2 = [2, 5]\n",
      ">>> mi.inputs.in3 = 3\n",
      ">>> out = mi.run()\n",
      ">>> out.outputs.out\n",
      "[1, 2, 5, 3]\n",
      "\n",
      ">>> merge = Merge(1)\n",
      ">>> merge.inputs.in1 = [1, [2, 5], 3]\n",
      ">>> out = merge.run()\n",
      ">>> out.outputs.out\n",
      "[1, [2, 5], 3]\n",
      "\n",
      ">>> merge = Merge(1)\n",
      ">>> merge.inputs.in1 = [1, [2, 5], 3]\n",
      ">>> merge.inputs.ravel_inputs = True\n",
      ">>> out = merge.run()\n",
      ">>> out.outputs.out\n",
      "[1, 2, 5, 3]\n",
      "\n",
      ">>> merge = Merge(1)\n",
      ">>> merge.inputs.in1 = [1, [2, 5], 3]\n",
      ">>> merge.inputs.no_flatten = True\n",
      ">>> out = merge.run()\n",
      ">>> out.outputs.out\n",
      "[[1, [2, 5], 3]]\n",
      "\n",
      "Inputs::\n",
      "\n",
      "        [Optional]\n",
      "        axis: ('vstack' or 'hstack', nipype default value: vstack)\n",
      "                direction in which to merge, hstack requires same number of elements\n",
      "                in each input\n",
      "        no_flatten: (a boolean, nipype default value: False)\n",
      "                append to outlist instead of extending in vstack mode\n",
      "        ravel_inputs: (a boolean, nipype default value: False)\n",
      "                ravel inputs when no_flatten is False\n",
      "\n",
      "Outputs::\n",
      "\n",
      "        out: (a list of items which are any value)\n",
      "                Merged output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utilMerge.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce76102",
   "metadata": {},
   "source": [
    "#### Apply coregistration transforms to mean functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1d8e8aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation = 'BSpline'\n",
    "interpolation_parameters = (5,)\n",
    "input_image_type = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "32db9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "applyCoreg2MeanFunc = Node(ApplyTransforms(interpolation=interpolation,\n",
    "                                          interpolation_parameters=interpolation_parameters,\n",
    "                                          input_image_type=input_image_type), name = 'applyCoreg2MeanFunc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fa3ea625",
   "metadata": {},
   "outputs": [],
   "source": [
    "if coregister and precalc_coreg and coreg_method == 'antsRegistration' and coreg_dir == 'func2struct':\n",
    "    if precalc_coreg:\n",
    "        output_image = 'reg_meanFunc.nii'\n",
    "        wf.connect([(meanFunc, applyCoreg2MeanFunc,[('mean_img', 'input_image')])]) \n",
    "        wf.connect([(datasource, applyCoreg2MeanFunc,[('T1', 'reference_image')])]) \n",
    "        wf.connect([(combineCoregTransforms, applyCoreg2MeanFunc,[('out', 'transforms')])])\n",
    "        applyCoreg2MeanFunc.inputs.output_image = output_image\n",
    "    else:\n",
    "        error()\n",
    "        #wf.connect([(coreg, applyCoreg2MeanFunc,[('forward_transforms', 'transforms')])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b6047b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wraps the executable command ``antsApplyTransforms``.\n",
      "\n",
      "ApplyTransforms, applied to an input image, transforms it according to a\n",
      "reference image and a transform (or a set of transforms).\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      ">>> from nipype.interfaces.ants import ApplyTransforms\n",
      ">>> at = ApplyTransforms()\n",
      ">>> at.inputs.input_image = 'moving1.nii'\n",
      ">>> at.inputs.reference_image = 'fixed1.nii'\n",
      ">>> at.inputs.transforms = 'identity'\n",
      ">>> at.cmdline\n",
      "'antsApplyTransforms --default-value 0 --float 0 --input moving1.nii --interpolation Linear --output moving1_trans.nii --reference-image fixed1.nii --transform identity'\n",
      "\n",
      ">>> at = ApplyTransforms()\n",
      ">>> at.inputs.dimension = 3\n",
      ">>> at.inputs.input_image = 'moving1.nii'\n",
      ">>> at.inputs.reference_image = 'fixed1.nii'\n",
      ">>> at.inputs.output_image = 'deformed_moving1.nii'\n",
      ">>> at.inputs.interpolation = 'Linear'\n",
      ">>> at.inputs.default_value = 0\n",
      ">>> at.inputs.transforms = ['ants_Warp.nii.gz', 'trans.mat']\n",
      ">>> at.inputs.invert_transform_flags = [False, True]\n",
      ">>> at.cmdline\n",
      "'antsApplyTransforms --default-value 0 --dimensionality 3 --float 0 --input moving1.nii --interpolation Linear --output deformed_moving1.nii --reference-image fixed1.nii --transform ants_Warp.nii.gz --transform [ trans.mat, 1 ]'\n",
      "\n",
      ">>> at1 = ApplyTransforms()\n",
      ">>> at1.inputs.dimension = 3\n",
      ">>> at1.inputs.input_image = 'moving1.nii'\n",
      ">>> at1.inputs.reference_image = 'fixed1.nii'\n",
      ">>> at1.inputs.output_image = 'deformed_moving1.nii'\n",
      ">>> at1.inputs.interpolation = 'BSpline'\n",
      ">>> at1.inputs.interpolation_parameters = (5,)\n",
      ">>> at1.inputs.default_value = 0\n",
      ">>> at1.inputs.transforms = ['ants_Warp.nii.gz', 'trans.mat']\n",
      ">>> at1.inputs.invert_transform_flags = [False, False]\n",
      ">>> at1.cmdline\n",
      "'antsApplyTransforms --default-value 0 --dimensionality 3 --float 0 --input moving1.nii --interpolation BSpline[ 5 ] --output deformed_moving1.nii --reference-image fixed1.nii --transform ants_Warp.nii.gz --transform trans.mat'\n",
      "\n",
      "Identity transforms may be used as part of a chain:\n",
      "\n",
      ">>> at2 = ApplyTransforms()\n",
      ">>> at2.inputs.dimension = 3\n",
      ">>> at2.inputs.input_image = 'moving1.nii'\n",
      ">>> at2.inputs.reference_image = 'fixed1.nii'\n",
      ">>> at2.inputs.output_image = 'deformed_moving1.nii'\n",
      ">>> at2.inputs.interpolation = 'BSpline'\n",
      ">>> at2.inputs.interpolation_parameters = (5,)\n",
      ">>> at2.inputs.default_value = 0\n",
      ">>> at2.inputs.transforms = ['identity', 'ants_Warp.nii.gz', 'trans.mat']\n",
      ">>> at2.cmdline\n",
      "'antsApplyTransforms --default-value 0 --dimensionality 3 --float 0 --input moving1.nii --interpolation BSpline[ 5 ] --output deformed_moving1.nii --reference-image fixed1.nii --transform identity --transform ants_Warp.nii.gz --transform trans.mat'\n",
      "\n",
      "Inputs::\n",
      "\n",
      "        [Mandatory]\n",
      "        input_image: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                image to apply transformation to (generally a coregistered\n",
      "                functional)\n",
      "                argument: ``--input %s``\n",
      "        reference_image: (a pathlike object or string representing an\n",
      "                  existing file)\n",
      "                reference image space that you wish to warp INTO\n",
      "                argument: ``--reference-image %s``\n",
      "        transforms: (a list of items which are a pathlike object or string\n",
      "                  representing an existing file or 'identity')\n",
      "                transform files: will be applied in reverse order. For example, the\n",
      "                last specified transform will be applied first.\n",
      "                argument: ``%s``\n",
      "\n",
      "        [Optional]\n",
      "        dimension: (2 or 3 or 4)\n",
      "                This option forces the image to be treated as a specified-\n",
      "                dimensional image. If not specified, antsWarp tries to infer the\n",
      "                dimensionality from the input image.\n",
      "                argument: ``--dimensionality %d``\n",
      "        input_image_type: (0 or 1 or 2 or 3)\n",
      "                Option specifying the input image type of scalar (default), vector,\n",
      "                tensor, or time series.\n",
      "                argument: ``--input-image-type %d``\n",
      "        output_image: (a string)\n",
      "                output file name\n",
      "                argument: ``--output %s``\n",
      "        out_postfix: (a string, nipype default value: _trans)\n",
      "                Postfix that is appended to all output files (default = _trans)\n",
      "        interpolation: ('Linear' or 'NearestNeighbor' or 'CosineWindowedSinc'\n",
      "                  or 'WelchWindowedSinc' or 'HammingWindowedSinc' or\n",
      "                  'LanczosWindowedSinc' or 'MultiLabel' or 'Gaussian' or 'BSpline',\n",
      "                  nipype default value: Linear)\n",
      "                argument: ``%s``\n",
      "        interpolation_parameters: (a tuple of the form: (an integer) or a\n",
      "                  tuple of the form: (a float, a float))\n",
      "        invert_transform_flags: (a list of items which are a boolean)\n",
      "        default_value: (a float, nipype default value: 0.0)\n",
      "                argument: ``--default-value %g``\n",
      "        print_out_composite_warp_file: (a boolean)\n",
      "                output a composite warp file instead of a transformed image\n",
      "                requires: output_image\n",
      "        float: (a boolean, nipype default value: False)\n",
      "                Use float instead of double for computations.\n",
      "                argument: ``--float %d``\n",
      "        num_threads: (an integer, nipype default value: 1)\n",
      "                Number of ITK threads to use\n",
      "        args: (a string)\n",
      "                Additional parameters to the command\n",
      "                argument: ``%s``\n",
      "        environ: (a dictionary with keys which are a bytes or None or a value\n",
      "                  of class 'str' and with values which are a bytes or None or a\n",
      "                  value of class 'str', nipype default value: {})\n",
      "                Environment variables\n",
      "\n",
      "Outputs::\n",
      "\n",
      "        output_image: (a pathlike object or string representing an existing\n",
      "                  file)\n",
      "                Warped image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ApplyTransforms.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "59d1effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if coregister and coreg_method == 'antsRegistration':\n",
    "#     if coreg_dir == 'func2struct':\n",
    "#         output_image = 'reg_meanFunc.nii'\n",
    "#         wf.connect([(meanFunc, applyCoreg2MeanFunc,[('mean_img', 'input_image')])]) \n",
    "#         wf.connect([(datasource, applyCoreg2MeanFunc,[('UNI', 'reference_image')])]) \n",
    "#         wf.connect([(coreg, applyCoreg2MeanFunc,[('forward_transforms', 'transforms')])]) \n",
    "        \n",
    "#     elif coreg_dir == 'struct2func':\n",
    "#         output_image = 'reg_UNI.nii'\n",
    "#         wf.connect([(meanFunc, applyCoreg2MeanFunc,[('mean_img', 'reference_image')])]) \n",
    "#         wf.connect([(datasource, applyCoreg2MeanFunc,[('UNI', 'input_image')])]) \n",
    "#         wf.connect([(coreg, applyCoreg2MeanFunc,[('forward_transforms', 'transforms')])]) \n",
    "        \n",
    "        \n",
    "#     applyCoreg2MeanFunc.inputs.output_image = output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57faad10",
   "metadata": {},
   "source": [
    "#### Apply coregistration transforms to all runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "be7dc19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation = 'BSpline'\n",
    "interpolation_parameters = (5,)\n",
    "input_image_type = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "115d643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "applyCoreg = Node(ApplyTransforms(interpolation=interpolation,\n",
    "                                  interpolation_parameters=interpolation_parameters,\n",
    "                                  input_image_type=input_image_type), name = 'applyCoreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "633409d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if coregister and precalc_coreg and coreg_method == 'antsRegistration' and coreg_dir == 'func2struct':\n",
    "    if precalc_coreg:\n",
    "        output_image = 'reg_meanFunc.nii'\n",
    "        wf.connect([(sliceTimingCorr, applyCoreg,[('timecorrected_files', 'input_image')])])\n",
    "        wf.connect([(datasource, applyCoreg,[('T1', 'reference_image')])]) \n",
    "        wf.connect([(combineCoregTransforms, applyCoreg,[('out', 'transforms')])])\n",
    "    else:\n",
    "        error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d3ed1bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ApplyTransforms.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c3932a",
   "metadata": {},
   "source": [
    "### Surface projection of functional runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "99213909",
   "metadata": {},
   "outputs": [],
   "source": [
    "hemi_list = ['lh','rh']\n",
    "reg_header = True\n",
    "sampling_range_list = [-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5]\n",
    "sampling_method = 'point'\n",
    "sampling_units = 'mm'\n",
    "interp_method = 'trilinear'\n",
    "out_type = 'mgh'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d22a7f",
   "metadata": {},
   "source": [
    "#### Iterate over depths and hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1aa273ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "hemi_depth = Node(IdentityInterface(fields=['hemi','sampling_range']),name='hemi_depth')\n",
    "hemi_depth.iterables = [('hemi', hemi_list), ('sampling_range', sampling_range_list)]\n",
    "hemi_depth.synchronize = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c979bd0e",
   "metadata": {},
   "source": [
    "#### Mean functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e0862710",
   "metadata": {},
   "outputs": [],
   "source": [
    "surfaceProjectMeanFunc = Node(SampleToSurface(reg_header=reg_header,\n",
    "                                              sampling_method=sampling_method,\n",
    "                                              sampling_units=sampling_units,\n",
    "                                              out_type=out_type,\n",
    "                                              interp_method=interp_method),name='surfaceProjectMeanFunc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ffab8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if coregister and coreg_method == 'antsRegistration':\n",
    "#     if coreg_dir == 'func2struct':\n",
    "#         wf.connect([(applyCoreg2MeanFunc,surfaceProjectMeanFunc,[('output_image', 'source_file')])]) \n",
    "#         wf.connect([(subjects,surfaceProjectMeanFunc,[('subject_id', 'subject_id')])])\n",
    "#         wf.connect([(hemi_depth,surfaceProjectMeanFunc,[('hemi', 'hemi')])])\n",
    "#         wf.connect([(hemi_depth,surfaceProjectMeanFunc,[('sampling_range', 'sampling_range')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e57952",
   "metadata": {},
   "source": [
    "#### Other runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "87137879",
   "metadata": {},
   "outputs": [],
   "source": [
    "surfaceProject = Node(SampleToSurface(reg_header=reg_header,\n",
    "                                      sampling_method=sampling_method,\n",
    "                                      sampling_units=sampling_units,\n",
    "                                      out_type=out_type,\n",
    "                                      interp_method=interp_method),name='surfaceProject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "253f36a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if coregister and coreg_method == 'antsRegistration':\n",
    "#     if coreg_dir == 'func2struct':\n",
    "#         wf.connect([(applyCoreg,surfaceProject,[('output_image', 'source_file')])]) \n",
    "#         wf.connect([(subjects,surfaceProject,[('subject_id', 'subject_id')])])\n",
    "#         wf.connect([(hemi_depth,surfaceProject,[('hemi', 'hemi')])])\n",
    "#         wf.connect([(hemi_depth,surfaceProject,[('sampling_range', 'sampling_range')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555c15f",
   "metadata": {},
   "source": [
    "#### Prepare occipital mask for pRF mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079975fe",
   "metadata": {},
   "source": [
    "Surface project manual occipital mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e144be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_method = 'nearest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bab4c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "surfaceProjectOccipitalMask = Node(SampleToSurface(reg_header=reg_header,\n",
    "                                      sampling_method=sampling_method,\n",
    "                                      sampling_units=sampling_units,\n",
    "                                      out_type=out_type,\n",
    "                                      interp_method=interp_method),name='surfaceProjectOccipitalMask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3932d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if coregister and coreg_method == 'antsRegistration':\n",
    "#     if coreg_dir == 'func2struct':\n",
    "#         wf.connect([(datasourceManualEdits,surfaceProjectOccipitalMask,[('manual_occipitalmask', 'source_file')])]) \n",
    "#         wf.connect([(subjects,surfaceProjectOccipitalMask,[('subject_id', 'subject_id')])])\n",
    "#         wf.connect([(hemi_depth,surfaceProjectOccipitalMask,[('hemi', 'hemi')])])\n",
    "#         wf.connect([(hemi_depth,surfaceProjectOccipitalMask,[('sampling_range', 'sampling_range')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c60c0",
   "metadata": {},
   "source": [
    "Make lable out of surface projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b2933284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mri_vol2label_bash(subjects_dir,subject_id,working_dir,hemi,sampling_range,surface_file):\n",
    "    from os.path import join as opj\n",
    "    import os\n",
    "\n",
    "    out_file = opj(working_dir,'_subject_id_'+subject_id,\n",
    "                   '_hemi_'+hemi+'_sampling_range_'+str(sampling_range),'makeOccLabel',\n",
    "                   hemi+'_occ_depth'+str(sampling_range)+'.label')\n",
    "    bash_command = 'mri_vol2label --i '+surface_file+' --id 1 --surf '+subject_id + ' '+ hemi + ' --l '+out_file\n",
    "    \n",
    "    print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "    print(out_file)\n",
    "    print(bash_command)\n",
    "    print('mri_vol2label --i $OUTDIR/sub-01/lh_occ_depth0.0.mgh --id 1  --surf sub-01 lh  --l $OUTDIR/sub-01/lh_occ_depth0.0.label')\n",
    "    print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "\n",
    "    os.system(bash_command)\n",
    "    \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c02f3f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "makeOccLabel = Node(Function(input_names = ['subjects_dir','subject_id','working_dir','hemi',\n",
    "                                            'sampling_range','surface_file'],\n",
    "                             output_names=['out_file'],\n",
    "                             function=mri_vol2label_bash),\n",
    "                    name='makeOccLabel')\n",
    "makeOccLabel.inputs.working_dir = opj(der_dir,wf_name)\n",
    "makeOccLabel.inputs.subjects_dir = subjects_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e4bdb76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if coregister and coreg_method == 'antsRegistration':\n",
    "#     if coreg_dir == 'func2struct':\n",
    "#         wf.connect([(subjects,makeOccLabel,[('subject_id', 'subject_id')])])\n",
    "#         wf.connect([(hemi_depth,makeOccLabel,[('hemi', 'hemi')])])\n",
    "#         wf.connect([(hemi_depth,makeOccLabel,[('sampling_range', 'sampling_range')])])\n",
    "#         wf.connect([(surfaceProjectOccipitalMask,makeOccLabel,[('out_file', 'surface_file')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "780f2d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#operation = 'mul'   # ('add' or 'sub' or 'mul' or 'div' or 'rem' or 'max' or\n",
    "                    # 'min')\n",
    "                    # operation to perform\n",
    "                    # flag: -%s, position: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6c35cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if coregister:\n",
    "#    occipitalGM = Node(BinaryMaths(operation=operation), name='occipitalGM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1301a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if coregister:\n",
    "#    wf.connect([(datasourceManualEdits,occipitalGM,[('binarizedmeanfunc', 'in_file')])]) \n",
    "#    wf.connect([(datasourceManualEdits,occipitalGM,[('occipital', 'operand_file')])]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a1dba",
   "metadata": {},
   "source": [
    "### Put data in sink\n",
    "\n",
    "A workflow working directory is like a cache. It contains not only the outputs of various processing stages, it also contains various extraneous information such as execution reports, hashfiles determining the input state of processes. All of this is embedded in a hierarchical structure that reflects the iterables that have been used in the workflow. This makes navigating the working directory a not so pleasant experience. And typically the user is interested in preserving only a small percentage of these outputs. The DataSink interface can be used to extract components from this cache and store it at a different location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "42815f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSink = Node(DataSink(), name='dataSink')\n",
    "dataSink.inputs.base_directory = out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "80880b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:27:11,753 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.datasource, wf_func_preproc.dataSink): No edge data\n",
      "230402-10:27:11,754 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.datasource, wf_func_preproc.dataSink): new edge data: {'connect': [('T1', 'func.anat')]}\n",
      "230402-10:27:11,755 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.applyRealign, wf_func_preproc.dataSink): No edge data\n",
      "230402-10:27:11,756 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.applyRealign, wf_func_preproc.dataSink): new edge data: {'connect': [('out_file', 'func.realign')]}\n",
      "230402-10:27:11,757 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.meanFunc, wf_func_preproc.dataSink): No edge data\n",
      "230402-10:27:11,757 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.meanFunc, wf_func_preproc.dataSink): new edge data: {'connect': [('mean_img', 'func.meanFunc')]}\n",
      "230402-10:27:11,758 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.binarizeMeanFunc, wf_func_preproc.dataSink): No edge data\n",
      "230402-10:27:11,759 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.binarizeMeanFunc, wf_func_preproc.dataSink): new edge data: {'connect': [('binary_file', 'func.meanFunc.@binarizedMeanFunc')]}\n",
      "230402-10:27:11,760 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sliceTimingCorr, wf_func_preproc.dataSink): No edge data\n",
      "230402-10:27:11,760 nipype.workflow DEBUG:\n",
      "\t (wf_func_preproc.sliceTimingCorr, wf_func_preproc.dataSink): new edge data: {'connect': [('timecorrected_files', 'func.sliceTimeCorr')]}\n"
     ]
    }
   ],
   "source": [
    "# T1.nii\n",
    "wf.connect([(datasource,dataSink,[('T1','func.anat')])])\n",
    "\n",
    "# realigned func volumes (within and between session)\n",
    "wf.connect([(applyRealign,dataSink,[('out_file','func.realign')])])\n",
    "\n",
    "# mean functional\n",
    "wf.connect([(meanFunc,dataSink,[('mean_img','func.meanFunc')])])\n",
    "\n",
    "# binarized mean functional\n",
    "wf.connect([(binarizeMeanFunc,dataSink,[('binary_file','func.meanFunc.@binarizedMeanFunc')])])\n",
    "\n",
    "\n",
    "# # prepared fieldmap\n",
    "# wf.connect([(prepFieldMap,dataSink,[('out_fieldmap','func.prepFieldMap')])])\n",
    "\n",
    "# # unwarped func volumes\n",
    "# if unwarp:\n",
    "#     wf.connect([(unwarping,dataSink,[('unwarped_file','func.unwarp')])])\n",
    "\n",
    "# slice-time corrected func volumes\n",
    "wf.connect([(sliceTimingCorr,dataSink,[('timecorrected_files','func.sliceTimeCorr')])])\n",
    "\n",
    "\n",
    "# coregistered T1 and transformation matrices\n",
    "if coregister:\n",
    "    if coreg_method == 'antsRegistration':\n",
    "#         wf.connect([(coreg,dataSink,[('warped_image','func.coreg')])])\n",
    "#         wf.connect([(coreg, dataSink,[('forward_transforms', 'func.coreg.@forwardTransform')])]) \n",
    "#         wf.connect([(coreg, dataSink,[('reverse_transforms', 'func.coreg.@reverseTransform')])])\n",
    "\n",
    "        wf.connect([(applyCoreg, dataSink,[('output_image', 'func.coreg')])])\n",
    "        wf.connect([(applyCoreg2MeanFunc, dataSink,[('output_image', 'func.coreg.@meanFunc')])])\n",
    "        \n",
    "    elif coreg_method == 'itk-snap':\n",
    "        wf.connect([(coreg,dataSink,[('output_image','func.coreg')])])\n",
    "    \n",
    "## occipital GM mask for pRF mapping\n",
    "#if manual_edits:\n",
    "#    wf.connect([(occipitalGM,dataSink,[('out_file','func.occipitalGM')])])\n",
    "    \n",
    "# if coreg_method == 'flirt':\n",
    "#    wf.connect([(coreg,dataSink,[('out_file','func.coreg')])])\n",
    "#    wf.connect([(coreg,dataSink,[('out_matrix_file','func.coreg.@out_matrix_file')])])\n",
    "# elif coreg_method == 'freesurfer':\n",
    "#    wf.connect([(coreg,dataSink,[('out_file','func.coreg')])])\n",
    "#    wf.connect([(coreg,dataSink,[('out_matrix_file','func.coreg.@out_matrix_file')])])\n",
    "# elif coreg_method == 'antsRegistration':\n",
    "#    wf.connect([(coreg,dataSink,[('warped_image','func.coreg')])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d78b44d",
   "metadata": {},
   "source": [
    "### Put pRF analysis data in separate sink\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1e5b0983",
   "metadata": {},
   "outputs": [],
   "source": [
    "prfSink = Node(DataSink(), name='prfSink')\n",
    "prfSink.inputs.base_directory = pRF_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "561845af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if coregister and coreg_method == 'antsRegistration':\n",
    "    \n",
    "#     # coregistered other functional runs\n",
    "#     wf.connect([(applyCoreg,prfSink,[('output_image','data')])])\n",
    "    \n",
    "#     # coregistered mean functional\n",
    "#     wf.connect([(applyCoreg2MeanFunc,prfSink,[('output_image','data.@meanFunc')])])\n",
    "        \n",
    "# #     # surface projected mean functional\n",
    "# #     wf.connect([(surfaceProjectMeanFunc,prfSink,[('out_file','data.surfs_meanFunc')])])\n",
    "    \n",
    "# #     # surface projected other functional runs\n",
    "# #     wf.connect([(surfaceProject,prfSink,[('out_file','data.surfs')])])\n",
    "    \n",
    "# #     # occipital labels\n",
    "# #     wf.connect([(makeOccLabel,prfSink,[('out_file','data.occLabels')])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0f4041",
   "metadata": {},
   "source": [
    "### Write graph for visualization and run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e292afb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:27:16,113 nipype.workflow DEBUG:\n",
      "\t Creating flat graph for workflow: wf_func_preproc\n",
      "230402-10:27:16,124 nipype.workflow DEBUG:\n",
      "\t expanding workflow: wf_func_preproc\n",
      "230402-10:27:16,126 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.subjects\n",
      "230402-10:27:16,127 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.datasource\n",
      "230402-10:27:16,128 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.datasourceFunc\n",
      "230402-10:27:16,129 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.sessions\n",
      "230402-10:27:16,129 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.datasourceManualEdits\n",
      "230402-10:27:16,130 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.discardDummies\n",
      "230402-10:27:16,130 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.mcflirtWithinSess\n",
      "230402-10:27:16,131 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.getMeanImg\n",
      "230402-10:27:16,131 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.concatenateMeans\n",
      "230402-10:27:16,132 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.mcflirtBetweenSess\n",
      "230402-10:27:16,133 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.betweenMat\n",
      "230402-10:27:16,133 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.concatenateTransforms\n",
      "230402-10:27:16,145 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.copyTransforms\n",
      "230402-10:27:16,145 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.applyRealign\n",
      "230402-10:27:16,146 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.sliceTimingCorr\n",
      "230402-10:27:16,147 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.acquisitionParams\n",
      "230402-10:27:16,147 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.concatenateFunc\n",
      "230402-10:27:16,147 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.meanFunc\n",
      "230402-10:27:16,148 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.binarizeMeanFunc\n",
      "230402-10:27:16,148 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.dataSink\n",
      "230402-10:27:16,149 nipype.workflow DEBUG:\n",
      "\t finished expanding workflow: wf_func_preproc\n",
      "230402-10:27:16,156 nipype.workflow DEBUG:\n",
      "\t PE: expanding iterables\n",
      "230402-10:27:16,158 nipype.workflow DEBUG:\n",
      "\t [Node] sliceTimingCorr - setting input num_slices = 30\n",
      "230402-10:27:16,159 nipype.workflow DEBUG:\n",
      "\t [Node] sliceTimingCorr - setting input slice_order = [0.693, 1.383, 0.593, 1.283, 0.495, 1.185, 0.395, 1.085, 0.298, 0.988, 0.198, 0.888, 0.101, 0.791, 0, 0.693, 1.383, 0.593, 1.283, 0.495, 1.185, 0.395, 1.085, 0.298, 0.988, 0.198, 0.888, 0.101, 0.791, 0]\n",
      "230402-10:27:16,160 nipype.workflow DEBUG:\n",
      "\t [Node] sliceTimingCorr - setting input time_repetition = 1.5\n",
      "230402-10:27:16,161 nipype.workflow DEBUG:\n",
      "\t [Node] sliceTimingCorr - setting input time_acquisition = 1.45\n",
      "230402-10:27:16,161 nipype.workflow DEBUG:\n",
      "\t Removed the identity node wf_func_preproc.acquisitionParams from the graph.\n",
      "230402-10:27:16,162 nipype.workflow DEBUG:\n",
      "\t Detected iterable nodes [wf_func_preproc.subjects, wf_func_preproc.sessions]\n",
      "230402-10:27:16,162 nipype.workflow DEBUG:\n",
      "\t Expanding the iterable node wf_func_preproc.subjects...\n",
      "230402-10:27:16,163 nipype.workflow DEBUG:\n",
      "\t node: wf_func_preproc.subjects iterables: {'subject_id': <function _standardize_iterables.<locals>.make_field_func.<locals>.<lambda> at 0x2aaadfba5bf8>}\n",
      "230402-10:27:16,164 nipype.workflow DEBUG:\n",
      "\t ('subnodes:', [wf_func_preproc.subjects, wf_func_preproc.datasource, wf_func_preproc.dataSink, wf_func_preproc.datasourceFunc, wf_func_preproc.discardDummies, wf_func_preproc.mcflirtWithinSess, wf_func_preproc.getMeanImg, wf_func_preproc.concatenateMeans, wf_func_preproc.mcflirtBetweenSess, wf_func_preproc.betweenMat, wf_func_preproc.concatenateTransforms, wf_func_preproc.copyTransforms, wf_func_preproc.applyRealign, wf_func_preproc.sliceTimingCorr, wf_func_preproc.concatenateFunc, wf_func_preproc.meanFunc, wf_func_preproc.binarizeMeanFunc, wf_func_preproc.datasourceManualEdits])\n",
      "230402-10:27:16,192 nipype.workflow DEBUG:\n",
      "\t [Node] subjects - setting input subject_id = sub-011\n",
      "230402-10:27:16,193 nipype.workflow DEBUG:\n",
      "\t Parameterization: paramstr=_subject_id_sub-011\n",
      "230402-10:27:16,194 nipype.workflow DEBUG:\n",
      "\t Expanding the iterable node wf_func_preproc.sessions...\n",
      "230402-10:27:16,195 nipype.workflow DEBUG:\n",
      "\t Excised the wf_func_preproc.getMeanImg -> wf_func_preproc.concatenateMeans join node in-edge.\n",
      "230402-10:27:16,195 nipype.workflow DEBUG:\n",
      "\t Excised the wf_func_preproc.sliceTimingCorr -> wf_func_preproc.concatenateFunc join node in-edge.\n",
      "230402-10:27:16,196 nipype.workflow DEBUG:\n",
      "\t node: wf_func_preproc.sessions iterables: {'sess_id': <function _standardize_iterables.<locals>.make_field_func.<locals>.<lambda> at 0x2aaadfba5d08>, 'sess_nvol': <function _standardize_iterables.<locals>.make_field_func.<locals>.<lambda> at 0x2aaadfba5ea0>, 'sess_nr': <function _standardize_iterables.<locals>.make_field_func.<locals>.<lambda> at 0x2aaadfba5c80>}\n",
      "230402-10:27:16,196 nipype.workflow DEBUG:\n",
      "\t ('subnodes:', [wf_func_preproc.sessions, wf_func_preproc.datasourceFunc.a0, wf_func_preproc.discardDummies.a0, wf_func_preproc.mcflirtWithinSess.a0, wf_func_preproc.getMeanImg.a0, wf_func_preproc.concatenateTransforms.a0, wf_func_preproc.copyTransforms.a0, wf_func_preproc.applyRealign.a0, wf_func_preproc.sliceTimingCorr.a0, wf_func_preproc.dataSink.a0, wf_func_preproc.betweenMat.a0])\n",
      "230402-10:27:16,201 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_id = task-bar_run-01\n",
      "230402-10:27:16,209 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_nr = 0\n",
      "230402-10:27:16,210 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_nvol = 168\n",
      "230402-10:27:16,211 nipype.workflow DEBUG:\n",
      "\t Parameterization: paramstr=_sess_id_task-bar_run-01_sess_nr_0_sess_nvol_168\n",
      "230402-10:27:16,219 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_id = task-bar_run-02\n",
      "230402-10:27:16,220 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_nr = 1\n",
      "230402-10:27:16,221 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_nvol = 168\n",
      "230402-10:27:16,221 nipype.workflow DEBUG:\n",
      "\t Parameterization: paramstr=_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168\n",
      "230402-10:27:16,226 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_id = task-bar_run-03\n",
      "230402-10:27:16,231 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_nr = 2\n",
      "230402-10:27:16,232 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_nvol = 168\n",
      "230402-10:27:16,233 nipype.workflow DEBUG:\n",
      "\t Parameterization: paramstr=_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168\n",
      "230402-10:27:16,234 nipype.workflow DEBUG:\n",
      "\t The join node wf_func_preproc.concatenateMeans input wf_func_preproc.getMeanImg.a0 was expanded to 3 nodes.\n",
      "230402-10:27:16,234 nipype.workflow DEBUG:\n",
      "\t Added the wf_func_preproc.concatenateMeans join item fields {'in_files': 'in_filesJ1'}.\n",
      "230402-10:27:16,235 nipype.workflow DEBUG:\n",
      "\t Added the wf_func_preproc.concatenateMeans join item fields {'in_files': 'in_filesJ2'}.\n",
      "230402-10:27:16,236 nipype.workflow DEBUG:\n",
      "\t Added the wf_func_preproc.concatenateMeans join item fields {'in_files': 'in_filesJ3'}.\n",
      "230402-10:27:16,236 nipype.workflow DEBUG:\n",
      "\t Qualified the wf_func_preproc.getMeanImg -> wf_func_preproc.concatenateMeans join field in_files as in_filesJ1.\n",
      "230402-10:27:16,237 nipype.workflow DEBUG:\n",
      "\t Connected the join node wf_func_preproc.concatenateMeans subgraph to the expanded join point wf_func_preproc.getMeanImg\n",
      "230402-10:27:16,237 nipype.workflow DEBUG:\n",
      "\t Qualified the wf_func_preproc.getMeanImg -> wf_func_preproc.concatenateMeans join field in_files as in_filesJ2.\n",
      "230402-10:27:16,238 nipype.workflow DEBUG:\n",
      "\t Connected the join node wf_func_preproc.concatenateMeans subgraph to the expanded join point wf_func_preproc.getMeanImg\n",
      "230402-10:27:16,238 nipype.workflow DEBUG:\n",
      "\t Qualified the wf_func_preproc.getMeanImg -> wf_func_preproc.concatenateMeans join field in_files as in_filesJ3.\n",
      "230402-10:27:16,238 nipype.workflow DEBUG:\n",
      "\t Connected the join node wf_func_preproc.concatenateMeans subgraph to the expanded join point wf_func_preproc.getMeanImg\n",
      "230402-10:27:16,239 nipype.workflow DEBUG:\n",
      "\t The join node wf_func_preproc.concatenateFunc input wf_func_preproc.sliceTimingCorr.a0 was expanded to 3 nodes.\n",
      "230402-10:27:16,240 nipype.workflow DEBUG:\n",
      "\t Added the wf_func_preproc.concatenateFunc join item fields {'in_files': 'in_filesJ1'}.\n",
      "230402-10:27:16,240 nipype.workflow DEBUG:\n",
      "\t Added the wf_func_preproc.concatenateFunc join item fields {'in_files': 'in_filesJ2'}.\n",
      "230402-10:27:16,241 nipype.workflow DEBUG:\n",
      "\t Added the wf_func_preproc.concatenateFunc join item fields {'in_files': 'in_filesJ3'}.\n",
      "230402-10:27:16,241 nipype.workflow DEBUG:\n",
      "\t Qualified the wf_func_preproc.sliceTimingCorr -> wf_func_preproc.concatenateFunc join field in_files as in_filesJ1.\n",
      "230402-10:27:16,241 nipype.workflow DEBUG:\n",
      "\t Connected the join node wf_func_preproc.concatenateFunc subgraph to the expanded join point wf_func_preproc.sliceTimingCorr\n",
      "230402-10:27:16,242 nipype.workflow DEBUG:\n",
      "\t Qualified the wf_func_preproc.sliceTimingCorr -> wf_func_preproc.concatenateFunc join field in_files as in_filesJ2.\n",
      "230402-10:27:16,242 nipype.workflow DEBUG:\n",
      "\t Connected the join node wf_func_preproc.concatenateFunc subgraph to the expanded join point wf_func_preproc.sliceTimingCorr\n",
      "230402-10:27:16,243 nipype.workflow DEBUG:\n",
      "\t Qualified the wf_func_preproc.sliceTimingCorr -> wf_func_preproc.concatenateFunc join field in_files as in_filesJ3.\n",
      "230402-10:27:16,243 nipype.workflow DEBUG:\n",
      "\t Connected the join node wf_func_preproc.concatenateFunc subgraph to the expanded join point wf_func_preproc.sliceTimingCorr\n",
      "230402-10:27:16,245 nipype.workflow DEBUG:\n",
      "\t PE: expanding iterables ... done\n",
      "230402-10:27:16,246 nipype.workflow DEBUG:\n",
      "\t [Node] datasourceFunc - setting input sess_id = task-bar_run-03\n",
      "230402-10:27:16,248 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_id = task-bar_run-03\n",
      "230402-10:27:16,249 nipype.workflow DEBUG:\n",
      "\t [Node] discardDummies - setting input t_size = 168\n",
      "230402-10:27:16,250 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_nvol = 168\n",
      "230402-10:27:16,250 nipype.workflow DEBUG:\n",
      "\t [Node] betweenMat - setting input index = 2\n",
      "230402-10:27:16,251 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_nr = 2\n",
      "230402-10:27:16,251 nipype.workflow DEBUG:\n",
      "\t Removed the identity node wf_func_preproc.sessions from the graph.\n",
      "230402-10:27:16,252 nipype.workflow DEBUG:\n",
      "\t [Node] datasourceFunc - setting input sess_id = task-bar_run-02\n",
      "230402-10:27:16,252 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_id = task-bar_run-02\n",
      "230402-10:27:16,253 nipype.workflow DEBUG:\n",
      "\t [Node] discardDummies - setting input t_size = 168\n",
      "230402-10:27:16,253 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_nvol = 168\n",
      "230402-10:27:16,254 nipype.workflow DEBUG:\n",
      "\t [Node] betweenMat - setting input index = 1\n",
      "230402-10:27:16,254 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_nr = 1\n",
      "230402-10:27:16,256 nipype.workflow DEBUG:\n",
      "\t Removed the identity node wf_func_preproc.sessions from the graph.\n",
      "230402-10:27:16,257 nipype.workflow DEBUG:\n",
      "\t [Node] datasourceFunc - setting input sess_id = task-bar_run-01\n",
      "230402-10:27:16,258 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_id = task-bar_run-01\n",
      "230402-10:27:16,258 nipype.workflow DEBUG:\n",
      "\t [Node] discardDummies - setting input t_size = 168\n",
      "230402-10:27:16,259 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_nvol = 168\n",
      "230402-10:27:16,259 nipype.workflow DEBUG:\n",
      "\t [Node] betweenMat - setting input index = 0\n",
      "230402-10:27:16,260 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_nr = 0\n",
      "230402-10:27:16,260 nipype.workflow DEBUG:\n",
      "\t Removed the identity node wf_func_preproc.sessions from the graph.\n",
      "230402-10:27:16,261 nipype.workflow DEBUG:\n",
      "\t [Node] datasource - setting input subject_id = sub-011\n",
      "230402-10:27:16,261 nipype.workflow DEBUG:\n",
      "\t [Node] datasourceManualEdits - setting input subject_id = sub-011\n",
      "230402-10:27:16,262 nipype.workflow DEBUG:\n",
      "\t [Node] datasourceFunc - setting input subject_id = sub-011\n",
      "230402-10:27:16,262 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input subject_id = sub-011\n",
      "230402-10:27:16,263 nipype.workflow DEBUG:\n",
      "\t [Node] datasourceFunc - setting input subject_id = sub-011\n",
      "230402-10:27:16,271 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input subject_id = sub-011\n",
      "230402-10:27:16,272 nipype.workflow DEBUG:\n",
      "\t [Node] datasourceFunc - setting input subject_id = sub-011\n",
      "230402-10:27:16,272 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input subject_id = sub-011\n",
      "230402-10:27:16,273 nipype.workflow DEBUG:\n",
      "\t Removed the identity node wf_func_preproc.subjects from the graph.\n",
      "230402-10:27:16,306 nipype.workflow DEBUG:\n",
      "\t using input graph\n",
      "230402-10:27:17,931 nipype.workflow DEBUG:\n",
      "\t creating dot graph\n",
      "230402-10:27:18,507 nipype.workflow INFO:\n",
      "\t Generated workflow graph: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/workflowgraph.svg (graph2use=exec, simple_form=True).\n"
     ]
    }
   ],
   "source": [
    "if write_graph:\n",
    "    wf.write_graph(\"workflowgraph.dot\",graph2use='exec', format='svg', simple_form=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c4f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230402-10:27:39,714 nipype.workflow DEBUG:\n",
      "\t Creating flat graph for workflow: wf_func_preproc\n",
      "230402-10:27:39,724 nipype.workflow DEBUG:\n",
      "\t expanding workflow: wf_func_preproc\n",
      "230402-10:27:39,727 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.subjects\n",
      "230402-10:27:39,730 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.datasource\n",
      "230402-10:27:39,732 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.datasourceFunc\n",
      "230402-10:27:39,733 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.sessions\n",
      "230402-10:27:39,735 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.datasourceManualEdits\n",
      "230402-10:27:39,737 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.discardDummies\n",
      "230402-10:27:39,738 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.mcflirtWithinSess\n",
      "230402-10:27:39,740 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.getMeanImg\n",
      "230402-10:27:39,741 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.concatenateMeans\n",
      "230402-10:27:39,744 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.mcflirtBetweenSess\n",
      "230402-10:27:39,746 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.betweenMat\n",
      "230402-10:27:39,746 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.concatenateTransforms\n",
      "230402-10:27:39,750 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.copyTransforms\n",
      "230402-10:27:39,750 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.applyRealign\n",
      "230402-10:27:39,751 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.sliceTimingCorr\n",
      "230402-10:27:39,751 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.acquisitionParams\n",
      "230402-10:27:39,752 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.concatenateFunc\n",
      "230402-10:27:39,752 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.meanFunc\n",
      "230402-10:27:39,753 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.binarizeMeanFunc\n",
      "230402-10:27:39,753 nipype.workflow DEBUG:\n",
      "\t processing node: wf_func_preproc.dataSink\n",
      "230402-10:27:39,753 nipype.workflow DEBUG:\n",
      "\t finished expanding workflow: wf_func_preproc\n",
      "230402-10:27:39,754 nipype.workflow INFO:\n",
      "\t Workflow wf_func_preproc settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "230402-10:27:39,760 nipype.workflow DEBUG:\n",
      "\t PE: expanding iterables\n",
      "230402-10:27:39,771 nipype.workflow DEBUG:\n",
      "\t [Node] sliceTimingCorr - setting input num_slices = 30\n",
      "230402-10:27:39,772 nipype.workflow DEBUG:\n",
      "\t [Node] sliceTimingCorr - setting input slice_order = [0.693, 1.383, 0.593, 1.283, 0.495, 1.185, 0.395, 1.085, 0.298, 0.988, 0.198, 0.888, 0.101, 0.791, 0, 0.693, 1.383, 0.593, 1.283, 0.495, 1.185, 0.395, 1.085, 0.298, 0.988, 0.198, 0.888, 0.101, 0.791, 0]\n",
      "230402-10:27:39,773 nipype.workflow DEBUG:\n",
      "\t [Node] sliceTimingCorr - setting input time_repetition = 1.5\n",
      "230402-10:27:39,773 nipype.workflow DEBUG:\n",
      "\t [Node] sliceTimingCorr - setting input time_acquisition = 1.45\n",
      "230402-10:27:39,774 nipype.workflow DEBUG:\n",
      "\t Removed the identity node wf_func_preproc.acquisitionParams from the graph.\n",
      "230402-10:27:39,774 nipype.workflow DEBUG:\n",
      "\t Detected iterable nodes [wf_func_preproc.subjects, wf_func_preproc.sessions]\n",
      "230402-10:27:39,776 nipype.workflow DEBUG:\n",
      "\t Expanding the iterable node wf_func_preproc.subjects...\n",
      "230402-10:27:39,776 nipype.workflow DEBUG:\n",
      "\t node: wf_func_preproc.subjects iterables: {'subject_id': <function _standardize_iterables.<locals>.make_field_func.<locals>.<lambda> at 0x2aaadfb76268>}\n",
      "230402-10:27:39,777 nipype.workflow DEBUG:\n",
      "\t ('subnodes:', [wf_func_preproc.subjects, wf_func_preproc.datasource, wf_func_preproc.dataSink, wf_func_preproc.datasourceFunc, wf_func_preproc.discardDummies, wf_func_preproc.mcflirtWithinSess, wf_func_preproc.getMeanImg, wf_func_preproc.concatenateMeans, wf_func_preproc.mcflirtBetweenSess, wf_func_preproc.betweenMat, wf_func_preproc.concatenateTransforms, wf_func_preproc.copyTransforms, wf_func_preproc.applyRealign, wf_func_preproc.sliceTimingCorr, wf_func_preproc.concatenateFunc, wf_func_preproc.meanFunc, wf_func_preproc.binarizeMeanFunc, wf_func_preproc.datasourceManualEdits])\n",
      "230402-10:27:39,784 nipype.workflow DEBUG:\n",
      "\t [Node] subjects - setting input subject_id = sub-011\n",
      "230402-10:27:39,785 nipype.workflow DEBUG:\n",
      "\t Parameterization: paramstr=_subject_id_sub-011\n",
      "230402-10:27:39,786 nipype.workflow DEBUG:\n",
      "\t Expanding the iterable node wf_func_preproc.sessions...\n",
      "230402-10:27:39,786 nipype.workflow DEBUG:\n",
      "\t Excised the wf_func_preproc.getMeanImg -> wf_func_preproc.concatenateMeans join node in-edge.\n",
      "230402-10:27:39,787 nipype.workflow DEBUG:\n",
      "\t Excised the wf_func_preproc.sliceTimingCorr -> wf_func_preproc.concatenateFunc join node in-edge.\n",
      "230402-10:27:39,787 nipype.workflow DEBUG:\n",
      "\t node: wf_func_preproc.sessions iterables: {'sess_id': <function _standardize_iterables.<locals>.make_field_func.<locals>.<lambda> at 0x2aaad7b9abf8>, 'sess_nvol': <function _standardize_iterables.<locals>.make_field_func.<locals>.<lambda> at 0x2aaad7b9aa60>, 'sess_nr': <function _standardize_iterables.<locals>.make_field_func.<locals>.<lambda> at 0x2aaad7bd5d08>}\n",
      "230402-10:27:39,788 nipype.workflow DEBUG:\n",
      "\t ('subnodes:', [wf_func_preproc.sessions, wf_func_preproc.datasourceFunc.a0, wf_func_preproc.discardDummies.a0, wf_func_preproc.mcflirtWithinSess.a0, wf_func_preproc.getMeanImg.a0, wf_func_preproc.concatenateTransforms.a0, wf_func_preproc.copyTransforms.a0, wf_func_preproc.applyRealign.a0, wf_func_preproc.sliceTimingCorr.a0, wf_func_preproc.dataSink.a0, wf_func_preproc.betweenMat.a0])\n",
      "230402-10:27:39,792 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_id = task-bar_run-01\n",
      "230402-10:27:39,793 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_nr = 0\n",
      "230402-10:27:39,794 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_nvol = 168\n",
      "230402-10:27:39,794 nipype.workflow DEBUG:\n",
      "\t Parameterization: paramstr=_sess_id_task-bar_run-01_sess_nr_0_sess_nvol_168\n",
      "230402-10:27:39,799 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_id = task-bar_run-02\n",
      "230402-10:27:39,812 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_nr = 1\n",
      "230402-10:27:39,813 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_nvol = 168\n",
      "230402-10:27:39,813 nipype.workflow DEBUG:\n",
      "\t Parameterization: paramstr=_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168\n",
      "230402-10:27:39,818 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_id = task-bar_run-03\n",
      "230402-10:27:39,818 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_nr = 2\n",
      "230402-10:27:39,819 nipype.workflow DEBUG:\n",
      "\t [Node] sessions - setting input sess_nvol = 168\n",
      "230402-10:27:39,819 nipype.workflow DEBUG:\n",
      "\t Parameterization: paramstr=_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168\n",
      "230402-10:27:39,820 nipype.workflow DEBUG:\n",
      "\t The join node wf_func_preproc.concatenateMeans input wf_func_preproc.getMeanImg.a0 was expanded to 3 nodes.\n",
      "230402-10:27:39,821 nipype.workflow DEBUG:\n",
      "\t Added the wf_func_preproc.concatenateMeans join item fields {'in_files': 'in_filesJ1'}.\n",
      "230402-10:27:39,821 nipype.workflow DEBUG:\n",
      "\t Added the wf_func_preproc.concatenateMeans join item fields {'in_files': 'in_filesJ2'}.\n",
      "230402-10:27:39,822 nipype.workflow DEBUG:\n",
      "\t Added the wf_func_preproc.concatenateMeans join item fields {'in_files': 'in_filesJ3'}.\n",
      "230402-10:27:39,822 nipype.workflow DEBUG:\n",
      "\t Qualified the wf_func_preproc.getMeanImg -> wf_func_preproc.concatenateMeans join field in_files as in_filesJ1.\n",
      "230402-10:27:39,823 nipype.workflow DEBUG:\n",
      "\t Connected the join node wf_func_preproc.concatenateMeans subgraph to the expanded join point wf_func_preproc.getMeanImg\n",
      "230402-10:27:39,823 nipype.workflow DEBUG:\n",
      "\t Qualified the wf_func_preproc.getMeanImg -> wf_func_preproc.concatenateMeans join field in_files as in_filesJ2.\n",
      "230402-10:27:39,824 nipype.workflow DEBUG:\n",
      "\t Connected the join node wf_func_preproc.concatenateMeans subgraph to the expanded join point wf_func_preproc.getMeanImg\n",
      "230402-10:27:39,824 nipype.workflow DEBUG:\n",
      "\t Qualified the wf_func_preproc.getMeanImg -> wf_func_preproc.concatenateMeans join field in_files as in_filesJ3.\n",
      "230402-10:27:39,825 nipype.workflow DEBUG:\n",
      "\t Connected the join node wf_func_preproc.concatenateMeans subgraph to the expanded join point wf_func_preproc.getMeanImg\n",
      "230402-10:27:39,825 nipype.workflow DEBUG:\n",
      "\t The join node wf_func_preproc.concatenateFunc input wf_func_preproc.sliceTimingCorr.a0 was expanded to 3 nodes.\n",
      "230402-10:27:39,826 nipype.workflow DEBUG:\n",
      "\t Added the wf_func_preproc.concatenateFunc join item fields {'in_files': 'in_filesJ1'}.\n",
      "230402-10:27:39,826 nipype.workflow DEBUG:\n",
      "\t Added the wf_func_preproc.concatenateFunc join item fields {'in_files': 'in_filesJ2'}.\n",
      "230402-10:27:39,827 nipype.workflow DEBUG:\n",
      "\t Added the wf_func_preproc.concatenateFunc join item fields {'in_files': 'in_filesJ3'}.\n",
      "230402-10:27:39,827 nipype.workflow DEBUG:\n",
      "\t Qualified the wf_func_preproc.sliceTimingCorr -> wf_func_preproc.concatenateFunc join field in_files as in_filesJ1.\n",
      "230402-10:27:39,827 nipype.workflow DEBUG:\n",
      "\t Connected the join node wf_func_preproc.concatenateFunc subgraph to the expanded join point wf_func_preproc.sliceTimingCorr\n",
      "230402-10:27:39,828 nipype.workflow DEBUG:\n",
      "\t Qualified the wf_func_preproc.sliceTimingCorr -> wf_func_preproc.concatenateFunc join field in_files as in_filesJ2.\n",
      "230402-10:27:39,828 nipype.workflow DEBUG:\n",
      "\t Connected the join node wf_func_preproc.concatenateFunc subgraph to the expanded join point wf_func_preproc.sliceTimingCorr\n",
      "230402-10:27:39,829 nipype.workflow DEBUG:\n",
      "\t Qualified the wf_func_preproc.sliceTimingCorr -> wf_func_preproc.concatenateFunc join field in_files as in_filesJ3.\n",
      "230402-10:27:39,829 nipype.workflow DEBUG:\n",
      "\t Connected the join node wf_func_preproc.concatenateFunc subgraph to the expanded join point wf_func_preproc.sliceTimingCorr\n",
      "230402-10:27:39,830 nipype.workflow DEBUG:\n",
      "\t PE: expanding iterables ... done\n",
      "230402-10:27:39,831 nipype.workflow DEBUG:\n",
      "\t [Node] datasourceFunc - setting input sess_id = task-bar_run-03\n",
      "230402-10:27:39,831 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_id = task-bar_run-03\n",
      "230402-10:27:39,832 nipype.workflow DEBUG:\n",
      "\t [Node] discardDummies - setting input t_size = 168\n",
      "230402-10:27:39,832 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_nvol = 168\n",
      "230402-10:27:39,847 nipype.workflow DEBUG:\n",
      "\t [Node] betweenMat - setting input index = 2\n",
      "230402-10:27:39,849 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_nr = 2\n",
      "230402-10:27:39,862 nipype.workflow DEBUG:\n",
      "\t Removed the identity node wf_func_preproc.sessions from the graph.\n",
      "230402-10:27:39,863 nipype.workflow DEBUG:\n",
      "\t [Node] datasourceFunc - setting input sess_id = task-bar_run-02\n",
      "230402-10:27:39,864 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_id = task-bar_run-02\n",
      "230402-10:27:39,864 nipype.workflow DEBUG:\n",
      "\t [Node] discardDummies - setting input t_size = 168\n",
      "230402-10:27:39,865 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_nvol = 168\n",
      "230402-10:27:39,865 nipype.workflow DEBUG:\n",
      "\t [Node] betweenMat - setting input index = 1\n",
      "230402-10:27:39,866 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_nr = 1\n",
      "230402-10:27:39,866 nipype.workflow DEBUG:\n",
      "\t Removed the identity node wf_func_preproc.sessions from the graph.\n",
      "230402-10:27:39,866 nipype.workflow DEBUG:\n",
      "\t [Node] datasourceFunc - setting input sess_id = task-bar_run-01\n",
      "230402-10:27:39,867 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_id = task-bar_run-01\n",
      "230402-10:27:39,867 nipype.workflow DEBUG:\n",
      "\t [Node] discardDummies - setting input t_size = 168\n",
      "230402-10:27:39,868 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_nvol = 168\n",
      "230402-10:27:39,868 nipype.workflow DEBUG:\n",
      "\t [Node] betweenMat - setting input index = 0\n",
      "230402-10:27:39,869 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input sess_nr = 0\n",
      "230402-10:27:39,869 nipype.workflow DEBUG:\n",
      "\t Removed the identity node wf_func_preproc.sessions from the graph.\n",
      "230402-10:27:39,870 nipype.workflow DEBUG:\n",
      "\t [Node] datasource - setting input subject_id = sub-011\n",
      "230402-10:27:39,870 nipype.workflow DEBUG:\n",
      "\t [Node] datasourceManualEdits - setting input subject_id = sub-011\n",
      "230402-10:27:39,871 nipype.workflow DEBUG:\n",
      "\t [Node] datasourceFunc - setting input subject_id = sub-011\n",
      "230402-10:27:39,871 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input subject_id = sub-011\n",
      "230402-10:27:39,872 nipype.workflow DEBUG:\n",
      "\t [Node] datasourceFunc - setting input subject_id = sub-011\n",
      "230402-10:27:39,872 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input subject_id = sub-011\n",
      "230402-10:27:39,872 nipype.workflow DEBUG:\n",
      "\t [Node] datasourceFunc - setting input subject_id = sub-011\n",
      "230402-10:27:39,873 nipype.workflow DEBUG:\n",
      "\t [Node] copyTransforms - setting input subject_id = sub-011\n",
      "230402-10:27:39,873 nipype.workflow DEBUG:\n",
      "\t Removed the identity node wf_func_preproc.subjects from the graph.\n",
      "230402-10:27:39,962 nipype.workflow DEBUG:\n",
      "\t Performing depth first search\n",
      "230402-10:27:40,63 nipype.workflow INFO:\n",
      "\t Running serially.\n",
      "230402-10:27:40,65 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"wf_func_preproc.datasourceFunc\" in \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/datasourceFunc\".\n",
      "230402-10:27:40,68 nipype.workflow DEBUG:\n",
      "\t [Node] Not cached \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/datasourceFunc\".\n",
      "230402-10:27:40,71 nipype.utils DEBUG:\n",
      "\t Removing contents of /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/datasourceFunc\n",
      "230402-10:27:40,95 nipype.workflow DEBUG:\n",
      "\t [Node] Writing pre-exec report to \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/datasourceFunc/_report/report.rst\"\n",
      "230402-10:27:40,172 nipype.workflow INFO:\n",
      "\t [Node] Executing \"datasourceFunc\" <nipype.interfaces.io.DataGrabber>\n",
      "230402-10:27:40,309 nipype.workflow INFO:\n",
      "\t [Node] Finished \"datasourceFunc\", elapsed time 0.134215s.\n",
      "230402-10:27:40,317 nipype.workflow DEBUG:\n",
      "\t Needed files: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-03.nii;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-03.mat;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/datasourceFunc/_0xe18258ae24578fcb64af207f8eb10762_unfinished.json;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/datasourceFunc/_inputs.pklz;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/datasourceFunc/_node.pklz\n",
      "230402-10:27:40,318 nipype.workflow DEBUG:\n",
      "\t Needed dirs: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/datasourceFunc/_report\n",
      "230402-10:27:40,321 nipype.workflow DEBUG:\n",
      "\t Removing files: \n",
      "230402-10:27:40,322 nipype.workflow DEBUG:\n",
      "\t Saving results file: '/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/datasourceFunc/result_datasourceFunc.pklz'\n",
      "230402-10:27:40,440 nipype.workflow DEBUG:\n",
      "\t [Node] Writing post-exec report to \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/datasourceFunc/_report/report.rst\"\n",
      "230402-10:27:40,445 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"wf_func_preproc.discardDummies\" in \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies\".\n",
      "230402-10:27:40,448 nipype.workflow DEBUG:\n",
      "\t [Node] Not cached \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies\".\n",
      "230402-10:27:40,450 nipype.workflow DEBUG:\n",
      "\t [Node] Setting 1 connected inputs of node \"discardDummies\" from 1 previous nodes.\n",
      "230402-10:27:40,452 nipype.utils DEBUG:\n",
      "\t Loading pkl: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/datasourceFunc/result_datasourceFunc.pklz\n",
      "230402-10:27:40,457 nipype.workflow DEBUG:\n",
      "\t Resolving paths in outputs loaded from results file.\n",
      "230402-10:27:40,459 nipype.workflow DEBUG:\n",
      "\t output: sess_id\n",
      "230402-10:27:40,461 nipype.workflow DEBUG:\n",
      "\t [Node] discardDummies - setting input in_file = /scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-03.nii\n",
      "230402-10:27:40,463 nipype.utils DEBUG:\n",
      "\t Removing contents of /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies\n",
      "230402-10:27:40,484 nipype.workflow DEBUG:\n",
      "\t [Node] Writing pre-exec report to \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/_report/report.rst\"\n",
      "230402-10:27:40,657 nipype.workflow INFO:\n",
      "\t [Node] Executing \"discardDummies\" <nipype.interfaces.fsl.utils.ExtractROI>\n",
      "230402-10:27:40,660 nipype.interface DEBUG:\n",
      "\t in_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-03.nii\n",
      "230402-10:27:40,663 nipype.interface DEBUG:\n",
      "\t roi_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-03_roi.nii\n",
      "230402-10:27:40,664 nipype.interface DEBUG:\n",
      "\t t_min_8\n",
      "230402-10:27:40,666 nipype.interface DEBUG:\n",
      "\t t_size_168\n",
      "230402-10:27:40,668 nipype.interface DEBUG:\n",
      "\t in_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-03.nii\n",
      "230402-10:27:40,669 nipype.interface DEBUG:\n",
      "\t roi_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-03_roi.nii\n",
      "230402-10:27:40,669 nipype.interface DEBUG:\n",
      "\t t_min_8\n",
      "230402-10:27:40,673 nipype.interface DEBUG:\n",
      "\t t_size_168\n",
      "230402-10:27:40,893 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:27:40.893102:\n",
      "230402-10:27:40,895 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:27:40.893102:\n",
      "230402-10:27:40,896 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:27:40.893102:\n",
      "230402-10:27:40,896 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:27:40.893102:WARNING!!!! Multiple image files detected:\n",
      "230402-10:27:40,901 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:27:40.901830:/scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-03.nii /scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-03.nii.gz \n",
      "230402-10:27:40,902 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:27:40.901830:\n",
      "230402-10:27:41,29 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:27:41.029859:\n",
      "230402-10:27:41,30 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:27:41.029859:\n",
      "230402-10:27:41,31 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:27:41.029859:\n",
      "230402-10:27:41,32 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:27:41.029859:WARNING!!!! Multiple image files detected:\n",
      "230402-10:27:41,38 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:27:41.038035:/scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-03.nii /scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-03.nii.gz \n",
      "230402-10:27:41,38 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:27:41.038035:\n",
      "230402-10:27:44,484 nipype.workflow INFO:\n",
      "\t [Node] Finished \"discardDummies\", elapsed time 3.8235900000000003s.\n",
      "230402-10:27:44,495 nipype.workflow DEBUG:\n",
      "\t Needed files: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-03_roi.nii;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-03_roi.mat;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-03.nii;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-03.mat;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/_0xd73a99d754cdf1e0401c0e0ca3d28a89_unfinished.json;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/command.txt;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/_inputs.pklz;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/_node.pklz\n",
      "230402-10:27:44,498 nipype.workflow DEBUG:\n",
      "\t Needed dirs: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/_report\n",
      "230402-10:27:44,500 nipype.workflow DEBUG:\n",
      "\t Removing files: \n",
      "230402-10:27:44,502 nipype.workflow DEBUG:\n",
      "\t Saving results file: '/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/result_discardDummies.pklz'\n",
      "230402-10:27:44,680 nipype.workflow DEBUG:\n",
      "\t [Node] Writing post-exec report to \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/_report/report.rst\"\n",
      "230402-10:27:44,688 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"wf_func_preproc.mcflirtWithinSess\" in \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess\".\n",
      "230402-10:27:44,691 nipype.workflow DEBUG:\n",
      "\t [Node] Not cached \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess\".\n",
      "230402-10:27:44,693 nipype.workflow DEBUG:\n",
      "\t [Node] Setting 1 connected inputs of node \"mcflirtWithinSess\" from 1 previous nodes.\n",
      "230402-10:27:44,696 nipype.utils DEBUG:\n",
      "\t Loading pkl: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/result_discardDummies.pklz\n",
      "230402-10:27:44,702 nipype.workflow DEBUG:\n",
      "\t Resolving paths in outputs loaded from results file.\n",
      "230402-10:27:44,704 nipype.workflow DEBUG:\n",
      "\t output: roi_file\n",
      "230402-10:27:44,706 nipype.workflow DEBUG:\n",
      "\t [Node] mcflirtWithinSess - setting input in_file = /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-03_roi.nii\n",
      "230402-10:27:44,708 nipype.utils DEBUG:\n",
      "\t Removing contents of /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess\n",
      "230402-10:27:44,732 nipype.workflow DEBUG:\n",
      "\t [Node] Writing pre-exec report to \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/_report/report.rst\"\n",
      "230402-10:27:44,875 nipype.workflow INFO:\n",
      "\t [Node] Executing \"mcflirtWithinSess\" <nipype.interfaces.fsl.preprocess.MCFLIRT>\n",
      "230402-10:27:44,879 nipype.interface DEBUG:\n",
      "\t in_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-03_roi.nii\n",
      "230402-10:27:44,882 nipype.interface DEBUG:\n",
      "\t mean_vol_False\n",
      "230402-10:27:44,884 nipype.interface DEBUG:\n",
      "\t out_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii\n",
      "230402-10:27:44,886 nipype.interface DEBUG:\n",
      "\t ref_vol_1\n",
      "230402-10:27:44,887 nipype.interface DEBUG:\n",
      "\t save_mats_True\n",
      "230402-10:27:44,889 nipype.interface DEBUG:\n",
      "\t in_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-03_roi.nii\n",
      "230402-10:27:44,891 nipype.interface DEBUG:\n",
      "\t mean_vol_False\n",
      "230402-10:27:44,893 nipype.interface DEBUG:\n",
      "\t out_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii\n",
      "230402-10:27:44,895 nipype.interface DEBUG:\n",
      "\t ref_vol_1\n",
      "230402-10:27:44,896 nipype.interface DEBUG:\n",
      "\t save_mats_True\n",
      "230402-10:28:22,166 nipype.workflow INFO:\n",
      "\t [Node] Finished \"mcflirtWithinSess\", elapsed time 37.284723s.\n",
      "230402-10:28:22,184 nipype.workflow DEBUG:\n",
      "\t Needed files: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.mat;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0000;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0001;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0002;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0003;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0004;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0005;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0006;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0007;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0008;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0009;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0010;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0011;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0012;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0013;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0014;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0015;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0016;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0017;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0018;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0019;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0020;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0021;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0022;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0023;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0024;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0025;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0026;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0027;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0028;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0029;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0030;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0031;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0032;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0033;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0034;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0035;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0036;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0037;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0038;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0039;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0040;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0041;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0042;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0043;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0044;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0045;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0046;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0047;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0048;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0049;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0050;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0051;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0052;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0053;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0054;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0055;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0056;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0057;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0058;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0059;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0060;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0061;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0062;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0063;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0064;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0065;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0066;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0067;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0068;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0069;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0070;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0071;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0072;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0073;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0074;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0075;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0076;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0077;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0078;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0079;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0080;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0081;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0082;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0083;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0084;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0085;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0086;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0087;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0088;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0089;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0090;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0091;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0092;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0093;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0094;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0095;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0096;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0097;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0098;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0099;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0100;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0101;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0102;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0103;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0104;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0105;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0106;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0107;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0108;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0109;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0110;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0111;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0112;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0113;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0114;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0115;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0116;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0117;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0118;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0119;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0120;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0121;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0122;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0123;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0124;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0125;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0126;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0127;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0128;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0129;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0130;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0131;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0132;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0133;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0134;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0135;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0136;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0137;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0138;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0139;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0140;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0141;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0142;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0143;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0144;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0145;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0146;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0147;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0148;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0149;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0150;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0151;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0152;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0153;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0154;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0155;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0156;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0157;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0158;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii.mat/MAT_0159;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-03_roi.nii;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-03_roi.mat;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/_0xe487ad87f5caee1a0249338a8bc0db5e_unfinished.json;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/command.txt;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/_inputs.pklz;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/_node.pklz\n",
      "230402-10:28:22,187 nipype.workflow DEBUG:\n",
      "\t Needed dirs: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/_report\n",
      "230402-10:28:22,188 nipype.workflow DEBUG:\n",
      "\t Removing files: \n",
      "230402-10:28:22,189 nipype.workflow DEBUG:\n",
      "\t Saving results file: '/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/result_mcflirtWithinSess.pklz'\n",
      "230402-10:28:22,221 nipype.workflow DEBUG:\n",
      "\t [Node] Writing post-exec report to \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/_report/report.rst\"\n",
      "230402-10:28:22,226 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"wf_func_preproc.getMeanImg\" in \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg\".\n",
      "230402-10:28:22,227 nipype.workflow DEBUG:\n",
      "\t [Node] Not cached \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg\".\n",
      "230402-10:28:22,228 nipype.workflow DEBUG:\n",
      "\t [Node] Setting 1 connected inputs of node \"getMeanImg\" from 1 previous nodes.\n",
      "230402-10:28:22,229 nipype.utils DEBUG:\n",
      "\t Loading pkl: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/result_mcflirtWithinSess.pklz\n",
      "230402-10:28:22,254 nipype.workflow DEBUG:\n",
      "\t Resolving paths in outputs loaded from results file.\n",
      "230402-10:28:22,265 nipype.workflow DEBUG:\n",
      "\t output: out_file\n",
      "230402-10:28:22,266 nipype.workflow DEBUG:\n",
      "\t [Node] getMeanImg - setting input in_file = /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii\n",
      "230402-10:28:22,268 nipype.utils DEBUG:\n",
      "\t Removing contents of /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg\n",
      "230402-10:28:22,698 nipype.workflow DEBUG:\n",
      "\t [Node] Writing pre-exec report to \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg/_report/report.rst\"\n",
      "230402-10:28:23,328 nipype.workflow INFO:\n",
      "\t [Node] Executing \"getMeanImg\" <nipype.interfaces.fsl.maths.MeanImage>\n",
      "230402-10:28:23,334 nipype.interface DEBUG:\n",
      "\t dimension_T\n",
      "230402-10:28:23,334 nipype.interface DEBUG:\n",
      "\t in_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii\n",
      "230402-10:28:23,335 nipype.interface DEBUG:\n",
      "\t out_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg/task-bar_run-03_roi_mcf_mean.nii\n",
      "230402-10:28:23,336 nipype.interface DEBUG:\n",
      "\t dimension_T\n",
      "230402-10:28:23,336 nipype.interface DEBUG:\n",
      "\t in_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii\n",
      "230402-10:28:23,337 nipype.interface DEBUG:\n",
      "\t out_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg/task-bar_run-03_roi_mcf_mean.nii\n",
      "230402-10:28:27,822 nipype.workflow INFO:\n",
      "\t [Node] Finished \"getMeanImg\", elapsed time 4.487712s.\n",
      "230402-10:28:27,835 nipype.workflow DEBUG:\n",
      "\t Needed files: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg/task-bar_run-03_roi_mcf_mean.nii;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg/task-bar_run-03_roi_mcf_mean.mat;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.nii;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-03_roi_mcf.mat;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg/_0x6707807923dbdfa747d23c1327c5a423_unfinished.json;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg/command.txt;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg/_inputs.pklz;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg/_node.pklz\n",
      "230402-10:28:27,836 nipype.workflow DEBUG:\n",
      "\t Needed dirs: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg/_report\n",
      "230402-10:28:27,837 nipype.workflow DEBUG:\n",
      "\t Removing files: \n",
      "230402-10:28:27,838 nipype.workflow DEBUG:\n",
      "\t Saving results file: '/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg/result_getMeanImg.pklz'\n",
      "230402-10:28:27,967 nipype.workflow DEBUG:\n",
      "\t [Node] Writing post-exec report to \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-03_sess_nr_2_sess_nvol_168/_subject_id_sub-011/getMeanImg/_report/report.rst\"\n",
      "230402-10:28:27,975 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"wf_func_preproc.datasourceFunc\" in \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/datasourceFunc\".\n",
      "230402-10:28:27,978 nipype.workflow DEBUG:\n",
      "\t [Node] Not cached \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/datasourceFunc\".\n",
      "230402-10:28:27,980 nipype.utils DEBUG:\n",
      "\t Removing contents of /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/datasourceFunc\n",
      "230402-10:28:28,225 nipype.workflow DEBUG:\n",
      "\t [Node] Writing pre-exec report to \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/datasourceFunc/_report/report.rst\"\n",
      "230402-10:28:28,297 nipype.workflow INFO:\n",
      "\t [Node] Executing \"datasourceFunc\" <nipype.interfaces.io.DataGrabber>\n",
      "230402-10:28:28,428 nipype.workflow INFO:\n",
      "\t [Node] Finished \"datasourceFunc\", elapsed time 0.127192s.\n",
      "230402-10:28:28,435 nipype.workflow DEBUG:\n",
      "\t Needed files: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-02.nii;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-02.mat;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/datasourceFunc/_0xfc404a3005bd4714b4444d8b0bd60b5e_unfinished.json;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/datasourceFunc/_inputs.pklz;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/datasourceFunc/_node.pklz\n",
      "230402-10:28:28,437 nipype.workflow DEBUG:\n",
      "\t Needed dirs: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/datasourceFunc/_report\n",
      "230402-10:28:28,439 nipype.workflow DEBUG:\n",
      "\t Removing files: \n",
      "230402-10:28:28,441 nipype.workflow DEBUG:\n",
      "\t Saving results file: '/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/datasourceFunc/result_datasourceFunc.pklz'\n",
      "230402-10:28:28,456 nipype.workflow DEBUG:\n",
      "\t [Node] Writing post-exec report to \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/datasourceFunc/_report/report.rst\"\n",
      "230402-10:28:28,460 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"wf_func_preproc.discardDummies\" in \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies\".\n",
      "230402-10:28:28,463 nipype.workflow DEBUG:\n",
      "\t [Node] Not cached \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies\".\n",
      "230402-10:28:28,465 nipype.workflow DEBUG:\n",
      "\t [Node] Setting 1 connected inputs of node \"discardDummies\" from 1 previous nodes.\n",
      "230402-10:28:28,467 nipype.utils DEBUG:\n",
      "\t Loading pkl: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/datasourceFunc/result_datasourceFunc.pklz\n",
      "230402-10:28:28,472 nipype.workflow DEBUG:\n",
      "\t Resolving paths in outputs loaded from results file.\n",
      "230402-10:28:28,472 nipype.workflow DEBUG:\n",
      "\t output: sess_id\n",
      "230402-10:28:28,475 nipype.workflow DEBUG:\n",
      "\t [Node] discardDummies - setting input in_file = /scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-02.nii\n",
      "230402-10:28:28,478 nipype.utils DEBUG:\n",
      "\t Removing contents of /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies\n",
      "230402-10:28:28,528 nipype.workflow DEBUG:\n",
      "\t [Node] Writing pre-exec report to \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/_report/report.rst\"\n",
      "230402-10:28:28,723 nipype.workflow INFO:\n",
      "\t [Node] Executing \"discardDummies\" <nipype.interfaces.fsl.utils.ExtractROI>\n",
      "230402-10:28:28,727 nipype.interface DEBUG:\n",
      "\t in_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-02.nii\n",
      "230402-10:28:28,729 nipype.interface DEBUG:\n",
      "\t roi_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-02_roi.nii\n",
      "230402-10:28:28,731 nipype.interface DEBUG:\n",
      "\t t_min_8\n",
      "230402-10:28:28,733 nipype.interface DEBUG:\n",
      "\t t_size_168\n",
      "230402-10:28:28,735 nipype.interface DEBUG:\n",
      "\t in_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-02.nii\n",
      "230402-10:28:28,737 nipype.interface DEBUG:\n",
      "\t roi_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-02_roi.nii\n",
      "230402-10:28:28,739 nipype.interface DEBUG:\n",
      "\t t_min_8\n",
      "230402-10:28:28,740 nipype.interface DEBUG:\n",
      "\t t_size_168\n",
      "230402-10:28:29,84 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:28:29.084515:\n",
      "230402-10:28:29,87 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:28:29.084515:\n",
      "230402-10:28:29,88 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:28:29.084515:\n",
      "230402-10:28:29,88 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:28:29.084515:WARNING!!!! Multiple image files detected:\n",
      "230402-10:28:29,93 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:28:29.093550:/scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-02.nii /scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-02.nii.gz \n",
      "230402-10:28:29,94 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:28:29.093550:\n",
      "230402-10:28:29,483 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:28:29.483547:\n",
      "230402-10:28:29,484 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:28:29.483547:\n",
      "230402-10:28:29,485 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:28:29.483547:\n",
      "230402-10:28:29,485 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:28:29.483547:WARNING!!!! Multiple image files detected:\n",
      "230402-10:28:29,491 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:28:29.491788:/scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-02.nii /scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-02.nii.gz \n",
      "230402-10:28:29,492 nipype.interface INFO:\n",
      "\t stderr 2023-04-02T10:28:29.491788:\n",
      "230402-10:28:33,234 nipype.workflow INFO:\n",
      "\t [Node] Finished \"discardDummies\", elapsed time 4.506863s.\n",
      "230402-10:28:33,242 nipype.workflow DEBUG:\n",
      "\t Needed files: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-02_roi.nii;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-02_roi.mat;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-02.nii;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/raw/sub-011/func/task-bar_run-02.mat;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/_0x5e1d800468c2e8f12d4267410614c37e_unfinished.json;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/command.txt;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/_inputs.pklz;/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/_node.pklz\n",
      "230402-10:28:33,243 nipype.workflow DEBUG:\n",
      "\t Needed dirs: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/_report\n",
      "230402-10:28:33,244 nipype.workflow DEBUG:\n",
      "\t Removing files: \n",
      "230402-10:28:33,244 nipype.workflow DEBUG:\n",
      "\t Saving results file: '/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/result_discardDummies.pklz'\n",
      "230402-10:28:33,300 nipype.workflow DEBUG:\n",
      "\t [Node] Writing post-exec report to \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/_report/report.rst\"\n",
      "230402-10:28:33,306 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"wf_func_preproc.mcflirtWithinSess\" in \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess\".\n",
      "230402-10:28:33,308 nipype.workflow DEBUG:\n",
      "\t [Node] Not cached \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess\".\n",
      "230402-10:28:33,310 nipype.workflow DEBUG:\n",
      "\t [Node] Setting 1 connected inputs of node \"mcflirtWithinSess\" from 1 previous nodes.\n",
      "230402-10:28:33,314 nipype.utils DEBUG:\n",
      "\t Loading pkl: /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/result_discardDummies.pklz\n",
      "230402-10:28:33,319 nipype.workflow DEBUG:\n",
      "\t Resolving paths in outputs loaded from results file.\n",
      "230402-10:28:33,322 nipype.workflow DEBUG:\n",
      "\t output: roi_file\n",
      "230402-10:28:33,324 nipype.workflow DEBUG:\n",
      "\t [Node] mcflirtWithinSess - setting input in_file = /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-02_roi.nii\n",
      "230402-10:28:33,325 nipype.utils DEBUG:\n",
      "\t Removing contents of /scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess\n",
      "230402-10:28:33,415 nipype.workflow DEBUG:\n",
      "\t [Node] Writing pre-exec report to \"/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/_report/report.rst\"\n",
      "230402-10:28:33,748 nipype.workflow INFO:\n",
      "\t [Node] Executing \"mcflirtWithinSess\" <nipype.interfaces.fsl.preprocess.MCFLIRT>\n",
      "230402-10:28:33,752 nipype.interface DEBUG:\n",
      "\t in_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-02_roi.nii\n",
      "230402-10:28:33,754 nipype.interface DEBUG:\n",
      "\t mean_vol_False\n",
      "230402-10:28:33,756 nipype.interface DEBUG:\n",
      "\t out_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-02_roi_mcf.nii\n",
      "230402-10:28:33,758 nipype.interface DEBUG:\n",
      "\t ref_vol_1\n",
      "230402-10:28:33,760 nipype.interface DEBUG:\n",
      "\t save_mats_True\n",
      "230402-10:28:33,762 nipype.interface DEBUG:\n",
      "\t in_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/discardDummies/task-bar_run-02_roi.nii\n",
      "230402-10:28:33,764 nipype.interface DEBUG:\n",
      "\t mean_vol_False\n",
      "230402-10:28:33,766 nipype.interface DEBUG:\n",
      "\t out_file_/scratch/mayaaj90/project-0b-pRF-tutorial-3T/derivatives/wf_func_preproc/_sess_id_task-bar_run-02_sess_nr_1_sess_nvol_168/_subject_id_sub-011/mcflirtWithinSess/task-bar_run-02_roi_mcf.nii\n",
      "230402-10:28:33,768 nipype.interface DEBUG:\n",
      "\t ref_vol_1\n",
      "230402-10:28:33,770 nipype.interface DEBUG:\n",
      "\t save_mats_True\n"
     ]
    }
   ],
   "source": [
    "if run_pipeline:\n",
    "    if n_procs == 1:\n",
    "        wf.run()\n",
    "    else:\n",
    "        wf.run('MultiProc', plugin_args={'n_procs': n_procs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a8780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
